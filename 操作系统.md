# 1. 基础知识
- 计算机的执行过程：取指(PC)执行
- 操作系统的功能：**处理器资源分配、存储管理、设备管理、文件管理、提供用户接口**
## 1.1 x86 PC开机过程
- 刚开机时CPU处于实模式(和保护模型对应，实模式的CS:IP和保护模式不一样)
- 开机： `CS=0xFFFF, IP=0x0000` (CS是x86的**代码段寄存器**，IP是**指令指针寄存器**，CPU会从`CS<<4+IP`的内存地址开始读取指令并执行)
- 寻址`0xFFFF0`（ROM BIOS映射区 Basic Input Ouput System）
- 检查RAM，键盘，显示器，软硬磁盘
- 将磁盘0磁道0扇区（操作系统的引导扇区，512B）读入`0x7c00`处（0x7c00处存放的语句是 `mov ax, #BOOTSEG   mov ds, ax`，其中BOOTSEG=0x07c0）
- 设置`CS=0x07c0，IP=0x0000`（CS<<4+IP=0x7c00）

## 1.2 操作系统的接口

- **操作系统的接口**表现为函数调用，又由系统提供，所以称为**系统调用(System Call)**

### 1.2.2 系统调用的实现
- 用户不能随意调用内核数据，不能随意jmp
- 处理器的硬件隔离设计：通过**内核态和用户态**将内核程序和应用程序隔离，CS:IP是当前指令，用**CS的最低两位来区分内核态和用户态**：0是内核态，3是用户态
- 内核态可以访问任何数据，用户态不可以访问内核数据(通过比较CPL和DPL)
- 系统调用通过`陷阱机制(Trap)`完成。系统调用是中断的一种。中断是用户态进入内核态的唯一方式


# 2. 进程和线程
## 2.1 进程
- **进程(Process)** 本质上就是操作系统执行的一个程序
- 与每个进程相关的是`地址空间(address space)`，在这个地址空间中，进程可以进行读写操作，地址空间中存放了可执行程序，程序所需要的指令和数据
- 与一个进程有关的所有信息，除了进程自身地址空间的内容外，均存放在操作系统的一张表中，成为`进程表(process table)`，进程表是数组或者链表结构，每个进程都要占据其中一项
- 一个挂起的进程包括：进程的地址空间 和 对应的进程表项
- **地址空间：** 为了防止应用程序之间相互干扰，需要一些保护机制，虽然机制是在硬件中实现的，但是由操作系统进行控制。现代操作系统利用`虚拟内存`计数可以把部分地址空间装入内存，部分留在磁盘，来运行超过计算机主存的地址空间的进程

内存中的进程：
![进程](https://s1.ax1x.com/2020/10/20/BSTFBD.png)

- 以 32 位机器为例，地址总线是32位，可寻址的最⼤内存空间是 $2^{32}$Bytes，即4GBytes。每⼀个运⾏的进程都可以获得⼀个4GB的逻辑地址空间，这个空间被分成两个部分： 内核空间和⽤户空间，其中⽤户空间分配到从0x00000000到0xC0000000共3GB的地址，⽽内核空间分配了0xC0000000到0xFFFFFFFF⾼位的1GB地址

![进程的内存映像](https://s1.ax1x.com/2020/10/22/BitjFe.png)


### 2.1.1 进程模型
- 在进程模型中，所有计算机上运行的软件，包括操作系统，被组织为若干`顺序进程(sequential process)`，简称为进程。一个进程就是一个正在执行的程序的实例
- 从概念上来说，每个进程都有自己的虚拟CPU(实际上是CPU在各个进程之间进行来回切换)。**进程包括程序计数器、寄存器和变量当前值**



### 2.1.2 进程创建
进程创建的四种方式：
1. **系统初始化(init)：** 启动操作系统时，通常会创建若干个进程。前台进程，后台进程，守护进程。`ps`可以查看正在运行的进程
2. **系统调用创建：** 一个正在运行的进程通过`系统调用(如fork)`来创建一个或多个新进程来帮助其完成工作
3. **用户请求创建：** 启动程序
4. **批处理创建：** 在`大型的批处理系统`中，用户提交批处理作业，操作系统创建一个新的进程并从其中的输入队列中运行下一个作业

UNIX和Win32的系统调用表
![系统调用](https://s1.ax1x.com/2020/10/19/0v7I3V.png)



![fork](https://s1.ax1x.com/2020/10/20/BpA559.png)
- **fork()函数有返回值：** 如果创建子进程成功，对于父进程的返回值是子进程的pid，对于子进程的返回值是0，创建失败则返回-1
- 父进程如果wait子进程，直接结束，子进程就变成孤儿进程，被pid=1的进程接管
~~~c
int main(int argc, char const* argv[])
{
  pid_t pid;  //父进程pid
  pid_t cid;  //子进程pid
  printf("我是父进程，我的pid是:%d\n", getpid());
  
  cid = fork();
  if(cid==0){ //子进程执行
    printf("我是子进程，我的pid是%d，我看到的fork返回值是%d\n", getpid(), cid);
  }else{
    printf("我是父进程，我的pid是%d, 我看到的fork返回值是%d\n", getpid(), cid);
  }
  pause();
  return 0;
}

//我是父进程，我的pid是:18619
//我是父进程，我的pid是18619, 我看到的fork返回值是18620
//我是子进程，我的pid是18620，我看到的fork返回值是0

~~~

- 进程创建之后，**父进程和子进程有各自不同的地址空间**，如果其中一个进程在其地址空间修改了一个词，这个修改对另一个进程是不可见的
- 在UNIX中，**子进程的地址空间是父进程的一个拷贝**，**但是却是两个不同的地址空间**。**不可写的内存区域是共享的**。或者子进程共享父进程的所有内存，但是是通过`写时复制(copy-on-write)`共享的，一旦某个进程要修改部分内存，这块内存首先就要被复制，以确保修改发生在私有内存区域。**可写的内存是不能被共享的**。
- 在Windows中，从一开始父进程的地址空间和子进程的地址空间就是不同的

### 2.1.3 进程终止
1. **正常退出(自愿)：** 由于完成工作而终止，当编译器完成所给定程序的编译后，会执行一个系统调用告诉操作系统它完成了任务。UNIX中是`exit`，Windows中是`ExitProcess`
2. **错误退出(自愿)：** 执行时遇到错误，声明错误并退出
3. **严重错误(非自愿)：** 执行时遇到严重错误，操作系统终止进程 
4. **被其他进程杀死(非自愿)：** 其他进程执行系统调用告诉操作系统杀死某个进程。UNIX中是`kill`，Windows中对应函数是`TerminateProcess`(不是系统调用)

**UNIX进程体系：** 进程和它的所有子进程以及子进程的子进程共同组成一个进程组。如UNIX启动后，整个操作系统中所有的进程都隶属于一个以`init`为根的进程树

### 2.1.4 进程的状态
- 一般而言，每个进程至少应处于三种基本状态之一：就绪态(Ready)、运行态(Running)、阻塞态(Block)
![进程状态](https://s1.ax1x.com/2020/10/20/BSxcwt.png)
1. 运行态：进程实际占用cpu时间片运行时
2. 就绪态：可运行，但是因为其他进程正在运行而处于就绪态
3. 阻塞态：除非某种事件时间发生，否则进程不能运行。**阻塞是运行时的进程主动进行的**

**进程何时离开cpu（进程切换时机）：**
1. 内部事件：主动放弃(`yield`)CPU，进入到`阻塞/终止`状态。例如使用IO设备，或者(非)正常结束
2. 外部事件：进程被剥夺CPU的使用权，进入到`就绪`态，这个动作叫`抢占(preempt)`。例如时间片用完，高优先权进程到达

- 进程切换时，会将原进程的数据保存到`进程控制块(Process Control Block)`中 **（进程状态，PID，PC，寄存器，内存管理相关数据，文件相关数据等）**
- 进程队列是PCB的队列，而不是整个进程上下文
- 进程上下文(Process Context)
![进程上下文](https://s1.ax1x.com/2020/10/20/BpCkbd.png)

**进程调度** 指的是，**决定哪些进程优先被运行和运行多久**，由操作系统的`调度器(scheduler)`执行
![进程调度](https://s1.ax1x.com/2020/10/20/BScN5T.png)]

### 2.1.5 进程的切换
操作系统为了执行进程间的切换，会维护一张`进程表(Process Table)`，每个进程占用一个表项，表项包括了进程状态的重要信息：**程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号、调度信息、其他由运行态转换到阻塞或就绪态所需要保存的信息**，从而保证改进程随后能再次启动，就像没有中断过一样
![进程表项](https://s1.ax1x.com/2020/10/19/0vXj4H.png)


- **进程切换的时机：** `主动`(启动IO设备)，`被动`(高优先级进程，CPU时间片用完)。进程切换时会发出中断信号，进行用户态到内核态的切换，执行中断处理程序，再切换回用户态执行另一个进程。
- **进程切换过程：** 保存被中断进程的上下文信息 --> 修改被中断进程的控制信息 --> 将被中断进程加入到相应的队列 --> 调度新的进程并恢复它的上下文信息

- **中断：** CPU在正常执行程序时，由于内部/外部事件的触发或由程序预先设定而引起的CPU暂时中止当前正在执行的程序，保存当前程序相关信息到栈中，转而执行中断服务子程序，待执行完中断服务子程序后，CPU再获取被保存到栈中的被中断程序的信息，从而继续执行被中断程序的过程
- **外中断(Interrupt)：** 来自外部事件触发的中断。如**键盘中断，外围设备中断**。外部中断均是`异步中断(随机中断)`
- **内中断(Exception)：** 来自内部事件触发的中断，就是异常。如硬件异常(掉电)，**程序异常**(非法操作，除0等)，**系统调用**。内部中断都是`同步中断`
- **模式切换：** 不管是外中断还是内中断都会进行用户态到内核态的切换，用户态到内核态的切换也只能通过`中断`进行。内核态到用户态通过`LPSWS指令`(恢复现场)切换

- **中断向量：** 中断服务程序的入口地址
- **中断向量表：** 中断类型码到对应中断向量的映射表
- **中断处理过程：** 请求中断→响应中断→关中断→保护断点→中断源识别→保护现场→开中断→中断服务程序→关中断→恢复现场→开中断→中断返回

中断处理和调度的过程：
1. 硬件压入堆栈：程序计数器、程序状态字、寄存器值
2. 硬件从中断向量装入新的程序计数器
3. 汇编语言过程：保存寄存器的值
4. 汇编语言过程：设置新的堆栈
5. C中断服务器运行(典型的读和缓存写入)
6. 调度器决定下面哪个程序先运行
7. C过程返回值汇编代码
8. 汇编语言过程：开始执行新的当前程序

## 2.2 线程
- 创建子进程即使是完成很小的任务，也要完全拷贝进程上下文，浪费了资源。于是有了线程
![线程引入](https://s1.ax1x.com/2020/10/20/BShErQ.png)
- 多线程之间会**共享同一块地址空间和所有可用数据**，这时进程所不具备的
- 线程比进程更轻量级，创建线程比创建进程快10-100倍
- 进程切换开销较大(保存和恢复现场)
- 线程间通信比进程间通信效率更高
- 对CPU密集型任务，多线程并不能获得性能上的增强，反而会因为过多的多任务切换降低效率，所以计算密集型任务同时进行的数量应当等于CPU核心数。但是对I/O密集型任务，多线程能在活动中彼此重叠进行，加快应用程序的执行速度

IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差

### 2.2.1 经典线程模型
- 同一个线程中的所有线程都会有完全一样的地址空间，这意味着他们也共享同样的全局变量。一个线程可以读取、写入甚至擦除另一个线程的堆栈。线程之间出了共享同一内存空间外，还具有如下不同的内容：
![线程额外字段](https://s1.ax1x.com/2020/10/19/0xkXan.png)

传统进程有一个单独的线程
多线程时，每个线程都有自己的堆栈
![线程堆栈](https://s1.ax1x.com/2020/10/19/0xAxwd.png)

线程的系统调用：
线程通常从当前的某个单线程开始，通过调用库函数`thread_create`来创建新的线程，指定线程名称   
当线程完成工作之后，调用函数`thread_exit`退出，紧接着而线程消失，状态变为终止，不能再调度。某些线程运行过程中可以通过调用`thread_join`来阻塞线程，直到等待的另一个线程退出。还可以通过`thread_yeild`自动放弃CPU，让其他线程运行。


### 2.2.2 用户线程和内核线程
![线程模型](https://s1.ax1x.com/2020/10/20/BpDSBV.png)
- 以前是M:1的模型，只是方便管理线程，并不能利用多核性能
- 现多采用1：1的模型(NPTL)，但是用户线程较多时，频繁创建内核线程开销大
- M:M模型(NGPT)，节省了内核的开销，相当于线程池的思想，直接复用内核线程。但是实现复杂，需要进行ULT到KLT的分发管理 


1. **在用户空间中实现线程(User Level Thread)：** 线程在`运行时系统(Runtime System)`之上运行，每个进程需要有专用的`线程表(thread table)`，用来跟踪该进程中的线程。**在用户态运行，它的管理无需内核支持**
   - 优势：切换线程时，保存线程的状态和调度程序都是`本地过程`，所以**启动他们比进行内核调用效率更高，不需要切换到内核，不需要上下文切换，不需要对内存高速缓存进行刷新，调度便捷，效率高。同时还允许每个进程有自己定制的线程调度算法**
2. **在内核空间中实现线程(Kernel Level Thread)：** 无需运行时环境，每个进程中也没有线程表。在内核中会有用来记录系统中所有线程的线程表，创建或撤销线程通过系统调用实现。**在内核态运行，由操作系统支持与管理**
    - 由于在内核中创建或者销毁线程的开销比较大，所以某些系统会采用可循环利用的方式来回收线程。当某个线程被销毁时，就把他标志位不可运行状态，稍后必须创建新的线程时，就会重新启用旧线程，标志为可用状态

### 2.2.3 线程库
1. POSIX Pthreads：可以创建用户线程库和内核线程库
2. Windows Threads：内核线程库
3. Java Threads：根据所依赖的操作系统而定。。在windows上就是内核线程，在unix上看具体实现

- POSIX是IEEE的标准，为了使程序可移植。线程被定义为`Pthreads`，大部分的UNIX系统都支持它。
> POSIX线程 （通常称为pthreads）是一种独立于语言而存在的执行模型，以及并行执行模型。它 允许程序控制时间上重叠的多个不同的工作流程。每个工作流程都称为一个线程，可以通过调用 POSIX Threads API来实现对这些流程的创建和控制。可以把它理解为线程的标准。

|线程调用|描述|
|----|---|
|pthread_create|创建线程|
|pthread_exit|结束线程|
|pthread_join|等待一个特定线程退出|
|pthread_yield|释放CPU，给其他线程运行机会|
|pthread_attr_init|创建并初始化一个线程的属性结构|
|pthread_attr_destory|删除一个线程的属性结构|

观察join的作用：
~~~cpp
void* threadFunc(void* arg){
        printf("in new thread\n");
}

int main(){
        pthread_t tid;
        pthread_create(&tid, NULL, threadFunc, NULL);
        
        // 等待指定线程结束
        pthread_join(tid, NULL); 
        printf("in main thread\n");
        return 0;
}
//in new thread
//in main thread
~~~

~~~cpp
void* threadFunc(void* arg){
        printf("in new thread\n");
}

int main(){
        pthread_t tid;
        pthread_create(&tid, NULL, threadFunc, NULL);
        //pthread_join(tid, NULL);
        printf("in main thread\n");
        return 0;
}

// [root@iZwz91j9t2admw7xtplq6bZ code]# ./pi
// in main thread
// in new thread
// in new thread
// [root@iZwz91j9t2admw7xtplq6bZ code]# ./pi
// in main thread
~~~

多线程计算个圆周率
~~~cpp

void* calculate_pi(void* arg){
    unsigned seed = time(NULL);
    int circle_points = 0;
    int square_points = 0;
    int intervals = *((int*)arg); //参数的传递

    for(int i = 0; i<intervals*intervals; ++i){
        double rand_x = (double)rand()/RAND_MAX;
        double rand_y = (double)rand()/RAND_MAX;
        if(rand_x*rand_x + rand_y*rand_y<=1){
                circle_points++;
        }
          square_points++;
    }
    double pi = ((double)circle_points)/square_points*4.0;
    printf("cirle_points=%d, square_points=%d, pi=%lf\n",circle_points, square_points,((double)circle_points)/square_points*4.0);

    pthread_exit(0); //结束线程
}

int main(int argc, char const *argvp[]){
    pthread_t calculate_pi_threads[10];

    int args[10];

    for(int i = 0; i<10; ++i){
        args[i] = 1000*(i+1);
        pthread_create(calculate_pi_threads+i, NULL, calculate_pi, args+i);
    }
    for(int i = 0; i<10; ++i){
        pthread_join(calculate_pi_threads[i], NULL);
    }
    return 0;
}
~~~

## 2.3 调度算法
- 操作系统有一个程序叫做`调度程序(scheduler)`，当多个线程竞争CPU时间片时，调度程序来选择具体执行哪个线程，该程序使用的算法叫做`调度算法(scheduling algorithm)`

### 2.3.1 调度介绍

**CPU密集型和I/O密集型进程**
![Bp5gS0.png](https://s1.ax1x.com/2020/10/20/Bp5gS0.png)
- 大多数进程需要的cpu时间都很少
- `CPU密集型(CPU-bound)`或`计算密集型(compute-bound)` 占用CPU时间片长，IO频率低
- `I/O密集型(I/O-bound)` 占用cpu时间片短，IO频率高

**非抢占调度(Nonpreemptive)：** 一旦某个进程得到CPU，就会一直占用到终止或者阻塞状态
**抢占调度(Preemptive)：** 会被抢占，进入到就绪态

**调度算法性能的衡量：** `CPU利用率`，任务`响应时间`，任务在就绪队列累计`等待的时间`，`周转时间`(提交到完成)，`吞吐率`(每个时钟单位处理的任务数)，`公平性`(合理的让各个进程共享CPU)


调度准则主要看`等待时间`(在就绪队列等待的总时间)和`周转时间`(提交到结束的时间)
### 2.3.2 调度策略
- 没有最好最坏，寻求的是一个平衡
- 长程调度(Program到Process)，短程调度(Process到CPU)，中程调度(虚拟内存)
- 很多长程调度策略和短程调度是类似的
#### 先来先服务 First-Come, First-Served(FCFS)
- 通过就绪队列来实现
- FCFS意味着一个程序会一直运行到结束(尽管其中会出现等待I/O的情况)

特点：`简单易行`，但是短作业处在长作业后面会导致等待时间很长

#### 最短作业优先 Shortest Job First(SJF)
- 每次选择所需CPU时间最短的进程
- 非抢占式
- 也可以修改位抢占式(最短剩余时间优先)

#### 最短剩余时间优先 Shortest Remaining Time First(SRTF)
- 抢占式

SJF和SRTF特点：总是将短进程移到长进程之前，`平均等待时间最少`，被证明是最优的。但是会导致饥饿现象(长进程可能长时间无法获得CPU)，不公平
该算法很难实现！因为很难预测作业需要的CPU时间！

#### 时间片轮转 Round-Robin(RR)
- 每个进程都可以得到相同的CPU时间片，当时间片到达，进程被剥夺CPU，并加入到就绪队列的尾部
- 是`抢占式`调度算法

特点：`公平`，将固定的时间片设置得太短会导致过多的进程切换并降低CPU效率，但设置太长会导致一个短请求很长时间得不到响应。一般切换时间是10-100ms之间，上下文切换时间是0.1~1ms(约1%的开销)。当时间片取值无穷大时变退化为FCFS

#### 优先级调度 Priority
- Linux中，0为最高优先级
- 下一次调度总是选择优先级最高的进程
- SJF是优先级调度的一个特例(时间越短优先级越高)
- 可以是抢占式，也可以是非抢占式
- **静态优先级：** 优先级保持不变，会出现饥饿现象(不公平)
- **动态优先级：** 随着进程占用CPU时间的增加，优先级慢慢降低。或者随着进程在就绪队列中等待的时间增加，优先级慢慢提高

### 2.3.3 Linux的线程调度

1. Scope: `PTHREAD_SCOPE_SYSTEM` 系统范围的线程竞争（SCS）/ `PTHREAD_SCOPE_PROCESS`进程范围内的线程竞争（PCS）
   - Linux用的是前者，不支持PCS，是1：1的模型

2. policy
    `Normal Scheduling`(priority value=0)，默认调度策略是`SCHED_OTHER`（RR）
    `Real-time Scheduling`(priority value=1~99)，策略`SCHED_FIFO, SCHED_RR`

3. `ps -eLf` 观察多线程的tid及数量
4. SCHED_OTHER：time-sharing policy（RR）
   - **NICE值 = [-20,19]** 越nice，越喜欢把cpu让给别人。。优先级就低了
   - **PR值 = 20+NICE = [0,39]**
   - PR值越小，优先级越高
5. `top -p pid` 显示PR值和NI值(NI值仅对normal进程有效)
6. `chrt -p pid` 显示进程调度策略及priority_value
7. 对于实时进程`Real-time`而言，**PR值=-1-priority_value=[-100, -2]** 依然是越小优先级越高。所以实时进程优先级都比Normal进程高
8. **normal进程优先级与prioity_value无关，prioity_value=0指示这是normal进程而已，优先级通过NICE值计算PR值得出，在0到39之间。而对于Real-time的实时进程，优先级是直接通过priority_value计算得到的，PR值在-100到-2之间**
9. `chrt -f -p 11 pid` 将pid进程切换为rt，并且设置其priority_value(11)，设置policy（-f表示FIFO）

**总结：** 
1. 对Normal进程，采用SCHED_OTHER策略，是分时调度，通过NICE值来调整PR值，从而动态调整优先级
2. 对Real-Time进程，PR值相同时，采用SCHED_FIFO或者SCHED_RR
3. 均是抢占式的调度

## 2.4 同步
并发进程之间可能`独立`也可能有`交互`，有交互时就会产生`竞争`和`协作`，需要进行同步
- **同步技术(Synchronization)** 用于维护交互进程的数据一致性。通过`互斥锁`来解决竞争关系的进程，通过`信号量`来解决协作关系的进程
- **临界区(critical section)：** 进程操作公共数据的区域。不允许有两个进程同时进入临界区，以达到`互斥(Mutex)`的目的
- **进程进出临界区协议：** 进入临界区前在entry section要请求许可，离开临界区后在exit section要归还许可

**进程同步有两种方式**：互斥锁`mutex`，信号量`semaphore`

### 2.4.1 互斥锁
- `互斥锁(Mutex Lock)` 是操作系统提供的解决临界区问题的工具
- `原子操作(Atomic operation)` 原子操作不会被打断。如 `test_and_set()`, `compare_and_swap()`，均是硬件指令(比系统调用还底层，一个周期内完成，不会被中断)

基于test_and_set的锁的实现
~~~cpp
bool test_and_set(bool* target){//示意代码，实际是原子的
  bool result = *target;
  *target = false;
  return result;
}

bool available = true; //unlock
lock(){
  while(!test_and_set(&available))
    do nothing;
}

unlock(){
  available = false;
}
~~~

#### 自旋锁
- `忙式等待(Busy Waiting)`是指占用CPU执行空循环实现等待，这种类型的互斥锁成为`自旋锁`。如上面实现的基于test_and_set的锁

- pthread提供的自旋锁：`pthread_mutex_t`
~~~cpp
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; //创建锁
pthread_mutex_lock(&lock);  //上锁
pthread_mutex_unlock(&lock);  //开锁
~~~
- 缺点：浪费CPU周期
- 优点：进程在等待时**没有上下文切换**，对于使用锁的时间不长的进程，或者多处理器系统中，优势明显。很常用    


### 2.4.2 信号量与PV操作
- `信号量(Semaphore)`是一种比互斥锁更强大的同步工具，提供更高级的方法来同步并发进程。**信号量的值除了在初始化时被赋值外，只能通过P和V操作进行修改**
- `二值信号量(binary semaphore)` 只能是0或1，通常初始化为1，用于实现互斥锁的功能
- `一般信号量(counting semaphore)` 可以取值任意数值，控制并发进程对共享资源的访问

![信号量](https://s1.ax1x.com/2020/10/21/BCPaf1.png) 
~~~cpp
//二值信号量
semaphore mutex = 1;  //mutex=1 解决竞争问题
process pi(){
  P(mutex); //将mutex变为0，等价于lock

  critical section

  V(mutex); //将mutex变为1，等价于unlock
} 
~~~

~~~cpp
//一般信号量
semaphore mutex = 2;  //mutex>1 控制同时进入临界区的进程数量：可用资源数量
process pi(){
  P(mutex); //将mutex-1，当mutex<=0时等待

  critical section

  V(mutex); //将mutex+1
} 
~~~

linux中，信号量的实现：
- 包含头文件`<semaphore.h>`
- `sem_t` 信号量的数据类型
- `int sem_init(sem_t *sem, int pshared, unsigned int val)` 信号量指针，信号量类型(0表示进程内所有线程可用，其他表示不同进程的线程可用)，初始值
- `int sem_wait(sem_t *sem)` P操作，申请信号量，当没有信号量可用时等待，有信号量时对信号量值减1
- `int sem_post(sem_t *sem)` V操作，释放一个信号量，信号量值加1
- `int sem_destory(sem_t *sem)` 销毁信号量

### 2.4.3 信号量实现同步

- 同步问题实质就是将异步的并发进程按照某种顺序执行
- 解决同步的本质就是找到并发进程的交互点，利用P操作的等待特点来调节进程的执行速度

#### 司机售票员
![司机售票员问题](https://s1.ax1x.com/2020/10/21/BCk3Of.png)  

#### 生产者消费者问题
- 生产者P和消费者C共用一个缓冲区buffer，生产者不能往满的缓冲区放产品，消费者不能从空的缓冲区中取产品

单缓冲解决方案
~~~cpp
Semaphore empty=1;
Semaphore full=0;

Producer{
  while(true){
    make a product;
    P(empty);
    put into buffer;
    V(full);
  }
}

Comsumer{
  while(true){
    P(full);
    pick product from buffer;
    V(empty);
    comsume the product;    
  }
}
~~~

多缓冲解决方案
~~~cpp
Semaphore empty=k;
Semaphore full=0;
Semaphore mutex=1;
item B[k];
int in=0, out=0;

Process producer_i{
    make a product;
    P(empty); //同步信号量：PV不在同一个进程，用于同步
    
    P(mutex); //互斥信号量：PV在同一个进程中，用于解决竞争
    B[in]=product;
    in=(in+1)%k;
    V(mutex);
    
    V(full);
}

Process comsumer_i{
    P(full);

    P(mutex);
    product = B[out];
    out=(out+1)%k;
    V(mutex);
    
    V(empty);
    comsume a product;
}
~~~

#### 苹果橘子问题
盘子一次放一个水果，爸爸放苹果，妈妈放橘子，女儿吃苹果，儿子吃橘子
![苹果橘子问题](https://s1.ax1x.com/2020/10/21/BCs8Tx.png)

#### 读者写者问题
Reader和Writer之间是竞争关系，Writer和Writer竞争，Reader和Reader共享
![读者写者问题](https://s1.ax1x.com/2020/10/21/BPFPmT.png)

#### 理发师问题
理发店有几个等待座位，没人要理发时理发师就睡觉，有人在理发，座位没坐满时顾客就坐下，否则离开
![理发师问题](https://s1.ax1x.com/2020/10/21/BPPm59.png)

#### 哲学家就餐问题
![哲学家就餐问题](https://s1.ax1x.com/2020/10/21/BPi6OK.png)

### 2.4.4 管程实现同步

- 信号量功能强大，但是使用时对信号量的操作分散，难以控制，读写和维护困难，于是有了一种集中式同步进程--**管程**。**基本思想就是将共享变量和对他们的操作集中在一个模块中**，操作系统或并发程序就是由这样的模块构成。这样模块之间联系清晰，便于维护和修改，易于保证正确性



**管程的特性：**

- 模块化：管程是一个基本单位，可以单独编译
- 抽象数据类型：管程中不仅有数据，还有对数据的操作
- 信息掩蔽和封装性：管程中定义的共享变量的所有操作都局限在管程中，外部只能通过调用管程的某些函数来间接访问这些变量但是函数的具体实现对外部是不可见的
- 互斥访问：管程是互斥的，某个时刻只能允许一个进程或线程访问共享资源
- 管程中必须有等待队列和响应的等待和唤醒的操作
- 必须有一种方法使进程无法继续运行时被阻塞(wait)



**管程是用于管理资源的**，因此管程中有进程等待队列和响应的等待和唤醒操作。在管程入口有一个`入口等待队列`，一个进程进入管程的等待队列就会**释放管程的互斥使用权**，当已进入管程的一个进程唤醒另一个进程时，两者必须有一个退出或停止使用管程。管程内部由于执行唤醒signal操作，可能存在多个等待进程(等待使用管程)，称为`紧急等待队列(管程内部的进程执行了wait)`，它的**优先级高于入口等待队列**。也就是：如果紧急队列有进程，则唤醒紧急队列的进程，否则才唤醒入口队列的进程

进程离开管程的时候要释放使用权



**java的monitor其实就是一种管程模型**





## 2.5 进程间通信方式

由于进程的用户地址空间都是独立的，一般是不能互相访问的，但是内核空间是每个进程都共享的，所以进程之间要进行通信必须要通过内核

### 2.5.1 管道

Linux的 `|` 就是一个管道，功能是将前一个命令的输出作为后一个命令的输入，**管道传输数据是单向的**，如果要相互通信需要创建两个管道

`|` 这种没有名字的管道称为**匿名管道**，用完了就销毁

有名字的管道称为**命名管道**，也被叫做`FIFO`，使用命名管道前要通过`mkfifo`命令创建，指定管道的名字

#### 命名管道

~~~
[root@hjc]/tmp/temp# mkfifo mypipe
[root@hjc]/tmp/temp# ll
total 0
prw-r--r-- 1 root root 0 Dec  5 13:12 mypipe	//可以看到文件类型是pipe
[root@hjc]/tmp/temp# echo "hello aaa">mypipe
//这时就阻塞住了，等待管道里的数据被读取

[root@hjc]/tmp/temp# cat<mypipe		//读取mypipe里的内容
hello aaa

//读取完毕之后上面的echo命令就正常退出了
~~~

管道通信的方式效率低，不适合进程间频繁的交换数据，好处就是简单，也很容易得知管道中的数据被其他进程读取了

#### 匿名管道

匿名管道的创建需要通过系统调用`int pipe(int fd[2])`

创建一个匿名管道，需要两个文件描述符，一个是管道的读取端的描述符`fd[0]`，一个是管道的写入端`fd[1]`

匿名管道是特殊的文件，**只存在于内存，不存在于文件系统中**

<img src="picture/操作系统/匿名管道.png" alt="匿名管道" style="zoom:67%;" />

**从管道的一端写入数据，其实就是`缓存在内核中`**，另一端读取，也就是从内核中读取这段缓存

通过fork创建子进程，然后关闭父进程的读取fd[0]，关掉子进程的写入fd[1]，就实现了父进程向子进程写入数据通信，要实现双端通信应该建立两个管道，使用一个管道，父子都能读写会造成混乱

<img src="picture/操作系统/匿名管道父子进程通信.png" alt="匿名管道父子进程通信" style="zoom: 67%;" />



- 对于shell中的`A|B` ，A进程和B进程都是shell创建出来的子进程，A和B之间不会存在父子关系，他们俩的父进程都是shell
- shell里通过`|`将多个命令连接在一起，实际上就是创建多个子进程，所以一般一个管道可以搞定的事情就不要用多个管道了，减少系统创建子进程的系统开销

<img src="picture/操作系统/shell中匿名管道的原理.png" alt="shell中匿名管道的原理" style="zoom:67%;" />



#### 匿名管道和命名管道总结

匿名管道的通信范围是**存在父子关系的进程**。因为管道没有实体，没有管道文件，只能**通过fork来复制子进程fd文件描述符**，来达到通信的目的

命名管道可以用于不相关的进程间的相互通信，因为创建了管道类型的文件，使用这个文件的进程就可以相互通信

同时，管道都是遵循先进先出的，不支持lseek之类的文件定位操作



### 2.5.2 消息队列

管道通信方式效率低，不适合进程间频繁地交换数据

**消息队列**就可以解决。A进程把数据放在对应的消息队列后就正常返回，B进程需要的时候再去读取数据就可以了



**消息队列保存的是内核中的消息链表**，通信双方提前约定好消息体的数据类型（固定大小），之后通信的数据被分为一个一个的消息体（数据块）。所以每个消息体都是固定大小的存储块，而不是管道那种无格式的字节流数据。当有进程从消息队列中读取了消息体，内核就把这个消息体删除



**生命周期**：消息队列的生命周期**随内核**，只要没有关闭操作系统，消息队列会一直存在，而**管道的生命周期随进程**的创建而创建，随进程的结束而销毁



**缺点**：**通信不及时**，**大小有限制**，不适合比较大数据的传输，不光每个消息体有大小限制`MSGMAX`，一个队列所包含的全部消息体的总长度也是有上限的`MSGMNB`。另外，消息队列**通信过程中存在用户态和内核态之间的数据拷贝开销**，进程写入数据到内核，另一个进程从内核中读取消息，都会发生用户态和内核态之间的切换



### 2.5.3 共享内存

共享内存的方式主要就是解决消息队列需要用户态和内核态状态切换的问题

基于虚拟内存技术，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中，所以即使进程A和B的虚拟地址是一样的，他们所访问的物理内存地址也是不一样的

**共享内存技术**就是拿出**一块虚拟地址空间，映射到相同的物理内存中**，这样这个进程写入的数据就可以被另一个进程看到了，不需要拷贝过来拷贝过去，大大提高了进程间通信的速度

![共享内存](picture/操作系统/共享内存.png)





### 2.5.4 信号量

共享内存方式带来的新问题就是：如果多个进程同时修改一个共享内存就会发生冲突。

为了防止多进程竞争共享资源造成数据错乱，引入了**信号量**来实现共享内存的互斥访问

和进程同步的方式差不多，引入PV操作

### 2.5.5 信号

上面的进程通信方式都是在常规工作模式，对于**异常情况下的工作模式**，就需要**信号**的方式来通知进程。

通过`kill -l`命令可以查看所有的信号

~~~
$ kill -l
1) SIGHUP     2) SIGINT     3) SIGQUIT     4) SIGILL     5) SIGTRAP
6) SIGABRT     7) SIGBUS     8) SIGFPE     9) SIGKILL    10) SIGUSR1
11) SIGSEGV    12) SIGUSR2    13) SIGPIPE    14) SIGALRM    15) SIGTERM
16) SIGSTKFLT    17) SIGCHLD    18) SIGCONT    19) SIGSTOP    20) SIGTSTP
21) SIGTTIN    22) SIGTTOU    23) SIGURG    24) SIGXCPU    25) SIGXFSZ
26) SIGVTALRM    27) SIGPROF    28) SIGWINCH    29) SIGIO    30) SIGPWR
31) SIGSYS    34) SIGRTMIN    35) SIGRTMIN+1    36) SIGRTMIN+2    37) SIGRTMIN+3
38) SIGRTMIN+4    39) SIGRTMIN+5    40) SIGRTMIN+6    41) SIGRTMIN+7    42) SIGRTMIN+8
43) SIGRTMIN+9    44) SIGRTMIN+10    45) SIGRTMIN+11    46) SIGRTMIN+12    47) SIGRTMIN+13
48) SIGRTMIN+14    49) SIGRTMIN+15    50) SIGRTMAX-14    51) SIGRTMAX-13    52) SIGRTMAX-12
53) SIGRTMAX-11    54) SIGRTMAX-10    55) SIGRTMAX-9    56) SIGRTMAX-8    57) SIGRTMAX-7
58) SIGRTMAX-6    59) SIGRTMAX-5    60) SIGRTMAX-4    61) SIGRTMAX-3    62) SIGRTMAX-2
63) SIGRTMAX-1    64) SIGRTMAX
~~~

例如 Ctrl+C就产生了`SIGINT`信号，表示终止退出该进程。Ctrl+Z就产生了`SIGSTOP`信号，表示中止执行该进程，但还未结束

如果进程在后台运行，可以通过`kill`命令发送信号，如`kill -9 pid`表示发送`SIGKILL`信号给pid的进程

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一个进程，一旦有信号产生，用户进程就需要进行处理：三种方式

1. 执行默认操作：linux对每种信号都规定了默认操作
2. 捕捉信号：为信号定义一个信号处理函数，当信号发生时执行相应的信号处理函数

3. 忽略信号：可以忽略某些不想处理的信号，但是`SIGKILL`和`SEGSTOP`是无法捕捉和忽略的，可以在任何时候中断或者结束某一进程



### 2.5.6 Socket

**跨网络的不同主机上的进程之间的通信**

~~~
//socket的系统调用
int socket(int domain, int type, int protocal)
~~~

- domain：指定协议族，如AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机
- type：指定通信的特性，如SOCK_STREAM 表示字节流(TCP)、SOCK_DGRAM 表示数据报(UDP)、SOCK_RAW 表示的是原始套接字
- protocal：原本用于指定通信协议，现作废，前面已经指定了，写成0即可

实现TCP字节流通信的socket类型：`AF_INET`和`SOCK_STREAM`

实现UDP数据报通信的socket类型：`AF_INET`和`SOCK_DGRAM`

实现本地进程通信的socket类型：`AF_LOCAL/AF_UNIX`和`SOCK_STREAM/SOCK_DGRAM`



需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样



## 2.6 再看多进程和多线程

- **数据共享和通信**：多进程间拥有独立的地址空间，数据独立不共享，因此数据共享复杂，通信需要使用`IPC(Inter Process Communication)`，借助管道、消息队列、共享内存、信号量、信号、socket等方式实现通信。而多线程是共享同一个进程的地址空间的，因此共享简单，使用该进程下的全局变量、静态变量等数据就可以实现通信
- **同步**：多进程相互独立，通常不需要考虑锁和同步资源的问题，而多线程访问进程的共享内存区域，需要经常考虑到同步问题(互斥锁、条件变量、读写锁、信号量)
- **内存和CPU**：多进程占用内存多，切换复杂，CPU利用率低。多线程占用内存少，切换简单，CPU利用率高
- **创建、销毁、切换开销**：进程开销大
- **编程调试**：多进程编程简单，多线程复杂
- **可靠性**：进程间互不影响。而多线程的方式只要一个线程挂掉，就会导致整个进程挂掉
- **分布式**：多进程方式扩展到多台机器比较简单



应用场景：

- 需要频繁创建和销毁的场景优先使用多线程：例如web服务器，来一个连接创建一个线程，断了就销毁线程，代价小
- 需要大量CPU计算的优先使用多线程：消耗CPU多，切换频繁，用多线程合适
- 弱相关处理适合多进程：web server的消息接发和消息处理
- 强相关处理适合多线程：消息处理的消息解码，业务处理等
- 分布式：多机分布适合用多进程，多核分布适合用多线程



## 2.7 死锁

### 2.7.1 死锁的介绍
- `饥饿`：进程长时间的等待
- `死锁(DEADLOCK)` 并发进程竞争有限的资源，循环等待，出现永远等待的现象。例如哲学家就餐问题每个人拿到一根筷子
- 避免哲学家就餐的死锁：
  - 允许最多4个哲学家同时吃
  - 奇数号哲学家先取左手筷子，偶数号先取右手的筷子
  - 每个哲学家取到手边的两根筷子菜开始吃，否则一根也不拿
- **产生死锁的四个必要条件：**
  - `互斥使用`：一个时刻一个资源只能被一个进程占用
  - `不可剥夺`：除了占有资源的进程主动释放资源外，其他进程都不可以抢夺其资源
  - `占有和等待`：一个进程请求的资源得不到满足时，不会释放已占有的资源
  - `循环等待`：上面三个条件同时存在产生的结果，每个进程分别等待另一个进程所占有的资源

- **处理死锁的策略**
  - 破坏死锁条件：破坏死锁产生的四个必要条件之一，防止死锁的发生
  - 避免死锁：允许四个必要条件存在，但是仔细分配资源来避免死锁
  - 检测恢复：死锁发生时对其进行检测，采取行动解决，解除死锁
  - 忽略死锁：`鸵鸟算法(ostrich algorithm)` 把头埋在沙子里，假装问题没有发生。。。

### 2.7.2 破坏死锁条件
`死锁的防止(Prevention)`：破坏四个必要条件之一
- ~~破坏互斥使用~~：允许资源同一时刻被共享使用。不现实，很多资源是不可以被共享使用的
- ~~破坏不可剥夺~~：使资源可以被抢夺。CPU可以被抢夺，但是对打印机等设备不应该被抢夺
- 破坏占有和等待： 可以！当一个进程获取不到所有资源时就放弃全部资源。缺点会降低资源的利用率，效果不好
- 破坏循环等待：可以！对资源按优先级编号，进程在请求某个资源时，必须获得之前的所有资源，那么资源分配之间就不会出现环。但是编号顺序难以确定，效果也不好 

**可操作性太复杂，资源利用率太低**

### 2.7.3 死锁的避免
`死锁的避免(Avoidance)`：允许四个必要条件存在，在并发进程中做出妥善安排来避免死锁的发生
- 银行家算法
- `安全状态(Safe State)`：系统按可以按一定顺序把资源分配给每个进程，并且能够避免死锁。即安全状态就是说存在一个安全序列。没有安全序列的系统状态就是不安全状态
- 安全状态一定可以避免死锁，但是不安全状态不一定会导致死锁

银行家算法的优缺点：
- 优点：允许死锁必要条件同时存在
- 缺点：缺乏实用价值。很难在运行程序前知道所需资源的最大数量，而且要求进程间无关，若考虑同步会打乱安全序列。要求进入系统的进程个数和资源数固定

### 2.7.4 死锁的检测和恢复
`死锁的检测和恢复(Detection & Recovery)` 允许死锁的发生，系统及时检测死锁并解除它

#### 死锁的检测
检测时机：
1. 当系统开销大，很多进程等待时检测死锁
2. 定时检测
3. 系统资源利用率下降时检测死锁

**检测算法：** 
通过资源分配图来检测死锁
![资源分配图](https://s1.ax1x.com/2020/10/21/BPf45d.png)

资源分配图简化：消除申请边和分配边
`(R1->P2)`，`(R2->P4)` 都可以消去
之后P3可以申请到R2，消去`(P3->R2)`，`(R1->P3)`
再接着就可以消去`(P1->R1)`，`(R2->P1)`
之后所有进程都变成了`孤立节点`(进程的所有请求边和分配边都被消去)
![资源分配图简化](https://s1.ax1x.com/2020/10/21/BPfbKf.png)

- `可完全简化`：资源分配图中所有的进程都可以简化为孤立节点
- **死锁定理：** 系统为死锁状态的充分条件是：当且仅当该状态的`进程-资源分配图`是`不可完全简化的`

#### 死锁的解除
- `中止进程，强制回收资源`：哲学家问题(杀死一个哲学家)
- `剥夺资源，不中止进程`
- `进程回滚(Roll Back)`：哲学家问题(让一个哲学家放下一把叉子)
- `重新启动`：最有效但是是最终解决办法

**操作系统的办法：** 尽管发生死锁会导致进程占用的资源一直得不到释放，越来越多进程请求的资源无法分配，最终导致系统重启，但是死锁发生的概率很低，所以**大多数操作系统都是直接忽略死锁**


# 3. 内存

- `内存(Main Memory)`由许多字节的序列组成，每个字节都有它自己的地址
- **CPU根据指令寄存器PC的值去从内存中获取指令**，这些指令可能也会导致去内存中额外的读写操作
- **指令周期：**
  - `取指令`：根据PC值所示地址去内存取出对应指令到指令寄存器IR，PC+1
  - `解释指令`：将IR中的指令译成机器语言
  - `执行指令`
  - `存储结果`
- **分层存储体系：**
顶层存储器速度最快，但是相对容量最小，成本非常高
![分层存储体系](https://s1.ax1x.com/2020/10/22/Bidl0P.png)

- 操作系统中管理内存层次结构的部分成为`内存管理器(memory manager)`，主要工作是有效的管理内存，记录哪些内存是正在使用的，在进程需要时分配内存以及在进程完成时回收内存

## 3.1 地址空间
- `地址空间`创建了一种抽象内存供程序使用。地址空间是进程可以用来寻址内存的地址集合。每个进程都有自己的地址空间，独立于其他进程的地址空间

- **保护操作系统和用户进程：** 用户进程不可以访问操作系统内存数据，用户进程空间之间不能呼响影响。这是通过硬件实现的，因为操作系统不干预CPU对内存的访问
  - `基址寄存器`：base register，存储程序在内存中的起始位置
  - `变址寄存器`：limit register，存储应用程序的长度
  - 这两个寄存器的值只能被操作系统的`特权指令`加载(内核模式)，于是隔离了各个进程空间

- **逻辑地址和物理地址：** 逻辑地址面向程序，总是从0开始编址，就是相对于第一条指令的偏移量吗，所以也叫`相对地址`或者`虚拟地址`。物理地址是内存单元看到的实际地址，也成为`绝对地址`
- **逻辑地址空间和物理地址空间：** 所有逻辑地址的集合称为`逻辑地址空间`，这些逻辑地址对应的所有物理地址集合成为`物理地址空间`
- **逻辑地址转换为物理地址的时机：** 如果在编译时转换，则运行时不再允许移动。如果在加载时转换，也不能在运行时移动。所以是**在运行时转换**的，执行到哪条指令就把那条指令的逻辑地址换算成物理地址。这个转换由`内存管理单元(Memory-Management Unit)`通过`重定位寄存器(基址寄存器)`来完成

## 3.2 连续内存的分配
- 连续内存的分配可以采用`固定分区`方案和`可变分区`的方案
- 两种方式的地址转换方案都是相似的：物理地址=基址+逻辑地址
- 地址保护策略：与限长limit进行比较
- 两种方案都会产生`碎片`，碎片越来越小，难以被再利用
- **现代操作系统一般不采用连续内存分配**
### 3.2.1 固定分区
每个分区只能容纳一个进程，容易造成内存浪费，大内存进程可能没有可用的分区
![固定分区](https://s1.ax1x.com/2020/10/22/BFSd74.png)


### 3.2.2 可变分区
会形成孔洞。并且随着时间的推移，孔洞越来越多，大小也不固定
- 首次适应和最佳适应在空间利用率和执行效率上都优于最坏适应

![可变分区](https://s1.ax1x.com/2020/10/22/BFpbGR.jpg)

### 3.2.3 紧凑技术
- `内存紧缩(memory compaction)`可以解决碎片问题，将所有空闲区尽可能向下移动合并成一个大的空闲区
- 但是必须要保证程序的逻辑地址到物理地址的转换是在运行时，才能实施紧凑技术，同时该技术需要消耗很多的cpu时间，所以该技术通常不会使用

## 3.3 分段和分页技术
- 前提：**允许进程的地址空间不连续**
- **需要额外空间存储段表/页表，记录每个段/页的起始地址和限长**

### 3.3.1 分段技术
- 逻辑地址发生了改变，`逻辑地址=段号+段内地址`
- 分段的硬件，`段表：段号，段基址，段限长`
- 首先根据逻辑地址的段号去段表找对应段号，**比较段内地址是否超过段限长**，未超过则用段基址加上段内地址，得到物理地址
- **原理和连续内存的可变分区类似，虽然内存分的更细了，但是段和段之间依然会产生外部碎片**
![分段技术](https://s1.ax1x.com/2020/10/22/BFhLyq.png)

### 3.3.2 分页技术
- 和固定分区类似，将内存分为很多个**大小相等**的分区`(页框/帧 fram)`，将进程分为多个和页框相等的`页(page)`，离散的存放到页框中
- linux的页框大小/页面大小为4KB： `getconf PAGESIZE命令`
- linux页面大小4KB占12位，64位系统而言，实际上现在只用了48位，所以页号48-12=36位
- `PTBR(page-table base register)`寄存器存放了当前进程的页表所在位置，进程切换的时候只需要修改PTBR的值就完成了页表的切换，减少了开销，但是需要访问两次内存！(第一次获得页表，第二次获得物理地址)

![分页技术](https://s1.ax1x.com/2020/10/22/BkZvzF.png)

![分页技术2](https://s1.ax1x.com/2020/10/22/Bkeaes.png)


<center>

|分段|分页|
|---|---|
|信息的逻辑单位|信息的物理单位|
|段长是任意的|页长由系统确定|
|段的起始地址可以从主存任一地址开始|页框起始地址只能以页框大小的整数倍开始|
|(段号，段内位移)构成了二维地址空间|(页号，页内位移)构成了一维地址空间|
|**会产生外部碎片**|**消除了外部碎片，但会出现内部碎片**|
</center>

### 3.3.3 加速分页
**快表：**
- 缓存的思想
- `TLB(Translation Look-aside Buffer)`是一个缓存，TLB包含了一部分页表的内容(不止一个进程的)，CPU先检查TLB是否有该逻辑地址，未命中才去访问内存
- TLB中的页表项就是`快表`
- 缓存的依据是程序的`局部性原理`：
  - `时间局部性：`某信息被访问，不久的将来极可能被访问多次
  - `空间局部性：`某信息被访问，和它相邻的信息也极有可能被访问
  - `内存局部性：`访问内存时，大概率会访问连续块(空间局部性在内存的体现)
  - `分支局部性：`大部分指令都是顺序执行的。顺序：非顺序 ≈ 5：1
  - `等距局部性：`某位置被访问，和它相邻等距离的连续地址极有可能被访问
- 缓存被修改后需要保持与内存的一致性：
  - `直接写(Write through)`：修改缓存数据的同时修改内存数据
  - `回写(Write back)`：只修改缓存(dirty data)，直到缓存中该数据要被清除时才把dirty data回写到内存

**多级页表：**
- 页表过大时，对连续的页表进行再页表
![多级页表](https://s1.ax1x.com/2020/10/23/BkoYIf.png)



### 3.3.4 页的保护和共享
- 页的保护：为了防止地址转换时出现异常，可以在页表的每个条目设置一个`valid/invalid`比特位，用于表示该页的有效性。还可以扩展为表示可读、可写、可执行等

- 页的共享：页框为多个进程共享。只有只读的text代码区才能共享，数据区data是不能共享的

### 3.3.5 虚拟内存
- 虚拟内存技术允许进程执行时不需要全部装入内存
- 程序可以比物理内存更大
- 将主内存抽象为了一个及其大的以字节为单位的存储器，将物理内存和逻辑内存分离开来，不用再去关心物理内存的限制
- 虚拟内存技术会导致缺页，执行缺页中断，去磁盘中调页，而这将会花费几十倍的时间。如果调页时发现内存中已经没有空闲的页框可用，就要采用`页面置换算法`

<center>

![请求调页](https://s1.ax1x.com/2020/10/23/BAdcM4.png)
</center>

### 3.3.6 页面置换算法
- 当进程在执行过程中发生了缺页，在请求调页时发现内存中已经没有空闲页框可用，操作系统就会做`页面置换` 
- 页面置换算法和Cache-memory的置换方法都类似的

#### FIFO
- 淘汰最先进入内存的页面，因为它在内存中待的时间最久

#### LRU
- 淘汰最近最少使用的页面，近似的最优页面置换算法


#### 最优页面置换算法
- 总是淘汰最长时间不会再使用的页面
- 无法实现。。。。。

#### 二次机会页面置换算法
- 基于FIFO，检查最老页面的标志位，如果是0，说明经过一轮之后依然没有被使用，直接淘汰并插入新页面，如果是1，置0并重新像新的一样加入到队列尾部，重复
- 缺点：链表中移动页面降低了效率

#### 时钟页面置换算法
- 改进的二次机会页面置换算法
- 将所有页面保存在环形链表中，一个指针指向最老的页面
- 当发生缺页错误时，检查指针指向的页面，如果是0，淘汰并插入新页面，如果是1，修改为0，并让指针前进一位，直到找到R位为0的页面
![时钟页面置换算法](https://s1.ax1x.com/2020/10/23/BAhofe.png)

### 3.3.7 抖动
- 如果进程运行时需要进行页面置换，而被置换的页面接下来也要被使用，这样高频率的调入调出称为`抖动`，抖动时进程花在调页的时间比执行时间还长
- 抖动的原因：并发进程数量过多，进程页框的分配不合理
- 抖动的结局方案：根据进程的抖动频率来动态的调节分配给进程的页框数量

# 4. 文件系统
## 4.1 文件

## 4.1.1 文件
- `文件`是信息的逻辑存储单位，提供了一种方式用来存储不同类型的信息以及在后面进行读取
- 文件是`按名存取`的：文件名，文件类型，位置，大小，时间和用户标识，保护
- 文件占用磁盘的空间比文件本身的大小要大一点
- `UNIX文件区分大小写`，`MS-DOS系统不区分大小写`
- 一般地，操作系统至少要能解释`文本文件`和`二进制可执行文件`
- 文件系统包含两个部分：`文件`和`目录`
- 文件打包之后再存入硬盘的sector，读取的时候一次也要读取一个sector，然后进行拆包

![文件的内部结构](https://s1.ax1x.com/2020/10/24/BZqWa4.png)

## 4.1.2 文件的访问方法
- `顺序访问`：文件信息按顺序排序，读取/写入当前文件信息后，将文件指针移向下一个邻接区域
- `直接访问`：若文件的`逻辑记录(logical record)`长度固定，就可以允许在访问文件信息时按任意顺序进行快速读取和写入。如要访问从起始位置第N个逻辑记录：`文件地址=文件起始位置+N*逻辑记录大小`


## 4.1.3 链接
- 链接分为`硬链接(hard link)`和`软连接/符号链接(symbol link)`
- 创建硬链接`ln filename linkname`
- 创建软连接`ln -s filename linkname`
- **硬链接的inode和原文件是一样的，会增加Links属性值**，作用是允许一个文件拥有多个有效路径名，防止误删。**删除的只是一个连接**，并不影响文件本身和其他链接，只有当**最后一个连接被删除后**，文件的数据块及目录的连接才会被释放，**文件才会被真正删除**。`完全等同原文件`
- **软链接的inode和原文件是不一样的**，实际上是相当于是快捷方式，对软连接的修改相当于对原文件修改，原文件删除之后软连接访问就报错了。`相当于快捷方式`
- 硬链接不能跨文件系统(分区)，不能链接目录，用的比较少
![软链接](https://s3.ax1x.com/2020/11/14/DCOEx1.png)


## 4.2 目录 

- 文件系统通常提供`目录(directories)`或者`文件夹(folders)`用于记录文件的位置
- 根目录和层次目录系统：

![层次目录](https://s1.ax1x.com/2020/10/24/BZLWOf.png)

- 文件访问控制：基于身份的控制
  - 用户类型：Owner/Group/Other
  - 三种访问权限：r, w, x
  - 每个文件的`访问控制列表(ACL)`有9bits来标识访问控制权限
- 低级格式化(出厂)：划分磁道和扇区
- 高级格式化(用户)：构建一个文件系统

### 4.2.1 引导块
- 整个引导块占4KB，从磁盘上的字节偏移量0开始，引导块可用于启动操作系统
![引导块](https://s1.ax1x.com/2020/10/24/BZxVxA.png)

**MBR**
- 磁盘可以划分出多个`磁盘分区`，每个分区都有独立的文件系统，每个分区的文件系统可以不同。磁盘的0号分区成为`主引导记录(Master Boot Record, MBR)`，用来引导计算机。 `MBR`是硬盘驱动器上的第一个扇区，包含了`引导程序代码(440B)`和`其他信息(6B)`

**超级块**
- 超级块4KB，从磁盘上的字节的偏移4096开始，超级块包含文件系统的所有关键参数：`文件系统的大小`、`文件系统的数据块数`、`指示文件系统状态的标志`、`分配组大小`
- 在计算机启动或者文件系统首次使用时超级块会被读入内存

**空闲空间块**
- 文件系统中的`空闲块`的信息。可以用位图或者指针列表的形式给出
- BitMap位图：每个位对应一个磁盘块，为1表示是一个空闲块，为0表示是已分配块
- 链表：将空闲块链接在一起，一个空闲块包含指向下一个空闲块的指针

**inode**
- `inode(index node)`也成为索引节点。是一个数组的结构，每个文件都有一个inode，说明了文件的各方面信息，可以使用`ls -lai`查看。inode节点主要包括了以下信息：`文件类型`，`权限`，`硬链接数`，`所有者id`，`group id`，`文件大小`，`15个block地址的数组`，`最后访问时间atime`，`内容修改时间mtime`，`inode修改时间ctime`

**根目录**
- 存放文件系统目录树的根部

最后，磁盘的其他部分存放了其他所有的目录和文件

## 4.3 文件系统的实现
常见的基于磁盘的文件系统：
- UNIX：UFS
- Windows：FAT, FAT32, NTFS
- Linux：ext3, ext4
- maxOS：AFS

**文件系统实现的需求**

![文件系统的需求](https://s1.ax1x.com/2020/10/25/BeX81A.png)

### 4.3.1 文件目录的实现
- 文件系统通过`文件控制块(File Control Block)`来维护文件结构，FCB包含有关文件的信息：所有者，权限，文件位置等 
- 每个文件目录项对应一个FCB

**Linux文件目录的实现：**
- UFS中的FCB被成为索引节点 inode，每个inode对应一个唯一的编号
- inode包含：`文件类型`，`权限`，`硬链接数`，`所有者id`，`group id`，`文件大小`，`15个block地址的数组`，`最后访问时间atime`，`内容修改时间mtime`，`inode修改时间ctime`
- **inode中不包含文件名**
- **UFS的entry包含文件名和inode number**，目录项长度固定，简洁，根据文件名获得inode编号，读取inode
![UFS的inode](https://s1.ax1x.com/2020/10/25/Bexn00.png)

### 4.3.2 磁盘空间分配方法
- `连续分配`：每个文件在磁盘上占用连续的物理块。 简单便于计算，但是会产生外部碎片，而且文件内容的增加不方便
- `链接分配`：文件所占物理分块分散在磁盘的不同位置，通过指针将它们连接起来。 这样没有碎片，但是会导致一部分的空间浪费(存储head，tail，next)，而且有断链风险，只支持顺序访问

![FAT](https://s1.ax1x.com/2020/10/25/BmeDXV.png)

- `簇(Cluster)`：一组物理块的集合，以簇为单位分配block，可以节省指针占用的空间比例。
- `索引分配`：将文件占用的所有物理块号按逻辑顺序保存在索引表中，存有索引表的物理块称为索引块。可以实现随机访问，但是索引块占用空间，造成空间的浪费，而且不好提前预知索引块需要多少的空间

![UFS索引块](https://s1.ax1x.com/2020/10/25/Bmufpj.jpg)

### 4.3.3 空闲空间管理
可以用位图或者指针列表的形式给出
- BitMap位图：每个位对应一个磁盘块，为1表示是一个空闲块，为0表示是已分配块
- 链表：将空闲块链接在一起，一个空闲块包含指向下一个空闲块的指针

# 5. I/O

## 5.1 I/O设备
- `总线(Bus)`：一组线路和通过线路传输信息的一个协议。`并行总线(Multiple Lane)`，`串行总线(Single Lane)`。PCIe总线，USB总线是串行总线   

- `设备控制器(Controller)`：设备控制器是处理CPU传入和传出信号的系统，可以操控一个端口，从连接的设备处接收数据，并将其存储在控制器内部的一些特殊目的寄存器也就是本地缓冲区中
- 每个设备控制器都有一个应用程序与之对应，设备控制器通过应用程序(驱动)的接口通过中断与操作系统进行通信。
![设备控制器](https://s1.ax1x.com/2020/10/26/BnYjNn.png)

- `I/O地址`：控制寄存器的地址
- `编址方式`：
  - `I/O独立编址`：使用独立的I/O指令，如IN，OUT
  - `内存映射编址`：画出一块内存地址，将I/O端口地址映射进来，这样就可以使用访问内存指令对控制寄存器进行读写

## 5.2 I/O控制方式
- `轮询`：`忙式等待`，重复测试控制器中的状态寄存器的busy位，直到为0，然后设置控制寄存器为工作位，设置状态位ready，执行操作，清除状态位。
- `中断`：
![中断IO](https://s1.ax1x.com/2020/10/26/Bn0IaD.png)

- `直接内存访问DMA`：真正的异步
![DMA](https://s1.ax1x.com/2020/10/26/BnBKJJ.png)
当DMA和CPU竞争内存总线时的：
  - 周期窃取：CPU暂时停止访问内存。DMA窃取一个总线周期

## 5.3 内核I/O结构的设计
主要目标：`高效率`，`通用性`
![IO的层次结构](https://s1.ax1x.com/2020/10/26/BuEo7D.png)

- `缓冲和缓存`：缓冲解决速度不匹配问题，并不会提高访问速度，缓存可以提高访问速度，而且修改之后需要回写

![IO生命周期](https://s1.ax1x.com/2020/10/26/BueghQ.png)