# 数据库

- 常见的数据库：Oracle、MySQL、SQLServer、DB2、MongoDB、SQLite、Redis 
- 关系型数据库：MySQL、Oracle、SQLServer等，数据之间有关联关系，数据存储在**硬盘**的文件上
- 非关系型数据库：MongoDB、Redis等，数据之间没有关联关系，数据存储在**内存**中

关系型数据库中，数据组置涉及到两个最基本的结构：**表**和**索引**
表中存储的是完整的记录，按**堆表**(无序存储，如Oracle，DB2，PostegreSQL)或者**聚簇索引表**(按主键排序存储)
索引中存储的是完整记录的一个子集，用于加速查询，索引的组织形式一般是B+树

# 1. MySQL     


## 1.1 MySQL基础    

### 1.1.1 mysql基本配置
- 配置my.ini
~~~

//设置 mysql 客户端默认字符集  
default-character-set=utf8 

//设置 3306 端口  
port = 3306  

//设置 mysql 的安装目录  
basedir=D:\Program Files\mysql-5.7.31-winx64

//设置 mysql 数据库的数据的存放目录  
datadir=D:\Program Files\mysql-5.7.31-winx64\data 

//允许最大连接数  
max_connections=200  

//服务端使用的字符集默认为 8 比特编码的 latin1 字符集  
character-set-server=utf8  

//创建新表时将使用的默认存储引擎  
default-storage-engine=INNODB
~~~

- 启动服务： net start mysql        
- 登录： `mysql -uroot -proot` //连接本地数据库，密码默认为 root，mysql -u <用户名> -p <密码>                
 `mysql -h <ip> -P <port> -u <username> -p <password>`   //连接网络数据库      
- 设置密码： ALTER USER 'root'@'localhost' IDENTIFIED BY 'new_password';        
- 退出：quit
- 停止服务：net stop mysql      
- 备份数据库：mysqldump -u用户名 -p密码 数据库名 > 保存的路径        
- 还原数据库: 登陆创建使用数据库，执行文件： source 文件路径
- 查看数据库版本：`select version();`
- 显示所有数据库：`show databases;`
- 显示当前数据库所有表：`show tables`
- 显示指定数据库的所有表：`show tables from <database>`
- 查看当前数据库支持的存储引擎：`show engines`
- 查看系统变量及其值：`show variables`
- 查看某个系统变量：`show variables like <变量名>` 如`show variables like 'port';`
### 1.1.2 sql语句介绍
SQL : Structured Query Language 结构化查询语言，定义了操作所有关系型数据库的规则        

- SQL语句可以多行书写，**分号结尾**        
- MYSQL 数据库的 SQL 语句**不区分大小写**，关键字建议使用大写       
- 单行**注释**： -- 单行注释 或者 # 单行注释 （--之后必须加空格，#之后可以不加空格）
- 多行注释：/* 多行注释 */

**SQL操作的分类**       
- **DDL(data define language)：** DDL是数据库定义语言，用来定义数据库对象：数据库、表、列等           
关键字：create、drop、alter等  
- **DML(data manipulation language)：** DML是数据库操作语言，用来对数据库表中的数据进行增删改           
关键字：insert、delete、update等  
- **DQL(data query languafe)：** DQL是数据库查询语言，用来查询数据库中表的记录(数据)     
关键字：select、where等
- **DCL(data control language)：** DCL是数据库控制语言，用来定义数据库的访问特权和安全级别，以及创建用户           
关键字：GRANT、REVOKE等

### 1.1.3 mysql数据类型
mysql有四种数据类型
- **整数类型：** bit, bool, tinyint, smallint, mediumint, int, bigint
- **浮点数类型：** float, double, decimal
- **字符串类型：** char, varchar, tinyblob, blob, mudiumblob, longblob, tinytext, text, mediumtext, longtext
- **日期类型：** Date, DateTime, TimeStamp, Time, Year

1. 整数类型

|类型	        |大小	    |范围（有符号）  |范围（无符号）        |用途
|---|----|---|---|---|
|TINYINT	    |    1byte	|$(-2^7, 2^7-1)$      |       $(0, 2^8-1)$	 |小整数值
|SMALLINT	    |2bytes	|$(-2^{15}, 2^{15}-1)$|  $(0, 2^{16}-1)$	 |大整数值
|MEDIUMINT	    |3bytes	|$(-2^{23}, 2^{23}-1)$|$(0, 2^{24}-1)$| 大整数值
|INT或INTEGER	|4bytes	|$(-2^{31}, 2^{31}-1)$|$(0, 2^{32}-1)$  |大整数值
|BIGINT	        |8bytes	|$(-2^{63}, 2^{63}-1)$|$(0, 2^{64}-1)$	|极大整数值


`int(N)` 无论N等于多少，int永远占4字节，N表示宽度，不足用0不足，但是要设置zerofill
~~~
mysql> CREATE TABLE test3 (
    -> `a` int,
    -> `b` int(5),
    -> `c` int(5) unsigned,
    -> `d` int(5) zerofill,
    -> `e` int(5) unsigned zerofill,
    -> `f` int zerofill,
    -> `g` int unsigned zerofill
    -> );
Query OK, 0 rows affected (0.35 sec)

mysql> insert into test3 values (1,1,1,1,1,1,1),
    -> (11,11,11,11,11,11,11),(12345,12345,12345,12345,12345,12345,12345);
Query OK, 3 rows affected (0.08 sec)
Records: 3  Duplicates: 0  Warnings: 0

mysql> select * from test3;
+-------+-------+-------+-------+-------+------------+------------+
| a     | b     | c     | d     | e     | f          | g          |
+-------+-------+-------+-------+-------+------------+------------+
|     1 |     1 |     1 | 00001 | 00001 | 0000000001 | 0000000001 |
|    11 |    11 |    11 | 00011 | 00011 | 0000000011 | 0000000011 |
| 12345 | 12345 | 12345 | 12345 | 12345 | 0000012345 | 0000012345 |
+-------+-------+-------+-------+-------+------------+------------+
3 rows in set (0.00 sec)
~~~

2. 浮点数类型

|类型	        |大小	    |范围（有符号）  |范围（无符号）|用途
|---|----|---|---|---|
|FLOAT|4 bytes|---|---|单精度浮点数|
|DOUBLE|8 bytes|---|---|双精度浮点数|
|DECIMAL|DECIMAL(M,D)<br>M>D为M+2否则为D+2|依赖于M和D|依赖于M和D|小数值|

`float(5,2)`表示总共5位(包括小数点)，保留两位小数
`但是decimal是四舍五入，float和double是四舍六入五成双`(是5的时候永远将最后一位凑双)
`如果decimal不写精度，会四舍五入为整数，float和double不写精度会正常显示`
除此之外，float和double的sum会存在精度问题，而decimal不会，银行等对结果要求精准的要采用decimal

3. 字符串类型

|类型	    |大小	                |用途
|---|---|---
|CHAR	    |0-255 bytes	        |    定长字符串
|VARCHAR	|0-65535 bytes	        |    变长字符串
|TINYBLOB	|0-255 bytes	        |    不超过 255 个字符的二进制字符串
|TINYTEXT	|0-255 bytes	        |    短文本字符串
|BLOB	    |0-65 535 bytes	        |二进制形式的长文本数据
|TEXT	    |0-65 535 bytes	        |长文本数据
|MEDIUMBLOB	|0-16 777 215 bytes	    |二进制形式的中等长度文本数据
|MEDIUMTEXT	|0-16 777 215 bytes	    |中等长度文本数据
|LONGBLOB	|0-4 294 967 295 bytes	|二进制形式的极大文本数据
|LONGTEXT	|0-4 294 967 295 bytes	|极大文本数据

4. 日期类型

|类型	    |大小|范围|格式	                |用途
|---|---|---|---|---
|DATE|	3bytes	|1000-01-01/9999-12-31|	YYYY-MM-DD	|日期值
|TIME|	3bytes|	'-838:59:59'/'838:59:59'|	HH:MM:SS	|时间值或持续时间
|YEAR|	1byte|	1901/2155|	YYYY|	年份值
|DATETIME|	8bytes|1000-01-01 00:00:00/<br>9999-12-31 23:59:59|YYYY-MM-DD HH:MM:SS|混合日期和时间值
|TIMESTAMP|	4bytes|1970-01-01 00:00:00/2038-1-19 11:14:07(北京时间)<br>结束时间是第 2147483647 秒|YYYYMMDD HHMMSS|	混合日期和时间值，时间戳


## 1.2 SQL语法

### 1.2.1 DDL(data define language)
1. **C(Create)**        
    - 创建数据库
        ~~~sql
        CREATE DATABASE [IF NOT EXISTS] 数据库名 [CHARACTER SET 字符集];  

        //创建数据库的通用写法：
        drop database if exists 库名;
        create database 库名;
        ~~~
    - 创建表
        ~~~sql
        CREATE TABLE 表名(
            列名1 数据类型1 [(宽度)] [约束条件] [comment '字段说明'],
            列名2 数据类型2, 
            ...     //最后一个字段不能加逗号
            )[表的一些设置];
        ~~~ 
        ~~~
        //例如
        mysql> create table test1(
            -> a int not null comment '字段a',
            -> b int not null default 0 comment '字段b' primary key,
            -> );

        //另一种primary key的限定方式
        mysql> create table test2(
            -> a int not null comment '字段a',
            -> b int not null default 0 comment '字段b',
            -> primary key(a)
            -> );
        
        //foreign key的用法
        mysql> create table test5(
            -> a int not null comment '字段a' primary key
            -> );
        Query OK, 0 rows affected (0.02 sec)
        mysql> create table test6(
            -> b int not null comment '字段b',
            -> ts5_a int not null,
            -> foreign key(ts5_a) references test5(a)
            -> );
        ~~~
        常用约束：not null、default 默认值、primary key、foreign key、unique key、auto_increment 
    - `CREATE TABLE name1 like name2;` 按表2的样式创建一个表1，复制表结构
    - `CREATE TABLE name1 as SELECT 字段 from 被复制表 [where..];` 按条件复制
        ~~~
        mysql> create table test1_copy as select * from test1;
        ~~~   

2. **R(Retrive)**  
    - `SHOW DATABASES;`  查询所有数据库的名称
    - `SHOW CREATE DATABASE 数据库名称;`  查询数据库的创建语句
    - `SHOW TABLES;`  查询数据库中所有的表  
    - `DESC 表名;` 或者 `DESCRIBLE 表名;`  查询表的结构
3. **U(update)**  
    - `ALTER DATABASE name character set UTF8;`
    - `ALTER TABLE 表名 rename name1;`  修改表名
    - `ALTER TABLE 表名 character set utf8;`  修改表的字符集
    - `ALTER TABLE 表名 add 列名 数据类型;`  添加一列
    - `ALTER TABLE 表名 change 原列名 新列名 数据类型;`  修改列名和类型
    - `ALTER TABLE 表名 modify 列名 数据类型;`  修改列的数据类型
    - `ALTER TABLE 表明 drop 列名;`   删除列
4. **D(DELETE)**       
    - `DROP DATABASE [IF EXISTS] name;`
    - `DROP TABLE [IF EXISTS] name;`
5. **使用数据库**           
    - 查询正在使用的数据库名称: `SELECT DATABASE();`
    - 使用数据库：`USE name`

### 1.2.2 DML(data manipulation language)
DML是数据库操作语言，用来对数据库表中的数据进行增删改           
1. 添加数据：       
    - `INSERT INTO 表名[(列名1,列名2,...)] values(值1,值2,...),(值1,值2,...);`  如果表明之后不写列名默认给所有列添加数据(未知为NULL)        
    
2. 删除数据：
    - `DELETE FROM 表名 WHERE 条件;`    不加条件则删除表中全部数据，但是一条一条执行删，效率低      
    - `TRUNCATE 表名;`    删除表并创建一个一模一样结构的表(相当于删除全部记录，比上面的删效率高)     
    - **注意：** **delete语句是数据库操作语言DML**，操作会放到rollback segement中，**事务提交之后才生效**。**truncate、drop是数据库定义语言DDL**，操作立即生效，**不能回滚**
3. 修改数据：
    - `update 表名 [as 别名] set [别名.]列名1=值1, 列名2=值2,... [WHERE 条件];`  不加条件则把所有数据对应列都修改

### 1.2.3 DQL(data query languafe)      
DQL是数据库查询语言，用来查询数据库中表的记录(数据)     

查询常量和表达式：
~~~
mysql> select 1,'b';
+---+---+
| 1 | b |
+---+---+
| 1 | b |
+---+---+
1 row in set (0.01 sec)

mysql> select 1+2,3*10,10/3;
+-----+------+--------+
| 1+2 | 3*10 | 10/3   |
+-----+------+--------+
|   3 |   30 | 3.3333 |
+-----+------+--------+
1 row in set (0.01 sec)
~~~

- `SELECT * FROM 表名;`
- `SELECT DISTINCT ...` 去重查询
~~~sql   
SELECT name AS 名字,   --起别名(AS可省略)
      math 数学, 
      english 英语, 
      IFNULL(math, 0) + IFNULL(english,0) 总分 -- 计算两者的行和,处理NULL，起别名
FROM student;
~~~
#### 条件查询
    
- WHERE条件：
`>, <, >=, <=, =, <>, !=`：<> 和 != 都是不等于，<>可移植性好，一般用<>
`BETWEEN...AND...`：介于二值之间 
`IN(集合)`：相当于多个 OR
`NOT IN(集合)`：和in正好相反
`LIKE`：模糊查询，**占位符 _(单个任意字符), %(多个任意字符)**
`IS　NULL`：查询NULL 只能用 IS 和 IS NOT 不能用 = 和 != 
`AND &&`
`OR ||`
`NOT !`
- `UNION` 操作符: 用于连接两个以上的 SELECT 语句的结果 组合到一个结果的集合中，多个SELECT 语句会删除重复的数据   
- **NULL值，通过>,>=,like '%'，in(NULL), not in, between等都查询不到**，只能通过`IS NULL`和`IS NOT NULL`或者安全等于`<=>`(安全等于用的少)

#### 函数
- `COUNT` 计算个数(排除NULL)
~~~sql
SELECT COUNT(id) FROM student WHERE score>92;
~~~
- `MAX`
- `MIN`
- `SUM`
- `AVG`
- `MOD`
- `abs`,`sqrt`
- `ceil`,`floor`
- `rand()` 生成一个0~1之间的随机数
- `pow`,`sin`,`asin`...
- `isnull(a)` 判断a的参数是否为空，为空返回1，不为空返回0
- `ifnull(a,b)` 如果a的参数是空则返回为b值
~~~sql
CASE [<表达式>]
    WHEN <条件1> 
        THEN <操作1> 
    WHEN <条件2> 
        THEN <操作2> 
    ...
    ELSE <操作>
END CASE;
~~~
- CASE的使用，如
~~~
mysql> SELECT
    t.name 姓名,
    (CASE t.sex
    WHEN 1
        THEN '男'
    WHEN 2
        THEN '⼥'
    ELSE '未知' END) 性别
    FROM t_stu t;
~~~

- 其他的mysql系列函数：
~~~
select version();  //查询当前版本
select database(); //查询当前数据库
select user();     //查询当前用户
select password('pw') //查询字符串的密码形式
select md5('str')  //查询指定str的md5码
~~~
#### 排序查询
    
- `SELECT * FROM 表名 ORDER BY 排序字段1 [asc|desc], 排序字段2 [asc|desc],...;`  排序方式: ASC(默认)、DESC。多字段排序时按照顺序进行
~~~
mysql> select * from stu order by age desc,id asc;
+------+-----+---------------+
| id | age | name |
+------+-----+---------------+
| 1004 | 20 | 张国荣 |
| 1005 | 20 | 刘德华 |
| 1010 | 19 | 梁朝伟 |
| 1001 | 18 | 路⼈甲Java |
| 1003 | 18 | 张学友 |
+------+-----+---------------+
5 rows in set (0.00 sec)
~~~
**注意：排序中存在相同的值时，需要再指定⼀个排序规则，通过这种排序规则不存在⼆义性，否则分页结果对相同值会存在混乱，每次分页结果不一致** 

#### 分页查询
- `LIMIT 开始的索引,每页条目数`   MySQL的语法，开始的索引=(页码-1)*每页条目数
~~~sql
SELECT * FROM student LIMIT 0,3;    -- 第一页
SELECT * FROM student LIMIT 3,3;    -- 第二页
SELECT * FROM student LIMIT 6,3;    -- 第三页
~~~

**注意：排序中存在相同的值时，需要再指定⼀个排序规则，通过这种排序规则不存在⼆义性，否则分页结果对相同值会存在混乱，每次分页结果不一致**

#### 分组查询
- 聚合函数(group_function)：`max`，`min`，`count`，`sum`，`avg`
~~~sql
SELECT  column, 
        group_function,
        ... 
FROM    table 
WHERE   ... 
GROUP BY group_by_expressin 
HAVING  [group_condition]   //分组后数据过滤
~~~

**注意：SELECT后面的列只能有两种：出现子啊GROUP BY后面的列和使用聚合函数的列**，不能再使用其他的列作为查询结果

- 多字段分组
~~~sql
//查询每个⽤户每年下单数量，输出字段：⽤户id、年份、下单数量
mysql> SELECT
            user_id ⽤户id, the_year 年份, COUNT(id) 下单数量
        FROM
            t_order
        GROUP BY user_id , the_year;
+----------+--------+--------------+
| ⽤户id | 年份 | 下单数量 |
+----------+--------+--------------+
| 1001 | 2017 | 1 |
| 1001 | 2018 | 2 |
| 1002 | 2018 | 3 |
| 1002 | 2019 | 1 |
| 1003 | 2018 | 1 |
| 1003 | 2019 | 1 |
+----------+--------+--------------+
6 rows in set (0.00 sec)
~~~

- 分组前筛查
~~~sql
//需要查询2018年每个⽤户下单数量，输出：⽤户id、下单数量
mysql>  SELECT
            user_id ⽤户id, COUNT(id) 下单数量
        FROM
            t_order t
        WHERE
            t.the_year = 2018
        GROUP BY user_id;
~~~

- 分组后筛查

~~~sql
//查询2018年订单数量⼤于1的⽤户，输出：⽤户id，下单数量
mysql>  SELECT
            user_id ⽤户id, COUNT(id) 下单数量
        FROM
            t_order t
        WHERE
            t.the_year = 2018
        GROUP BY user_id
        HAVING count(id)>=2;
~~~

- **where和having的区别：** where在分组前筛查，having在分组后筛查；**where的条件不能有聚合函数**

- `WITH ROLLUP` : 可以对分组统计的数据的基础上再进行相同的统计
~~~sql
mysql> SELECT name, SUM(singin) as singin_count FROM  employee_tbl GROUP BY name WITH ROLLUP;
+--------+-------------+
| name   | sum(singin) |
+--------+-------------+
| 小丽   |           2 |
| 小明   |           7 |
| 小王   |           7 |
| NULL   |          16 |
+--------+-------------+
~~~

#### 查询总结

~~~sql
SELECT
    字段列表
FROM
    表名列表
WHERE
    条件列表
GROUP BY
    分组字段
HAVING
    分组后的条件限定
ORDER BY
    排序
LIMIT
    分页限定
~~~


### 1.2.4 DCL(data control language)
DCL是数据库控制语言，用来定义数据库的访问特权和安全级别，以及创建用户              

1. 管理用户：

    - 添加用户：`CREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';`   
        (主机名：localhost表示本地登陆，% 表示外部任意主机可以登陆)
    - 查询用户：`SELECT * FROM USER;`  
    - 删除用户：`DROP USER '用户名'@'主机名';`  
    - 修改用户密码：            
    `UPDATE USER SET PASSWORD = PASSWORD('新密码') WHERE USER = '用户名';`          
    `SET PASSWORD FOR '用户名'@'主机名' = PASSWORD('新密码');`   
    - 忘记root密码？            
    重新使用无验证方式启动MySQL服务：`mysql --skip-grant-tables`        
    打开新的命令行直接使用命令`mysql`即可登陆数据库             
    `USE mysql`         
    `UPDATE USER SET PASSWORD = PASSWORD('新密码') WHERE USER = '用户名';`      
    任务管理器结束mysql服务，重新登陆即可       

2. 授权：
    - 查询权限：`SHOW GRANTS FOR '用户名'@'主机名';`  
    - 授予权限：            
    `GRANT 权限列表 ON 数据库名.表名 TO '用户名'@'主机名'`          
    `GRANT ALL ON *.* TO '用户名'@'主机名'`  :给予全部权限
    - 撤销权限：`REVOKE 权限列表 ON 数据库名.表名 FROM '用户名'@'主机名'`
    - 授予远程访问的所有权限：` grant all privileges on *.* to 'root'@'%' identified by 'root';`或者` grant all privileges on *.* to 'root'@'%' with grant option;`
    - mysql8开始不能再隐式使用grant命令创建用户，应该：
~~~sql
mysql> CREATE USER 'root'@'%' IDENTIFIED BY 'root';
mysql> GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;
~~~


### 1.2.5 连接操作
- `INNER JOIN`（内连接,或等值连接）：获取两个表中字段匹配关系的记录，也可以省略 INNER，只写 JOIN
- `LEFT JOIN`（左连接）：获取左表所有记录，即使右表没有对应匹配的记录
- `RIGHT JOIN`（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录
- 连接条件用 `ON` 表示，例如：
    ~~~sql
    SELECT a.id, a.name, b.main_teacher FROM student a INNER JOIN class b ON a.classid=b.classid
    ~~~

### 1.2.6 NULL
NULL的查询处理
- `IS NULL` : 当列的值是NULL 时返回true
- `IS NOT NULL` 
- `<=>` : 比较操作符，当二者值相等或都等于NULL时返回true        
- `IFNULL(列名, 新值)`      
---

- 比较运算中的NULL：任何数和NULL比较、运算、in 结果都是NULL
~~~sql
mysql> select 1>NULL, 1<NULL, 1<>NULL;
+--------+--------+--------+
| 1>NULL | 1<NULL | 1<>NULL |
+--------+--------+--------+
|   NULL |   NULL |   NULL |
+--------+--------+--------+
1 row in set (0.00 sec)

mysql> select NULL=NULL,NULL!=NULL;
+-----------+------------+
| NULL=NULL | NULL!=NULL |
+-----------+------------+
|      NULL |       NULL |
+-----------+------------+
1 row in set (0.00 sec)

mysql> select 1 in (null),1 not in (null),null in (null),null not in (null);
+-------------+-----------------+----------------+--------------------+
| 1 in (null) | 1 not in (null) | null in (null) | null not in (null) |
+-------------+-----------------+----------------+--------------------+
|        NULL |            NULL |           NULL |               NULL |
+-------------+-----------------+----------------+--------------------+
1 row in set (0.00 sec)
~~~

- IN和NULL：当IN和NULL比较时，无法查询出为NULL的记录。
~~~sql
mysql> select * from test1 where a in (null,1);
+------+------+
| a    | b    |
+------+------+
|    1 |    1 |
|    1 | NULL |
+------+------+
2 rows in set (0.00 sec)
~~~
- NOT IN 和 NULL：当NOT IN 后面有NULL值时，不论什么情况下，整个sql的查询结果都为空
~~~sql
mysql> select * from test1 where a not in (null,2);
Empty set (0.00 sec)
~~~

- 聚合函数和NULL：count(属性)不能统计NULL，而COUNT(*)可以统计NULL
~~~sql
mysql> select count(a),count(b),count(*) from test1;
+----------+----------+----------+
| count(a) | count(b) | count(*) |
+----------+----------+----------+
|        2 |        1 |        3 |
+----------+----------+----------+
1 row in set (0.00 sec)
~~~

### 1.2.7 子查询
按结果集的行列数分为四种
1. **标量子查询**：结果集只有一行一列
2. **列子查询**：结果集只有一列多行
3. **行子查询**：结果集只有一行多列
4. **表子查询**：结果集为多行多列

按子查询出现的位置，分为四种
1. **select后面**：只支持标量子查询
2. **from后面**：支持表子查询
3. **where或having后面**：支持标量子查询、列子查询、行子查询
4. **exists后面**：支持表子查询

#### select后的子查询
只支持标量子查询
~~~sql
//查询每个部门的员工数
SELECT
    a.*,
    (SELECT count(*)
    FROM employees b
    WHERE b.department_id = a.department_id) AS 员⼯个数
FROM departments a;

//查询员⼯号=102的部门名称
SELECT (SELECT a.department_name
        FROM departments a, employees b
        WHERE a.department_id = b.department_id
        AND b.employee_id = 102) AS 部门名;
~~~

#### from后的子查询
支持表子查询
要求from后的子查询必须起别名，否则找不到这个表，然后将真实的表和子查询结果表进行连接查询

~~~sql
//查询每个部门平均工资的工资等级
SELECT
  t1.department_id,
  sa AS '平均工资',
  t2.grade_level
FROM (SELECT
        department_id,
        avg(a.salary) sa
      FROM employees a
      GROUP BY a.department_id) t1, job_grades t2
WHERE
  t1.sa BETWEEN t2.lowest_sal AND t2.highest_sal;
~~~

#### where和having后面的子查询
支持标量、列、行子查询
子查询的执行优先于主查询，因为著查询的条件用到了子查询的结果
- 列子查询要搭配多行操作符使用`in(not in), any/some, all`
~~~sql
//标量子查询：查询谁的工资比Abel的高
SELECT *
FROM employees a
WHERE a.salary > (SELECT salary
                  FROM employees
                  WHERE last_name = 'Abel');


//标量子查询：查询最低工资大于50号部门最低工资的部门id和其最低工资
SELECT
  min(a.salary) minsalary,
  department_id
FROM employees a
GROUP BY a.department_id
HAVING min(a.salary) > (SELECT min(salary)
                        FROM employees
                        WHERE department_id = 50);

//列子查询：返回location_id是1400或1700的部门中的所有员工姓名 <> ALL 等价于 NOT IN
SELECT a.last_name
FROM employees a
WHERE a.department_id <> ALL (SELECT DISTINCT department_id  -- <> ALL 等价于 NOT IN
                             FROM departments
                             WHERE location_id IN (1400, 1700));

//行子查询：查询员工编号最小并且工资最高的员工信息
SELECT *
FROM employees a
WHERE (a.employee_id, a.salary) in (SELECT
                                     min(employee_id),
                                     max(salary)
                                   FROM employees);
~~~

#### exist后的子查询(相关子查询)
exists查询结果：1或0，exists查询的结果用来判断子查询的结果集中是否有值
一般来说，能用exists的子查询，绝对都能用in代替，所以exists用的少

~~~sql
mysql> SELECT exists(SELECT employee_id
              FROM employees
              WHERE salary = 300000) AS 'exists返回1或者0';
~~~

### 1.2.8 正则表达式    
MySQL中，正则表达式使用 `REGEXP` 声明(Regular Expression)      
- `^` : 匹配起始位置
- `$` : 匹配结束位置
- `.` : 匹配除 "\n" 外的所有单字符，要匹配包括 "\n" 则使用 `[.\n]`      
- `[...]` : 匹配字符集中的任一字符
- `[^...]` : 匹配未包含在字符集的任一字符 
- `\d` : 匹配所有单个数字[0-9]
- `[\w]` :匹配单个单词字符[a-zA-Z0-9]      
- `p1|p2|p3` : 或的单字符匹配  
- `*` : 匹配前面子表达式零次或多次  
- `+` : 匹配前面子表达式一次或多次  
- `{n}` : n 是非负数，匹配确定的 n 次  
- `{n, m}` : 最少匹配 n 次，最多匹配 m 次   


通配符： _ 替代一个字符， % 替代零个或多个字符

~~~sql
# 查找name字段中以'st'为开头的所有数据：
mysql> SELECT name FROM person WHERE name REGEXP '^st';

#查找name字段中以元音字符开头或以'ok'字符串结尾的所有数据：
mysql> SELECT name FROM person WHERE name REGEXP '^[aeiou]|ok$';
~~~


## 1.3 约束     
对表中的数据进行限定，保证数据的正确性、完整性、有效性      
- 约束的分类          
主键约束：primary key           
非空约束：not null      
唯一约束：unique            
外键约束：foreign key           

### 1.3.1 非空约束          
- 创建表时，对应列加上 NOT NULL 约束  
    ~~~sql
    CREATE TABLE student(
        id INT NOT NULL,
        name VARCHAR(20) NOT NULL
    );
    ~~~

- 修改约束      
    ~~~sql
    ALTER TABLE student MODIFY name VARCHAR(20);
    ~~~

### 1.3.2 唯一约束      

- 创建表时，添加唯一约束(MySQL中唯一约束的列可以有多个NULL)    
    ~~~sql
    CREATE TABLE student(
        id INT NOT NULL,
        name VARCHAR(20) NOT NULL
    );
    ~~~
- 唯一约束的添加可以直接modify(要保证唯一)，去除时，直接modify修改不了，必须删除索引
    ~~~sql
    ALTER TABLE student DROP INDEX id;
    ~~~

### 1.3.3 主键约束  
- 主键非空且唯一，一个 table 只能有一个主键     
- 创建表时添加主键约束  
    ~~~sql
    CREATE TABLE student(
        id INT PRIMARY KEY,     -- 添加主键约束
        name VARCHAR(20) NOT NULL
    );

    create table student(   -- 创建表
    -> id int,
    -> name varchar(20),
    -> address varchar(20),
    -> primary key(id, name)       -- 直接设置主键
    -> );
    ~~~

- 删除主键
    ~~~sql
    ALTER TABLE student DROP PRIMARY KEY;
    ~~~

- 添加主键
    ~~~sql
    ALTER TABLE student MODIFY id INT PRIMARY KEY;
    ~~~

- 自动增长，一般与主键结合使，当下一个记录的该值为 NULL 时从上一个记录值自动增长
    ~~~sql
    ALTER TABLE student MODIFY id INT PRIMARY KEY AUTO_INCREMENT;
    ~~~

- 删除自动增长          
    ~~~sql
    ALTER TABLE student MODIFY id INT PRIMARY KEY;
    ~~~

### 1.3.4 外键约束  

外键值可以为NULL，但是不能为外表对应列不存在的其他值
- 创建表时，添加外键约束        
    ~~~sql
    CREATE TABLE 表名(
        ......
        外键列
        CONSTRAINT 起外键名 FOREIGN KEY (外键的列名) REFERENCES 外部主表名(列名)  -- 关联外表唯一约束的列(不一定是主键)       

        -- 例如
        department_id INT
        CONSTRAINT dep_fk FOREIGN KEY (department_id) REFERENCES department(id)
    );
    ~~~

- 删除外键  
    ~~~sql
    ALTER TABLE 表名 DROP FOREIGN KEY 外键名
    ~~~

- 添加外键      
    ~~~sql
    ALTER TABLE 表名 ADD CONSTRAINT 起外键名 FOREIGN KEY (外键的列名) REFERENCES 外部主表名(列名)
    ~~~

- 级联操作      
`ON UPDATE CASCADE;`  外部表对应列修改时，外键自动更新  
`ON DELETE CASCADE;`  级联删除       
    ~~~sql
    ALTER TABLE 表名 ADD CONSTRAINT 起外键名 FOREIGN KEY (外键的列名) REFERENCES 外部主表名(列名) ON UPDATE CASCADE;
    ~~~

## 1.4 数据库的设计     

### 1.4.1 第一范式(1NF)
- 如果一个关系模式R的**所有属性都是不可分的**基本数据项，则R∈1NF
- 1NF 强调的是**列的原子性**，即列不能够再分成其他几列  

如学生（学号，姓名，性别，出生年月日），如果认为最后一列还可以再分成（出生年，出生月，出生日），它就不是一范式了，否则就是

### 1.4.2 第二范式(2NF)
- 关系模式R∈1NF，并且每一个非主属性都完全函数依赖于R的主键，则R∈2NF
- 2NF 在1NF 的基础上要求**非主键字段必须完全函数依赖于主键**，不能只依赖于主键的一部分，所以只有一个主键的表如何符合第一范式，必然也符合第二范式              

如表：学号、课程号、姓名、成绩          
这个表明显说明了两个事务:学生信息, 课程信息; 主键是学号和课程号，姓名只依赖于学号，不满足 2NF       

### 1.4.3 第三范式(3NF)
- 3NF 要求在 1NF 的基础上，任何 非主属性不依赖于其他非主属性，即**在2NF的基础上消除传递依赖**    

如表: 学号, 姓名, 年龄, 学院名称, 学院电话   
因为存在依赖传递: (学号) → (学生) → (学院名称) → (学院电话)

### 1.4.4 BCNF范式  
- BCNF范式是对 3NF 的改进，关系模式R属于第一范式，且每个表中只有一个候选键（在一个数据库中每行的值都不相同，则可称为候选键）   

## 1.5 事务

### 1.5.1 事务的基本介绍        
事务是并发控制的基本单位，是一个操作序列，这些操作要么都执行，要么都不执行           
- 开启事务： `start transaction`    
- 回滚： `rollback`
- 提交： `commit`       

~~~sql
START TRANSACTION;
UPDATE account SET balance = balance - 500 WHERE name = "张三";
UPDATE account SET balance = balance + 500 WHERE name = "李四";
COMMIT;
~~~

- MySQL 中事务会默认自动提交，一条 DML 语句会自动提交一次，手动时，开启后如果未提交就退出，则会自动回滚       
- Oracle 默认为手动提交
~~~sql
SET autocommit = 0        -- 设置默认为手动提交
~~~

### 1.5.2 事务的四大特征(ACID)        
- **原子性(Atomicity)：** 事务是不可分割的最小操作单位，要么全部做完，要么全部不做                
- **一致性(Consistency)：** 事务执行的结果必须是使数据库从一个一致性状态到另一个一致性状态      
- **隔离性(Isolation)：** 多个事务之间，相互独立，相互隔离。该事务提交前对其他事务不可见          
- **持久性(Durability)：** 事务一旦提交后，它对数据库中数据的改变会持久化到硬盘，修改是永久性的             

### 1.5.3 事务的隔离级别        

**多个事务操作同一批数据时存在的问题**          
1. 第一类丢失更新：A事务撤销时，把已提交的B事务的更新数据覆盖了       
<center>

| 时间点 | 事务A                        | 事务B                     |
| ------ | ---------------------------- | ------------------------- |
| T1     | 开始事务                     |                           |
| T2     |                              | 开始事务                  |
| T3     | 查询账户余额为1000元         |                           |
| T4     |                              | 查询账户余额为1000元      |
| T5     |                              | 存入100元把余额改为1100元 |
| T6     |                              | 提交事务                  |
| T7     | 取出100元把余额改为900元     |                           |
| T8     | 撤销事务                     |                           |
| T9     | 余额恢复为1000元（丢失更新） |                           |
</center>

2. 第二类丢失更新：A事务提交时，把已提交的B事务的更新数据覆盖了
<center>

| 时间点 | 事务A                        | 事务B                    |
| ------ | ---------------------------- | ------------------------ |
| T1     |                              | 开始事务                 |
| T2     | 开始事务                     |                          |
| T3     |                              | 查询账户余额为1000元     |
| T4     | 查询账户余额为1000元         |                          |
| T5     |                              | 取出100元把余额改为900元 |
| T6     |                              | 提交事务                 |
| T7     | 存入100元把余额改为1100      |                          |
| T8     | 提交事务                     |                          |
| T9     | 余额恢复为1100元（丢失更新） |                          |
</center>

3. 脏读：一个事务读取到另一个事务没有提交的数据          
<center>

| 时间点 | 事务A                       | 事务B                          |
| ------ | --------------------------- | ------------------------------ |
| T1     |                             | 开始事务                       |
| T2     | 开始事务                    |                                |
| T3     |                             | 查询账户余额为1000元           |
| T4     |                             | 取出500元把余额改为500元       |
| T5     | 查询账户余额为500元（脏读） |                                |  |  |
| T6     |                             | **撤销事务**，余额恢复为1000元 |
| T7     | 存入100元把余额改为600元    |                                |
| T8     | 提交事务                    |                                |
</center>

4. 不可重复读(虚读)：同一个事务中，两次读取到的数据不一样
<center>

| 时间点 | 事务A                                                      | 事务B                    |
| ------ | ---------------------------------------------------------- | ------------------------ |
| T1     |                                                            | 开始事务                 |
| T2     | 开始事务                                                   |
| T3     |                                                            | 查询账户余额为1000元     |
| T4     | 查询账户余额为1000元                                       |
| T5     |                                                            | 取出100元把余额改为900元 |
| T6     |                                                            | 提交事务                 |
| T7     | 查询账户余额为900元 <br>（与T4读取的一不一致，不可重复读） |
</center>


5. 幻读：由于数据的插入删除，导致读取操作不能支持后面的操作，两者相矛盾，不一致，仿佛发生了幻觉，只有可重复读的模式下才会发生幻读
<center>

| 时间点 | 事务A                                                         | 事务B                          |
| ------ | ------------------------------------------------------------- | ------------------------------ |
| T1     |                                                               | 开始事务                       |
| T2     | 开始事务                                                      |                                |
| T3     |                                      |   插入数据a                             |
| T4     | 查询发现数据a不存在                                                              |  |
| T5     |                                                               | 提交事务                       |
| T6     | 尝试插入数据a，报错 |                                |
|T7|查询发现数据a依然不存在||
|T8|提交事务||
</center>
A产生幻觉：明明不存在为什么不能插入？？？

**不可重复读和幻读的区别：** 不可重复读是由于数据修改引起的，幻读是由数据插入或者删除引起的。

**隔离级别：** 级别越高约安全，但是效率越低          
1. **READ UNCOMMITTED（读未提交）:** 一个事务在执行过程中可以看到其他事务没有提交的新插入的记录，而且还能看到其他事务没有提交的对已有记录的更新      
2. **READ COMMITTED（读已提交）:** 一个事务在执行过程中可以看到其他事务已经提交的新插入的记录，而且还能看到其他事务已经提交的对已有记录的更新（允许第二类丢失更新）       
3. **REPEATABLE READ（可重复读）：** 一个事务在执行过程中可以看到其他事务已经提交的新插入的记录，但是不能看到其他事务对已有记录的更新。**mysql的默认隔离级别**   
4. **SERIALIZABLE（串行化）：** 一个事务在执行过程中完全看不到其他事务对数据库所做的更新。当两个事务同时操作数据库中相同数据时，如果第一个事务已经在访问该数据，第二个事务只能停下来等待，必须等到第一个事务结束后才能恢复运行。因此这两个事务实际上是串行化方式运行。



<center>

| 隔离级别                     | 第一类丢失更新 | 第二类丢失更新 | 脏读 | 不可重复读 | 幻读 |
| ---------------------------- | :------------: | :------------: | ---- | :--------: | ---- |
| READ-UNCOMMITTED（读未提交） |      避免      |      允许      | 允许 |    允许    | 无 |
| READ-COMMITTED （读已提交）  |      避免      |      允许      | 避免 |    允许    | 无 |
| REPEATABLE-READ（可重复读）  |      避免      |      避免      | 避免 |    避免    | 允许 |
| SERIALIZABLE （可串行）      |      避免      |      避免      | 避免 |    避免    | 避免 |
</center>

隔离级别越高越安全，但是并发性能越低，最高级别直接让操作变成串行了

**数据库隔离级别的查询和设置：**            
- `show variables like 'transaction_isolation'`  查看隔离级别 
- `select @@transaction_isolation;` 查看隔离级别
- `set global transaction isolation level REPEATABLE READ;`   设置隔离级别之后重启数据库生效
- `set @@transaction_isolation='REPEATABLE-READ';`

## 1.6 锁       
锁也是数据库管理系统区别文件系统的重要特征之一。锁机制使得在对数据库进行并发访问时，可以保障数据的完整性和一致性。不同数据库实现方法有所不同，主要介绍的是 MySQL 中的 InnoDB 引擎的锁

### 1.6.1 锁的类型      

**数据库的增删改操作默认都会加排他锁，而查询不会加任何锁**

1. **共享锁(S锁)**：又称为读锁，允许多个事务读取同一行数据，但无法修改，要修改必须等所有共享锁都释放。如果事务1获取了行r的S锁，其他事务再获取行r的S锁，但不能加X锁     

~~~sql
SELECT * FROM tableName WHERE... LOCK IN SHARE MODE;   -- 手动加 S 锁
~~~

2. **独占锁(X锁，排他锁)**： 又称为写锁，只能独占，允许事务删除或更新一行数据。如果事务1获取了行r的X锁，其他事务获取S或X锁都不行     

~~~sql
SELECT * FROM tableName WHERE... FOR UPDATE;   --手动加 X 锁
~~~

- S 锁和 S 锁是 **兼容** 的，X 锁和其它锁都 **不兼容** ，举个例子，事务 T1 获取了一个行 r1 的 S 锁，另外事务 T2 可以立即获得行 r1 的 S 锁，此时 T1 和 T2 共同获得行 r1 的 S 锁，此种情况称为 **锁兼容** ，但是另外一个事务 T2 此时如果想获得行 r1 的 X 锁，则必须等待 T1 对行 r1 的锁的释放，此种情况也成为 **锁冲突**              

3. **乐观锁和悲观锁：** 读多写少用乐观锁，写多读少用悲观锁
- 乐观锁：添加version版本字段或者timestamp时间戳字段等，更新有可能会失败，甚至是更新几次都失败，这是有风险的。所以如果写入频繁，对吞吐要求不高，应该使用悲观锁
- 悲观锁：使用了排他锁，当程序独占锁时，其他程序就连查询都是不允许的，导致吞吐较低。如果在查询较多的情况下，可使用乐观锁

4. **意向锁(Intention Locks)：** 意向锁是表级锁，用来表示该表中的row锁需要的锁(S,X)的类型
意向锁可以分为意向共享锁(IS)和意向排它锁(IX)，事务要获得某个表某行的S或X锁时，必须先分别获得IS锁和IX锁

### 1.6.2 分布式锁
1. 分布式锁的使用者位于不同机器中，锁获取成功后才可以对共享资源进行操作
2. 锁具有重入功能：一个使用者可以多次获取某个锁
3. 获取锁具有超时的功能：超时仍未获得锁就返回失败
4. 能够自动容错：保证持有锁的机器即使出现故障也可以成功归还锁

## 1.7 视图
- 视图是mysql5之后才有的。是一种虚拟表，行和列的数据都来自于定义视图时使用的表中，视图的数据是在使用视图时动态生成的，`视图只保存了sql的逻辑，不保存查询的结果`
- 视图的好处是可以**简化复杂的sql操作**，不用知道它的实现细节，**隔离了原始表**，可以不让使用视图的人接触原始表，提高了安全性
- 创建视图：`CREATE VIEW 视图名 AS 查询语句;`
- 修改视图：`CREATE OR REPLACE VIEW 视图名 AS 查询语句;` 或者 `ALTER VIEW 视图名 AS 查询语句;`
- 删除视图：`DROP VIEW 视图名;`
- 查看视图结构：`DESC 视图名;`
~~~sql
/*案例1：查询姓名中包含a字符的员工名、部门、工种信息*/
/*①创建视图myv1*/
CREATE VIEW myv1
AS
  SELECT
    t1.last_name,
    t2.department_name,
    t3.job_title
  FROM employees t1, departments t2, jobs t3
  WHERE t1.department_id = t2.department_id
        AND t1.job_id = t3.job_id;

/*②使用视图*/
SELECT * FROM myv1 a where a.last_name like '%a%';
~~~

## 1.8 变量
全局变量：每次重启都会被赋予初值
会话变化：仅当次会话有效
- `SHOW GLOBAL VARIABLES` 查看全局变量
- `SHOW SESSION VARIABLES` 查看会话变量
- `SHOW GLOBAL VARIABLES LIKE '%变量名%'` 通过模糊匹配查找变量
- `SELECT @@GLOBAL.变量名;` 查看全局变量
- `SET @@GLOBAL.变量名=值;` 设置全局变量的值

自定义变量：仅当次会话有效
- `SET @变量名=值`
- `SELECT @变量名`

局部变量：一般用于函数中
- `DECLARE 变量名 变量类型` 声明局部变量
- 局部变量的使用和自定义变量一样，set，select

## 1.9 游标
游标（Cursor）是处理数据的一种方法，为了查看或者处理结果集中的数据，游标提供了在结果集中一次一行遍历数据的能力

- `DECLARE 游标名称 CURSOR FOR 查询语句;` 声明游标
- `open 游标名称;` 打开游标
- `fetch 游标名称 into 变量列表;` 遍历游标，将当前行结果存放到对应的变量列表中
- `close 游标名称;` 游标使用完要关闭

## 1.10 索引

### 1.10.1 索引和页
- **索引**：通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是说，有了这种索引机制，我们可以总是用同一种查找方式来锁定数据
- **磁盘块**：磁盘进行读写的最小单位是扇区，**磁盘块的大小=扇区*2^n**，操作系统与磁盘之间是按块进行读写的，一般磁盘块大小为`4KB`
- **页：** mysql中和磁盘交互的最小单位是页，一页默认是`16KB`

### 1.10.2 可能的加快查找的办法
- 二叉查找树：最坏时间复杂度是O(n)，查询效率不稳定。当数据量大时高度很高，如果每个节点对应磁盘的一个块来存储一条数据，io次数依然很多
- 二叉平衡树：无法支持范围查找，同样一个节点对应一个磁盘块存储，io次数多
- B-树：每个节点占用一个磁盘块。B-树相对于avl树，通过在节点中增加节点内部数据的个数来减少磁盘的io操作。缺点是不利于范围查找
![B-树](https://s1.ax1x.com/2020/11/06/BhR3nO.png)
- B+树：额外支持顺序查找，非叶节点不再存储数据，**只存储关键字和子节点的指针**。叶节点的页之间是双向链表，页内的记录按单链表存储，并按索引字段排序
![B+树](https://s1.ax1x.com/2020/11/06/Bh4jFe.png)
- **B-树和B+树的区别：**
  - **B+树**一个节点k个关键字，则**最多包含k个子节点**；**B-树最多包含k+1个子节点**。因为B+树路径上不含数据，所以叶子节点必须要包含路径节点，所以无法做开区间的k+1子节点
  - B+树除叶节点外，其他节点存储关键字和指向子节点的指针，而**B-树还存储了数据**，所以同样内存大小下，B+树可以存储更多关键字
  - **B+树叶子节点支持顺序遍历**，便于快速的范围查找
- **B-树和B+树的查询对比：**
  - 由于B-树非叶节点也有数据，所以**单个关键字的查找效率高于B+树**
  - **B+树支持范围查找**，而B-树可能需要多次查找(不在一个磁盘块时)
  - B-树每层都需要一次io操作去磁盘读取数据，而B+树查找到之后才需要IO

mysql内部索引是由不同的引擎实现的，主要用**InnoDB**和**MyISAM**两种，这两种都是使用**B+树**的结构存储的  
### 1.10.3 InnoDB引擎和MyISAM引擎
聚簇索引和非聚簇索引：主要指数据和索引是否存放在一起(一个文件中)
1. `InnoDB`中有两种索引：**主键索引(聚集索引)**、**辅助索引(非聚集索引)**
**主键索引**：每个表只有一个主键索引，叶子节点同时保存了主键的**值和数据**
**辅助索引**：叶子节点保存了索引字段的**值以及主键的值**
所以检索非主键的数据，需要两步，先在辅助索引中找到其主索引，再到主索引中检索，辅助索引这个查询过程叫`回表`
所以InnoDB中最好**采用主键查询**，这样只需要一次索引，如果使用辅助索引还需要回表操作，比主键查询要耗时一些
2. `MyISAM`不管是主键索引还是辅助索引结构都是一样的，叶子节点保存了**索引字段的值以及数据记录的地址**
- 二者的对比：
  - InnoDB由于是聚集索引，辅助索引记录的是主键，所以**主键不应过大**，否则其他索引也会很大。而MyISAM是非聚集索引，数据文件是分离的，**索引仅仅保存数据文件的指针**。
  - InnoDB支持外键，MyISAM不支持外键。对包含外键的InnoDB表转为MyISAM会失败
  - InnoDB锁的粒度是**行锁**，而MyISAM是**表锁**
  - InnoDB支持事务，**MyISAM不支持事务**。InnoDB默认把每条sql都封装成事务，所以最好把多条sql放在begin和commit中，组成事务，提高速度
  - InnoDB不保存表的行数，**执行select(*)需要全表扫描**。MyISAM用一个变量保存了整个表的行数，速度很快
  - 如果绝大多数都是读操作，且不需要事务支持，可以考虑MyISAM

- **InnoDB辅助索引只保存主键的原因：** 如果辅助索引保存的是数据地址，对于写操作较多的情况，那么当数据地址变了的话，所有的辅助索引也要频繁跟着更新。而主键的值一般很少更新，数据地址变化对辅助索引是没有影响的
![InnoDB和MyISAM](https://s1.ax1x.com/2020/11/06/BhHOTP.png)

### 1.10.5 页
mysql的`页`是InnoDB中数据存储的基本单位，也是mysql中管理数据的最小单位，和磁盘交互的基本单位，默认是`16KB`，对应的是`B+树的一个节点`
- Page之间是双向链表连接
- Page主体的记录record是采用链表的方式存储的，Infimum是头节点，superemum是尾节点
- **为了提高查找效率，page主体还存储了一个数组结构的Directory，每个slot占两个字节，多个slot组成有序数组，可以用于二分法快速定位，行记录被Page Directory逻辑的分成了多个块，块之间是有序的，能够加速查找**
- 每个记录都有一个n_owned区域，表示所属的slot块有多少条数据，Inf的n_onwen为1，Sup的n_owned为1-8，其他位4-8.

![页](https://s1.ax1x.com/2020/11/07/B4zD81.png)

**数据检索过程：** 先通过B+树查询定位到数据所在的页，将页整体加载到内存，通过二分法在Page Directory中检索数据，缩小范围，然后从对应slot开始查找，直到查找到slot边界还没有就结束

### 1.10.6 索引的管理
- **聚集索引：**
  - **每个表有且仅有一个聚集索引**，未指定主键时，mysql首先会选择一个**不含null的唯一键作为主键**，如果没有唯一键，mysql自动给每个记录添加一个隐藏的`RowID`字段(6字节)作为主键，用RowID构建聚集索引
- **非聚集索引的分类：**
  - **单列索引**：一个索引只包含一个列
  - **多列索引(复合索引)**：一个索引包含多个列
  - **唯一索引**：索引列的值必须唯一，允许一个空值
- 创建索引：char和varchar的索引的length可以指定小于实际长度的值，blog、text等长文本必须指定length
  - `create [unique] index 索引名 on 表名(列名[(length)]);`
  - `alter 表名 add [unique] index 索引名 on (列名[(length)]);`
- 删除索引：`drop index 索引名 on 表名;`
- 查看索引：`show index from 表名`

~~~sql
/*无索引速度*/
mysql> select * from test1 a where a.name = javacode1;
+----+-----------+-----+-------------------+
| id | name      | sex | email             |
+----+-----------+-----+-------------------+
|  1 | javacode1 |   1 | javacode1@163.com |
+----+-----------+-----+-------------------+
1 row in set (0.77 sec)

/*创建索引后的速度*/
mysql> create unique index idx2 on test1(name);
Query OK, 0 rows affected (9.67 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql> select * from test1 where name = 'javacode1';
+----+-----------+-----+-------------------+
| id | name      | sex | email             |
+----+-----------+-----+-------------------+
|  1 | javacode1 |   1 | javacode1@163.com |
+----+-----------+-----+-------------------+
1 row in set (0.00 sec)


/*email后面结尾字符都是一样的，前面最多15个字符，所以可以指定创建的索引字段的长度*/
mysql> create index idx3 on test1 (email(15));
Query OK, 0 rows affected (7.67 sec)
~~~

### 1.10.7 索引与sql优化
- **模糊匹配：** 模糊匹配如果是包含索引开头的字段，如`a%`，是可以走索引的，如果是`%a`或者`%a%`，则索引对查询无效，只能进行遍历

- **最左匹配原则：** 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性

例如3个字段(a,b,c)的联合索引，索引顺序是按 a ASC, b ASC, c ASC排序存储，即首先按a升序，如果a相同再按b升序，以此类推
此时如果要查询的记录是 `包含a` 的，自然可以利用索引
如果要查询 `不包含a` 的记录，例如查询 `b=1` 的记录，就没法判断b=1的记录在哪些页，只能遍历所有的记录，然后进行过滤

- **索引区分度：** $索引区分度=distinct 记录数/总记录数$，当索引区分度低的时候，说明重复数据较多，检索的时候需要访问更多的记录才能找到所有目标数据。所以**建立索引的时候要尽量选择区分度高的列作为索引**

当多个where条件都有索引，并且条件间的关系是and的时候，mysql会`优先走索引区分度高的索引进行检索`，**并不会按where后面的顺序来查**
~~~sql
/*为name和sex均建立索引*/
mysql> create index idx1 on test1(name);
Query OK, 0 rows affected (13.50 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql> create index idx2 on test1(sex);
Query OK, 0 rows affected (6.77 sec)
Records: 0  Duplicates: 0  Warnings: 0


/*where多条件查询，并不是先查出sex=2的人之后，再过滤name，而是先查找到索引区分度高的name，再过滤sex*/
mysql> select * from test1 where sex=2 and name='javacode3500000';
+---------+-----------------+-----+-------------------------+
| id      | name            | sex | email                   |
+---------+-----------------+-----+-------------------------+
| 3500000 | javacode3500000 |   2 | javacode3500000@163.com |
+---------+-----------------+-----+-------------------------+
1 row in set (0.00 sec)

/*可以看到单独查找sex的速度远远慢于上面的速度*/
mysql> select count(id) from test1 where sex=2;
+-----------+
| count(id) |
+-----------+
|   2000000 |
+-----------+
1 row in set (0.36 sec)
~~~

- **索引覆盖和回表：** 查询中采用的索引树包含了查询所需要的所有字段的值，不需要再去聚集索引检索数据，这种就叫做`索引覆盖`。反之，如果不包含，还需要去聚集索引进行检索，就叫做`回表`

~~~sql
/*仅查找name和id，name的索引数包含了id，不需要回表，索引覆盖*/
mysql> select id,name from test1 where name='javacode3500000';

/*查找所有信息，所查找的索引树仅仅包含了name和id，需要回表*/
mysql> select * from test1 where name='javacode3500000';
~~~

- **索引条件下推(Index Condition Pushdown ICP)：** mysql5.6添加的，可以减少存储引擎查询基础表的次数。
  - 不使用ICP的情况下进行非主键索引查询时，存储引擎通过索引检索到数据，返回给MySQL服务器，由服务器判断数据是否符合条件 
  - 使用ICP的情况下，MySQL服务器将判断条件传递给存储引擎，由存储引擎判断数据是否符合条件，符合条件时才会把数据返回给MySQL服务器

例如检索name以javacode35开头的，性别为1的记录： 
~~~sql
select * from test1 a where name like 'javacode35%' and sex = 1;
~~~
可以创建一个(name,sex)的组合索引
不使用ICP时，首先检索出所有 name='javacode35%' 的记录id，利用id去主键索引中查找记录R，最后再筛选出 R 中 sex 为1的记录
使用ICP时，检索出所有 name='javacode35%' 的记录R，筛选出R的sex为1的记录，再进行回表，显然回表查询的次数要少很多

- **数字使字符串索引失效：** 如果索引是字符串类型的数字，查询的时候传入的是int数字，mysql进行比较就需要把字符串转换为数字再进行比较，导致索引失效，需要全表扫描。反之如果索引是数字，查询传入的是字符串则可以正常利用索引进行快速检索

- **函数使索引失效：** 索引字段使用函数查询会使索引无效，变成全表数据扫描
~~~sql
mysql> select a.name+1 from test1 a where a.name = 'javacode1';
+----------+
| a.name+1 |
+----------+
|        1 |
+----------+
1 row in set, 1 warning (0.00 sec)


/*索引字段使用函数使索引失效*/
mysql> select * from test1 a where concat(a.name,'1') = 'javacode11';
+----+-----------+-----+-------------------+
| id | name      | sex | email             |
+----+-----------+-----+-------------------+
|  1 | javacode1 |   1 | javacode1@163.com |
+----+-----------+-----+-------------------+
1 row in set (2.88 sec)
~~~

- **运算符使索引失效：** 索引字段使用了运算符也会使索引无效，变成全表的数据扫描
~~~sql
mysql> select * from test1 a where id = 2 - 1;
+----+-----------+-----+-------------------+
| id | name      | sex | email             |
+----+-----------+-----+-------------------+
|  1 | javacode1 |   1 | javacode1@163.com |
+----+-----------+-----+-------------------+
1 row in set (0.00 sec)

mysql> select * from test1 a where id+1 = 2;
+----+-----------+-----+-------------------+
| id | name      | sex | email             |
+----+-----------+-----+-------------------+
|  1 | javacode1 |   1 | javacode1@163.com |
+----+-----------+-----+-------------------+
1 row in set (2.41 sec)
~~~

- **使用索引优化排序：**
我们有个订单表t_order(id,user_id,addtime,price)，经常会查询某个用户的订单，并且按照addtime升序排序，应该怎么创建索引呢？
在user_id上创建索引，可以通过user_id索引查询到id，最后将这些订单按addtime进行排序，但是当订单数量很多的时候排序非常花费时间。
更好的做法是让查询出来的数据刚好是排好序的。就可以将user_id和addtime放在一起组成联合索引(user_id,addtime)，这样根据user_id检索出来的数据自然就是按照addtime排好序的了，减少了一步排序操作，效率提高了

- **开启查询缓存：** 开启缓存可以提高查询效率
- **使用ENUM而不是varchar：** 对于字段取值有限且固定的情况，如性别，民族，部门等，使用ENUM枚举，枚举的数量应该控制在20个以内，**mysql自动将这些字符串映射为(1，2，3...)数字**
~~~sql
CREATE TABLE table_name (
    ...
    col ENUM ('value1','value2','value3'),  /*表示该列只接收者三个值*/
    ...
);
~~~

## 1.11 mysql确保数据不丢失的办法
~~~sql
start transaction;
update t_user set name = 'Java1' where user_id = 666;
update t_user set name = 'java2' where user_id = 888;
commit;
~~~
上面的过程，如果666和888在不同的页，当第一页加载到内存，修改后写回磁盘，再去读第二页的时候，mysql宕机了，此时id666修改成功，id888修改失败，数据是有问题的。

- mysql的办法是引入了一个 **redo log**

>mysql内部有个redo log buffer，是内存中一块区域，我们将其理解为数组结构，向redo log文件中写数据时，会先将内容写入redo log buffer中，后续会将这个buffer中的内容写入磁盘中的redo log文件，这个个redo log buffer是整个mysql中所有连接共享的内存区域，可以被重复使用。

1. mysql收到start transaction后，生成一个全局的事务编号trx_id，比如trx_id=10

2. user_id=666这个记录我们就叫r1，user_id=888这个记录叫r2

3. 找到r1记录所在的数据页p1，将其从磁盘中加载到内存中

4. 在内存中找到r1在p1中的位置，然后对p1进行修改（这个过程可以描述为：将p1中的pos_start1到pos_start2位置的值改为v1），这个过程我们记为rb1(内部包含事务编号trx_id)，将rb1放入 **redo log buffer** 数组中，此时p1的信息在内存中被修改了，和磁盘中p1的数据不一样了

5. 找到r2记录所在的数据页p2，将其从磁盘中加载到内存中

6. 在内存中找到r2在p2中的位置，然后对p2进行修改（这个过程可以描述为：将p2中的pos_start1到pos_start2位置的值改为v2），这个过程我们记为rb2(内部包含事务编号trx_id)，将rb2放入redo log buffer数组中，此时p2的信息在内存中被修改了，和磁盘中p2的数据不一样了

7. 此时redo log buffer数组中有2条记录[rb1,rb2]

8. mysql收到commit指令，将redo log buffer数组中内容写入到 **redo log文件** 中，写入的内容：
~~~
1.start trx=10;
2.写入rb1
3.写入rb2
4.end trx=10;
~~~
9.  返回给客户端更新成功。

这样之后，实际上内存中的p1、p2被修改了还未同步到磁盘，而是持久到了**redo log**中，也不会丢失
一个成功的事务在redo log中是有start和end的，如果redo log中只有start没有end就说明是有问题的

**回写到磁盘：** 当redo log满了，或者系统比较闲的时候，就会对redo log中的内容进行读取，对完整的trx_id对应的信息进行处理，如果p1在内存中还存在，直接将p1的信息回写到所在磁盘位置，如果不存在则将p1从磁盘中加载到内存，通过redo log中信息在内存中对p1进行修改，回写到磁盘。然后释放redo log中trx_id=10的空间区域。如果redo log中对应的rex_id没有end，则跳过不处理


## 1.12 缓存
MySQL查询缓存是MySQL中比较独特的一个缓存区域，用来缓存特定Query的整个结果集信息

当MySQL Server打开Query Cache之后，MySQL Server会对接收到的每一个**SELECT语句**通过特定的Hash算法计算该Query的**Hash值**，然后通过该hash值到**Query Cache**中去匹配
1. 如果没有匹配，将hash值和查询结果分别存放到hash链表和cache中
2. 匹配则直接将cache中对应的query结果集返回

**缓存的一些规则：**
当表发生**改动**之后，缓存中该表的**所有缓存**查询都将不再有效
缓存的hash值计算是大小写敏感的，任何的大小写、空格、注释等不同都将导致hash值不同！
缓存的结果是通过**sessions共享**的，所以一个client查询的缓存结果，另一个client也可以使用
where条件中如包含任何一个不确定的函数将永远不会被cache, 比如current_date, now等
太大的result set不会被cache (< query_cache_limit)

**缓存的缺点：**
1. 每条查询语句都需要计算hash并进行hash查找，带来额外的性能开销
2. 表变更频繁的话，造成缓存失效频繁
3. 查询语句字符大小写、空格、注释不同，都会重复缓存，带来额外开销
4. 内存碎片？

# 2. JDBC           
Java DataBase Connectivity          
- 官方(sun)定义的一套操作所有关系型数据库的接口，各个关系型数据库厂商均实现了这些接口，提供数据库驱动jar包。我们使用这套接口(JDBC)编程，真正执行的代码是驱动jar包中的实现类       

## 2.1 整体步骤         
1. 导入jar包：复制到目录，add as library
2. 注册驱动 ：          
3. 获取数据连接对象 Connection
4. 定义 sql
5. 获取执行sql 语句的对象 Statement
6. 执行sql ，接收返回的结果
7. 处理结果  
8. 释放资源 

~~~java
public class DemoJDBCPractice {
    public static void main(String[] args) {
        
        //提升释放的资源的作用域
        Connection connectionnn = null;
        Statement statement = null;
        try {
            //1. 注册驱动包   MySQL8.0以上版本使用com.mysql.cj.jdbc.Driver
            Class.forName("com.mysql.jdbc.Driver");

            //2. 获取数据库连接对象
            connectionnn = DriverManager.getConnection("jdbc:mysql://localhost:3306/mydb?characterEncoding=utf8&useSSL=false", "root", "janshan123");
            
            //3. 获取执行sql的对象
            statement = connectionnn.createStatement();

            //4. 定义sql
            //String sql = "insert into student values(124,'小蓝','北京',null)";
            //String sql = "update student set address='上海' where id = 121";
            String sql = "delete from student where name='小蓝'";
            
            //5. 执行sql，处理结果
            int count = statement.executeUpdate(sql);
            System.out.println("count=" + count);

        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        } catch (SQLException throwables) {
            throwables.printStackTrace();
        } finally {

            //6. 释放资源
            if (statement != null) {    //空指针判断
                try {
                    statement.close();
                } catch (SQLException throwables) {
                    throwables.printStackTrace();
                }
            }

            try {
                connectionnn.close();
            } catch (SQLException throwables) {
                throwables.printStackTrace();
            }
        }
    }
}
~~~

## 2.2 常用类   
### 2.2.1 DriverManager：驱动管理对象 
**功能：**
1. **注册驱动** 
- `static void registerDriver(Driver driver)`        
- MySQL5之后驱动jar包可以省略注册驱动的步骤，会自动注册驱动
~~~java
public class Driver ...{
    ...
    static {        //使用Class.forname加载类的时候执行了该类的静态代码块
        try {
            DriverManager.registerDriver(new Driver()); //实际调用DriverManager注册驱动
        } catch (SQLException var1) {
            throw new RuntimeException("Can't register driver!");
        }
    }
    ...
}
~~~

2. **获取数据库连接对象** 
- `public static Connection getConnection(String url)`
- `static Connection getConnection(String url,String user, String password)`  
- url语法：`jdbc:mysql://ip地址:端口/数据库名称` ，本地数据库直接省略 ip:端口

### 2.2.2 Connection：数据库连接对象
1. **获取执行sql的对象**        
- `Statement createStatement()`     
- `PreparedStatement prepareStatement(String sql)`  
2. **管理事务**  
- `boolean getAutoCommit(boolean autoCommit)`  开启事务
- `void commit()`  提交事务
- `void rollback()`   回滚
### 2.2.3 Statement：执行静态sql的对象    
- `boolean execute(String sql)`  执行任意sql，不常用
- `int executeUpdate(String sql)` 执行**DML**(insert、update、delete) 和 DDL(create、alter、drop)，DML返回值是**影响的行数**，DDL返回0  
- `ResultSet executeQuery(String sql)` 执行**DQL**(slelect) 
### 2.2.4 ResultSet：结果集对象     
- `boolean next()`  游标向下移动，并判断是否位于最后一行之后，最开始移动前位于第一行之前
- `Xxx getXxx(int columnIndex)`  根据列的编号(从1开始)返回对应类型的数据
- `Xxx getXxx(String columnLabel)`  根据列的标签返回对应数据        
~~~java
//查询示例，查询结果并封装为对应的对象      
class Student {     //根据查询创建相应的对象
    private int id;
    private String name;
    private String address;
    private Timestamp add_time;

    public Student(int id, String name, String address, Timestamp add_time) {
        this.id = id;
        this.name = name;
        this.address = address;
        this.add_time = add_time;
    }

    @Override
    public String toString() {
        return '\n'+
                "Student{" +
                "id=" + id +
                ", name='" + name + '\'' +
                ", address='" + address + '\'' +
                ", add_time=" + add_time +
                '}';
    }
}

public class DemoJDBCPractice2 {

    public static void main(String[] args) {
        List<Student> students = new DemoJDBCPractice2().findAll();
        System.out.println(students);
    }

    public List<Student> findAll(){
        Connection connection = null;
        Statement statement = null;
        List<Student> students = new ArrayList<>();     //使用列表存储student对象
        try {
            Class.forName("com.mysql.jdbc.Driver");

            connection = DriverManager.getConnection("jdbc:mysql://localhost:3306/mydb?useSSL=false", "root", "janshan123");

            statement = connection.createStatement();

            String sql = "select * from student";

            ResultSet resultSet = statement.executeQuery(sql);
            while(resultSet.next()){
                int id = resultSet.getInt("id");
                String name = resultSet.getString("name");
                String address = resultSet.getString("address");
                Timestamp add_time = resultSet.getTimestamp("add_time");
                students.add(new Student(id, name, address, add_time));
            }

        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        } catch (SQLException throwables) {
            throwables.printStackTrace();
        }finally{
            if(statement!=null){
                try {
                    statement.close();
                } catch (SQLException throwables) {
                    throwables.printStackTrace();
                }
            }

            try {
                connection.close();
            } catch (SQLException throwables) {
                throwables.printStackTrace();
            }
            return students;
        }
    }
}

/*
[
Student{id=121, name='小红', address='上海', add_time=2020-08-09 16:08:10.0}, 
Student{id=123, name='小强', address='深圳', add_time=2020-08-08 18:32:40.0}]
*/
~~~

- 但是上述方法很麻烦，更好的办法是写一个工具类：
~~~java
public class JDBCS {
    private static String url;
    private static String user;
    private static String password;
    private static String driver;

    static { //静态代码块只在类加载的时候执行一次，读取相关的参数
        try {
            Properties pro = new Properties();  //创建Properties

            //获取src路径下文件
            ClassLoader classLoader = JDBCS.class.getClassLoader();
            URL resource = classLoader.getResource("jdbc.properties");
            String path = resource.getPath();

            //加载Properities的配置
            pro.load(new FileReader(path));
            url = pro.getProperty("url");
            user = pro.getProperty("user");
            password = pro.getProperty("password");
            driver = pro.getProperty("driver");

            //注册驱动
            Class.forName(driver);
        } catch (IOException e) {
            e.printStackTrace();
        }catch (ClassNotFoundException e) {
            e.printStackTrace();
        }
    }
    
    //定义连接数据库的函数
    public static Connection getConnection() throws SQLException {
        return DriverManager.getConnection(url, user, password);
    }

    //定义最后抛出异常的函数
    public static void close(Statement statement, Connection connection) {
        if (statement != null) {
            try {
                statement.close();
            } catch (SQLException e) {
                e.printStackTrace();
            }
        }

        try {
            connection.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void close(ResultSet resultSet, Statement statement, Connection connection) {

        if (resultSet != null) {
            try {
                resultSet.close();
            } catch (SQLException throwables) {
                throwables.printStackTrace();
            }
        }

        close(statementm, connextion)
    }
}
~~~

### 2.2.5 PreparedStatement：执行sql的对象  

- **SQL注入问题：** 在拼接sql时，一些sql的特殊关键字参与字符串的拼接会造成安全问题      
~~~java
//例如登录时的查询
String sql = "select * from users where userid=" + userid + " and password='" + password + "'";

//如果登录时输入：
输入用户id：
10000
输入密码：
a' or 'a'='a

//则会登录成功，因为此时的sql语句实际上是：
select * from users where userid=10000 and password='a' or 'a'='a'  
~~~

**解决办法：PreparedStatement**
- 预编译sql，使用参数？作为占位符       
- 获取PreparedStatement对象:            
    `PreparedStatement Connection.prepareStatemnt(String sql)`      
- 给 ? 赋值：`preparedStatement.setXxx(参数编号, 参数的值)`         
- 直接调用无参`executeQuery()`或者`executeUpdate()`执行     


~~~java
        String sql = "select * from users where userid = ? and password = ?";
        preparedStatement = connection.prepareStatement(sql);
        preparedStatement.setInt(1, userid);
        preparedStatement.setString(2, password);
        resultSet = preparedStatement.executeQuery();
~~~

### 2.2.6 JDBC控制事务  

**使用Connection管理事务**  
- `boolean setAutoCommit(boolean autoCommit)`  开启事务
- `void commit()`  提交事务
- `void rollback()`   回滚

~~~java
        try{
            ......
            //开启事务
            connection.setAutoCommit(false);
            ....
            //提交事务
            connection.commit();
        } catch (SQLException throwables) {
            try {
                //有异常时回滚事务，判空
                if (connection != null) {
                    connection.rollback();
                }
            } catch (SQLException e) {
                e.printStackTrace();
            }
            throwables.printStackTrace();
        } finally {
            JDBCS.close(resultSet, preparedStatement, connection);
        }

~~~

## 2.3 数据库连接池     
- 数据库连接池时一个存放数据库连接的容器。当系统初始化好后，容器被创建，并申请一些连接对象，用户访问数据时，从容器中获取连接对象，访问完之后把连接对象归还给容器。达到**节约资源**和用户**高效访问**的目的

- 数据库连接池的标准接口：**DataSource**，获取连接的方法 `getConnection()`，由数据库厂商来实现          
- 如果连接对象 connection 是从连接池获取的，那么调用 close() 方法时不再关闭连接，而是归还给连接池           

### 2.3.1 C3P0 数据库连接池
- 注意 c3p0-0.9.5.2.jar 包 依赖 mchange-commons-java-0.2.12.jar 包， 同样要导入数据库驱动jar包
- 配置文件：c3p0.properties 或者 c3p0-config.xml , 放在 src 目录
- 创建核心对象 `ComboPooledDataSource`   
- 获取连接对象 `getConnection()`    

~~~java
        //获取数据库连池接对象
        DataSource dataSource = new ComboPooledDataSource("otherc3p0"); //无参时使用默认配置

        //获取数据库连接对象
        Connection connection = dataSource.getConnection();
~~~

### 2.3.2 Druid
- durid-1.0.9.jar       
- 配置文件 durid.properties 可以叫任意名字放在任意地方(手动加载)        
- 获取数据库连接池对象，工厂类 `DruidDataSourceFactory`     

~~~java
        Reader rr = new FileReader("jdbc/src/druid.properties");
        Properties properties = new Properties();
        properties.load(rr);
        DataSource dataSource = DruidDataSourceFactory.createDataSource(properties);

        Connection connection = dataSource.getConnection();
~~~

## 2.4 Spring JDBC  
- Spring 框架对JDBC 的简单封装，提供了一个 `JDBCTemplate` 对象简化JDBC 的开发               

**创建JdbcTemplate对象**            
~~~java
    JdbcTemplate template = new JdbcTemplate(dataSource)
~~~

**CRUD操作**    
- `update(String sql)` 执行DML语句    
- `Map<String, Object> queryForMap(String sql)` 查询结果，封装为 Map，**只能查询一条记录**，列明为key，值为value       
- `List<Map<String, Object>> queryForList(String sql)` 查询结果集，封装为List，**List里存放的是Map**，一条记录封装为一个Map，装载到List           
- `List<T> query(String var1, RowMapper<T> var2)`  查询结果，封装为 JavaBean 对象         
- `T queryForObject(String var1, Class<T> var2)` 查询结果，封装为对象，也可以传入RowMapper       
- 自动释放资源，无需再手动释放资源


~~~java
public class DemoJDBCTemplate {
    public static void main(String[] args) {

        //获取连接池对象
        DataSource dataSource = JDBCDataSources.getDataSource();

        //创建Jdbctemplate对象
        JdbcTemplate template = new JdbcTemplate(dataSource);

        String sql = "update student set address = ? where id = 121";
        //传入sql语句 和 参数
        template.update(sql, "北京");

        sql = "select * from student";
        List<Student> students = template.query(sql, new BeanPropertyRowMapper<Student>(Student.class));

        for(Student student:students){
            System.out.println(student);
        }
    }
}
~~~

- **BeanPropertyRowMapper** 是 **RowMapper** 的实现类，通过无参构造创建对象，所以传入的类必须有 setter 方法，否则创建的全是初始化的对象       

# 3. Redis     
## 3.1 sql和nosql
- redis是一款高性能的NOSQL(Not Only SQL)系列的非关系型数据库
- 数据存储格式：nosql存储格式是 key,value形式、文档形式、图片等，sql只能存储基础类型
- 速度和成本：nosql数据存储在缓存中，查询速度快，成本低(开源)
- 扩展性：关系型数据库有类似join的夺标查询机制的限制，导致扩展艰难，nosql没有这种限制       
- nosql缺点：维护工具和资料有限(新技术)、不提供对sql的支持、不提供关系型数据库对事务的支持(Redis支持)
- 通常两者是互补的，一般数据存储在关系型数据库中，在nosql中备份存储关系型数据库的数据       

## 3.2 Redis简介
redis存储的是键值对
### 3.2.1 Redis支持的键值数据类型
**键始终都是字符串对象(string object)，值有以下几种：**
- 字符串 string
- 哈希类型 hash
- 列表类型 list
- 集合类型 set
- 有序集合类型 sorted set

### 3.2.2 Redis的应用场景
- 缓存(数据查询、短链接、新闻内容、商品内容等)
- 聊天室的在线好友列表
- 任务队列(秒杀、抢购、12306等)
- 应用排行榜
- 网站访问统计
- 数据过期处理(可以精确到毫秒)
- 分布式集群架构中的session分离         

### 3.2.3 启动
~~~
./redis-server.exe redis.windows.conf
~~~

## 3.3 Redis操作命令

### 3.3.1 redis按不同数据结构的命令

redis存储的是 key,value，其中key都是字符串，value有5中不同的数据结构        


| 数据结构                   | 存储类型       | 存储命令                           | 获取命令                           | 删除命令                        |
| -------------------------- | -------------- | ---------------------------------- | ---------------------------------- | ------------------------------- |
| 字符串<br>string           | 字符串         | set key value                      | get key value                      | del key                         |
| 哈希类型<br>hash           | 套娃           | hset key field value               | hget key field<br>hgetall key      | hdel key field                  |
| 列表类型<br>list           | 元素可重复     | lpush key value<br>rpush key value | lrange key start end<br>没有rrange | lpop key 删除并返回<br>rpop key |
| 集合类型<br>set            | 不可重复，无序 | sadd key value                     | smembers key                       | srem key                        |
| 有序集合类型<br> sortedset | 不可重复，排序 | zadd key score value               | zrange key start end (withscores)              | zrem key value                  |


~~~r
127.0.0.1:6379> set username zhangsan
OK
127.0.0.1:6379> get username
"zhangsan"
127.0.0.1:6379> del username
(integer) 1
127.0.0.1:6379> hset user username zhangsan
(integer) 1
127.0.0.1:6379> hset user password 123
(integer) 1
127.0.0.1:6379> hget user username
"zhangsan"
127.0.0.1:6379> hgetall user
1) "username"
2) "zhangsan"
3) "password"
4) "123"
127.0.0.1:6379> hdel user username
(integer) 1
127.0.0.1:6379> lpush user zhangsan
(integer) 1
127.0.0.1:6379> lpush user lisi
(integer) 2
127.0.0.1:6379> rpush user wangwu
(integer) 3
127.0.0.1:6379> lpop user
"lisi"
127.0.0.1:6379> lrange user 0 -1
1) "zhangsan"
2) "wangwu"
127.0.0.1:6379> rpop user
"wangwu"
127.0.0.1:6379> sadd username zhangsan
(integer) 1
127.0.0.1:6379> sadd username lisi
(integer) 1
127.0.0.1:6379> smembers username
1) "lisi"
2) "zhangsan"
127.0.0.1:6379> srem username lisi
(integer) 1
127.0.0.1:6379> zadd student 60 zhangsan
(integer) 1
127.0.0.1:6379> zadd student 20 lisi
(integer) 1
127.0.0.1:6379> zadd student 70 wangwu
(integer) 1
127.0.0.1:6379> zrange student 0 -1
1) "lisi"
2) "zhangsan"
3) "wangwu"
127.0.0.1:6379> zrem student zhangsan
(integer) 1
127.0.0.1:6379> zrange student 0 -1 withscores
1) "lisi"
2) "20"
3) "wangwu"
4) "70"
~~~

### 3.3.2 通用命令 
- `KEYS *` : 查询所有的键，支持正则表达式
- `TYPE key` ：获取键对应的value的类型
- `DEL key` : 删除指定的key value   
- `EXPIRE`
- `RENAME`
- `OBJECT`
## 3.4 Redis数据结构

### 3.4.1 简单动态字符串 SDS
Redis没有直接使用C语言传统字符串，而是构建了一种`简单动态字符串(Simple Dynamic Strign, SDS)`的结构，其中buf依然遵循以'\0'结尾，且'\0'的一个字节不用做计算长度
~~~c
struct sdshdr{
    int len;    //buf已使用字节数，即SDS字符串长度
    int free;   //buf未使用字节数
    char buf[]; //字节数组
}
~~~
![sdshdr](https://s1.ax1x.com/2020/11/09/B7mb8I.png)

**好处：**
- **O(1)时间获得字符串长度**，c语言的字符串长度需要遍历字符数组O(n)
- **避免缓冲区溢出**，进行拼接时检查free是否足够，不够就先扩容，再拼接。c语言的字符串拼接不检查，有可能缓冲区溢出，覆盖其他内容
- **减少修改字符串带来的内存重分配次数**，对于c，每次修改字符串都将进行内存重分配，耗时，数据库不允许这样的性能损失。SDS采用**空间预分配**和**惰性空间释放**，减少执行字符串增长、缩短操作所需要的内存重分配次数
  - 空间预分配：字符串扩展，若空间够用**直接分配**。否则若扩展后SDS<1MB，则分配`free=len`的额外空间；若扩展后SDS>1MB，分配`1MB`的额外空间
  - 惰性空间释放：字符串缩短后，不立即使用内存重分配来回收内存，SDS可用空间不变，将来拼接无需再次分配内存。也支持手动未使用空间，避免惰性空间释放策略造成内存浪费
- **二进制安全，可以存储'\0'**，buf保存的是二进制数据而非字符，由于记录了len，所以也支持存储'\0'，可以保存任意格式的二进制数据。(C字符串只能保存文本)。`客户端自己负责编码负责解码，SDS只存储二进制数据`
- **兼容部分C字符串**，保存文本数据的SDS可以重用string.h的函数

### 3.4.2 链表 list
- 双向链表
~~~c
//节点
typedef struct listNode{
    struct listNode *prev;
    struct listNode *next;
    void *value;
}listNode;

//封装成链表
typedef struct list{
    listNode *head;
    listNode *tail;
    unsigned long len; //链表长度
    void *(*dup)(void *ptr); //节点值复制函数
    void (*free)(void *ptr); //节点值释放函数
    int (*match)(void *ptr, void *key); //节点值对比函数
}list;
~~~

![list](https://s1.ax1x.com/2020/11/09/B7y0s0.png)

### 3.4.3 字典 map
应用：
**Redis数据库底层就是使用字典来实现的**，对数据库的增删改查操作都是构建在对字典的操作之上
字典也是**哈希键的底层实现之一**，当一**个哈希键包含的键值对比较多**时，或者**键值对中的元素都是比较长的字符串**时，Redis就会使用字典作为哈希键的底层实现

**字典的基本结构如下：**
字典中存放了两个哈希表，一般使用ht[0]，扩展和收缩hash表通过rehash，需要ht[1]的帮助
$sizemask = size-1$，用于哈希计算位置：$index=hash \& sizemask$
used表示哈希表中存放的Entry节点数量
![字典](https://s1.ax1x.com/2020/11/09/B7ROq1.png)

**rehash操作**
- 如果是扩容操作，ht[1]的大小等于 ht[0].used*2 (始终保持为$2^n$)
- 如果是收缩操作，ht[1]的大小等于 大于等于ht[0].used 的最小的2的幂
- 将ht[0]中所有键值对rehash到ht[1]
- 释放ht[0]，将ht[1]设置为ht[0]，在ht[1]新创建一个空白哈希表，用于下一次rehash

**渐进式rehash**
如果hash表中存放了很多键值对，一次性全部rehash代价太大，所以采用的是分多次、渐进式rehash
- 为ht[1]分配空间
- rehashindex设置为0，表示rehash工作开始
- **每执行一次对字典的操作(增删改查)，程序就将哈希表中rehashindex索引位置的所有键值对rehash到ht[1]，然后rehashindex+1**
- 当ht[0]中所有键值对都被rehash到ht[1]后，将rehashindex设置为-1，操作完成

**rehash期间所有对字典的操作都会在两个hash表中执行**
- 查找操作，如果在ht[0]中未找到，则去ht[1]中查找
- 添加操作则只添加到ht[1]，保证ht[0]的键值对只减不增，随着rehash慢慢变为空表

### 3.4.4 跳跃表 skipList
有序的数据结构，支持平均O(logN)、最坏O(N)的查找，大部分情况下效率可以和平衡树媲美，实现还比平衡树简单，所以多用跳表代替平衡树

应用：
跳表是**有序集合键**的底层实现之一，如果**有序集合包含的元素数量较多**，或者元素是**比较长的字符串**的时候，Redis就会使用跳表作为有序集合键的底层实现
跳表还作为集群节点中的内部数据结构。除此之外跳表在Redis中没别的用途了


**zskiplist结构**
- `zskiplistNode *header`：指向跳跃表的头节点
- `zskiplistNode *tail`：指向跳跃表的尾节点
- `int level`：跳跃表内最大的层数(表头节点层数不计算在内)
- `unsigned long length`：跳跃表长度(表头节点不计算)
~~~c
typedef struct zskiplist{
    struct zskiplistNode *header, *tail; //头尾指针
    unsigned long length;   //节点数量
    int level;  //最大层数
}
~~~

**zskiplistNode结构**
- `struce level[]`：层，每个层都有两个属性：**前进指针forward和跨度span**，**前进指针指示该层的前进后的zskiplistNode**，跨度指示前进指针所指节点和当前节点的距离，**通过累加走过的跨度就知道了排位**
- `zskiplistNode *backword`：BW指针，后退指针，用于从表尾向表头遍历时使用
- `double score`：分值，按分值从小到大排序
- `robj *obj`：成员对象。分值可以相同，obj却是唯一的，指向一个字符串对象(SDS)，分值相同的节点按照成员对象的顺序排序
~~~c
typedef struct zskiplistNode{
    struct zskiplistNode *backward; //后退指针
    double score;   //分数
    robj *obj;      //成员对象
    struct zskiplistLevel{  //层数组
        struct zskiplistNode *forward;  //前进指针
        unsigned int span;  //跨度
    }level[];
}zskiplistNode;
~~~


![跳跃表](https://s1.ax1x.com/2020/11/09/B7L2fs.png)


### 3.4.5 整数集合 intset
整数集合是redis用于保存整数值的集合抽象数据结构可以保存int16_t、int32_t、int64_t的整数值，**不保存重复值**

应用
因为**不保存重复值**，所以是**集合键的底层实现之一**，当一个集合只包含整数值的元素，并且集合元素数量不多时，Redis就使用整数集合作为集合键的底层实现

**intset结构**
- encoding：编码方式
- length：整数集合包含的元素数量
- contents：数组，虽然声明为int8_t，但是真正**类型取决于encoding方式**
~~~c
typedef struct intset{
    uint32_t encoding;
    uint32_t length;
    int8_t contents[];
}
~~~
![intset](https://s1.ax1x.com/2020/11/09/B7vNHf.png)

**升级**
将一个新元素添加到整数集合，如果新元素类型比整数集合现有元素类型长，就要进行升级(如，向encoding是int16_t中添加超过范围的int32_t)，由于升级机制的存在，**向整数集合中添加元素的最坏时间复杂度是O(N**)
升级过程：
- 根据新元素类型，扩展底层数组空间大小，并为新元素分配空间
- **将现有元素转换为新元素相同的类型**，从后向前(预留新元素位置)放置到新的空间上
- 将新元素添加到数组中，新元素只会是最大或最小的元素(正溢出或负溢出)

**不支持降级操作**

### 3.4.6 压缩列表 ziplist

应用
ziplist是**列表键和哈希键**的底层实现之一，当列表键只包含**少量的列表项**，并且列表项要么就是**小整数值**，要么就是长度**短的字符串**时，Redis就采用压缩列表来作为列表键的底层实现；当哈希键只包含少量的键值对，并且键值对的键和值都要么是小整数，要么是短的字符串时，Redis就采用压缩列表作为哈希键的底层实现

**ziplist结构**
- `zlbytes`：4字节，记录整个压缩列表占用的内存字节数
- `zltail`：4字节，压缩列表**最后一个entry节点**距离起始地址的字节长度，不是zlend，而是最后一个entry的距离
- `zllen`：2字节，压缩列表的节点数量。当数量小于UINT16_MAX(65535)时，就是真实节点数量，超过则需要遍历计算
- `entryX`：不定，节点列表，长度由节点具体保存的内容决定
- `zlend`：1字节，0xFF，结束标志

**entry结构**
- `previous_entry_length`：前一个节点的长度，字节为单位（小于254则用一个字节记录，大于254则用5个字节记录，第一个字节0xFE）
- `encoding`：表示content保存的数据类型(1，2，5字节的字节数组/各种类型的整数)，对于字节数组还要保存数组长度
- `content`：**保存字节数组或者整数**的具体内容

**ziplist的content中保存的是字节数组或者整数**！所以一般用来保存短的字符串或者数量不多的字符串和小整数！

**压缩列表的遍历方式**是：通过zlbytes和zltail，找到最后一个entry节点位置，**通过previous_entry_length从后向前遍历**！

![ziplist](https://s1.ax1x.com/2020/11/09/BHE4PI.png)

**连锁更新**
由于压缩链表的机制，如果一开始都是长度小于254字节的entry，要在头节点插入一个较长的entry，就会引发第二个节点的previous_entry_length增长到5字节，同样后面都有可能产生连带反应，可能全都需要扩展，同理，如果删除一个长entry后的短entry，同样会引发连锁更新
因为连锁更新，最坏的情况需要对压缩列表执行N次空间重分配操作，而每次空间重分配复杂度都是O(N)，所以连锁更新最坏复杂度为$O(N^2)$

![连锁更新](https://s1.ax1x.com/2020/11/09/BHZoDS.png)

## 3.5 对象
Redis并没有直接使用前面的SDS、list、dict、skiplist、ziplist、intset来实现键值对数据库。而是基于这些数据结构创建了一个**对象系统**，对象系统包含**字符串对象、列表对象、哈希对象、集合对象、有序集合**对象五种类型对象，每种对象都至少用了一种数据结构

对象的好处：
- Redis在执行命令前根据对象类型判断一个对象是否可以执行给定的命令
- 针对不同的使用场景，为对象设置多种不同的数据结构实现，优化效率
- Redis还实现了基于引用计数的内存回收机制，对象不再使用时，对象所占内存就会被释放
- 对象共享：多个数据库键共享同一个对象，节约内存
- 对象带有访问时间记录信息，帮助删除数据库键空转时间长的键

每当在Redis中创建一个键值对时，至少都会创建**两个对象**，一个是键对象，一个是值对象
**键对象总是一个字符串对象**，而值对象有五种，我们说一个键是`列表键`，其实是说这个键所对应的值是列表对象

**对象结构**
~~~c
typedef struct residObject{
    unsigned type:4;    //类型
    unsigned encoding:4; //编码
    void *ptr;          //指向底层实现数据结构的指针
    unsigned int ref;   //引用计数
    unsigned int lru;   //最后一次被访问时间
    ...
}
~~~

**对象类型**
|对象|type属性值|TYPE命令输出|
|---|---|---|---
|字符串对象|REDIS_STRING|"string"|
|列表对象|REDIS_LIST|"list"|
|哈希对象|REDIS_HASH|"hash"|
|集合对象|REDIS_SET|"set"|
|有序集合对象|REDIS_ZSET|"zset"|

**编码方式**
对象的ptr指针指向对象底层的数据结构，这个数据结构具体是什么由对象的encoding属性决定

|编码常量|对应底层数据结构|OBJECT ENCODING命令输出|
|---|---|---
|REDIS_ENCODING_INT|long类型整数|"int"
|REDIS_ENCODING_EMBSTR|embstr编码的简单动态字符串|"embstr"
|REDIS_ENCODING_RAW|简单动态字符串|"raw"
|REDIS_ENCODING_HT|字典|"hashtable"
|REDIS_ENCODING_LINKEDLIST|双端链表|"linkedlist"
|REDIS_ENCODING_ZIPLIST|压缩列表|"ziplist"
|REDIS_ENCODING_INTSET|整数集合|"intset"
|REDIS_ENCODING_SKIP_LIST|跳跃表|"skiplist"
`REDIS_ENCODING_INT`表示long类型整数

**不同对象类型和编码方式的对应表**

|对象类型|编码方式|
|:---:|:---:|
|string|**int、embstr、raw**|
|list|**ziplist、linkedlist**|
|hash|**ziplist、hashtable**|
|set|**intset、hashtable**|
|zset|**ziplist、skiplist**|

### 3.5.1 字符串对象
**编码方式**：字符串对象可以用**int、embstr、raw**三种方式存储
1. 当字符串对象保存的是整数值，并且在long类型范围内，字符串对象就会把整数值保存在ptr属性中(void*转换为long)
2. 当字符串对象保存的是字符串，并且长度小于等于39字节，就用embstr编码方式保存
3. 当字符串对象保存的是字符串，并且长度大于39字节，就用简单动态字符串SDS存储(void*转换为raw)

![字符串raw](https://s1.ax1x.com/2020/11/09/BHzvss.png)

**embstr和raw**
- 底层都是使用redisObject结构和sdshdr结构来表示字符串对象
- raw编码会调用**两次内存分配**函数，**分别创建redisObject和sdshsr**，释放raw也需要调用两次内存释放函数
- embstr编码对于短字符串，**将redisObject和sdshdr分配到一块连续的空间**，创建只需要一次内存分配，释放也只需要一次
- Redis没有为embstr编码的字符串提供修改方式，执行修改后，程序会将embstr转换为raw，再修改，所以**embstr编码的字符串一旦修改就变成了raw**

字符串对象可以保存
1. **long类型整数**（int编码）
2. **超过long的整数、浮点数、字符串**（embstr或者raw编码）

`STRLEN`返回的是字节长度

可以作为轻量级的文件系统
~~~
SET /root/../xx.jpg  <图片的字节数组>
~~~

**字符串命令的实现**

![字符串命令实现](https://s1.ax1x.com/2020/11/09/BbPPB9.png)

### 3.5.2 列表对象
**编码方式**：列表对象可以用**ziplist、linkedlist**两种方式存储
**编码转换**：列表对象少于512个，且每个长度都小于64字节，使用ziplist存储，否则使用linkedlist存储
~~~
redis> RPUSH numbers 1 "three" 5
(integer) 3
~~~

![列表ziplist](https://s1.ax1x.com/2020/11/09/BHOQJJ.png)
![列表linkedlist](https://s1.ax1x.com/2020/11/09/BHLKgI.png)

链表中，每个节点保存了一个**字符串对象**，字符串对象保存1和5采用int编码，保存three采用embstr编码，redis中多种对象都嵌套了字符串对象！

![列表命令实现](https://s1.ax1x.com/2020/11/09/BbCz1U.png)


### 3.5.3 哈希对象
**编码方式**：哈希对象可以用**ziplist、hashtable**两种方式存储

ziplist方式：每当有新键值对要存入哈希对象时，程序把保存了键的压缩列表节点存入压缩列表的表尾，然后把保存了值的压缩列表节点存入压缩列表的表尾，因此，**哈希对象的一对键值对总是紧挨在一起的，保存键的在前，保存值的在后**
hashtable方式：使用字典方式存储，字典的每个键和值都是StringObject，分别保存键和值
**编码转换**：键值对数量不超过512，且每个长度都小于64字节，使用ziplist，否则使用hashtable

![哈希hashtable](https://s1.ax1x.com/2020/11/09/BbSgwq.png)

**哈希命令的实现**
![哈希命令的实现](https://s1.ax1x.com/2020/11/09/BbpRud.png)]



### 3.5.4 集合对象
**编码方式**：集合对象可以用**intset、hashtable**两种方式存储
使用hashtable方式存储的话，hashtable每个键都是StringObject，而**值都是NULL**
**编码转换**：集合对象少于512个，且都是整数值时，使用intset存储，否则使用hashtable存储

![集合hashtable](https://s1.ax1x.com/2020/11/09/Bb95L9.png)

**集合命令的实现**
![集合命令的实现](https://s1.ax1x.com/2020/11/09/BbCwY6.png)


### 3.5.5 有序集合
**编码方式**：有序集合可以用**ziplist、skiplist+hashtable**两种方式存储
ziplist方式：两个紧挨着的节点分别存储元素值和元素的分值score，**按分值递增排序的方式存放**
skiplist方式：**同时使用了dict和skiplist**，使用dict使随机查找成员的score变为O(1)，使用skiplist按score排序，空间换时间，使两种查询方式效率都高 
实际中，字典和跳跃表是**共享元素的成员和分值**的，不会造成数据重复，浪费空间

**编码转换**：有序集合对象少于128个，且每个元素长度都小于64字节，使用ziplist，否则使用skiplsit

![有序集合skiplist](https://s1.ax1x.com/2020/11/09/BbFmeH.png)

**有序集合命令的实现**
![有序集合命令的实现](https://s1.ax1x.com/2020/11/09/BbF279.png)


### 3.5.6 类型检查
由于Redis有两类命令：针对不同对象的以及通用的
对于针对特定对象的命令，redis会先做类型检查，确保指定类型的键可以执行指定的命令

- 客户端发出命令
- 服务器通过redisObject的**type属性**检查key值对应对象类型是否是执行改命令所需的类型
- 是才执行，否则返回类型错误

至于底层用不同数据结构来实现对象，直接**利用对象的多态性**，就可以正确执行对应数据结构的函数了

### 3.5.7 内存回收和对象共享
使用引用计数的方式进行内存的回收

得益于引用计数，可以通过该方式实现对象共享
Redis在初始化服务器时，会创建一万个字符串对象，包含0-9999的所有整数值，用于共享
不共享复杂对象：验证复杂的共享对象和目标对象是否完全相同的代价太大了
所以一般只对包含整数值的字符串对象进行共享

### 3.5.8 对象的空转时长
**redisObject除了type、encoding、ptr、refcount属性之外，还包含lru属性**，用于记录对象最后被访问的时间
`OBJECT IDLETIME`命令可以查看给定键的空转时长（当前时间-lru时间），这个命令本身访问键的值对象时不会更新对象的lru属性
此外，如果服务器打开了`maxmemory`选项，内存回收算法选择为`volatile-lru`或`allkeys-lru`，则在内存占用超过maxmemory后，空转时间长的键就会被服务器释放掉，回收内存

## 3.6 单机数据库实现

### 3.6.1 数据库
Redis数据库的结构是redisDb，Redis服务器将所有数据库都保存在redisServer结构的db数组中（每个元素都是redisDb），默认数组大小是16，即Redis服务器默认会创建16个数据库，默认使用的是0号数据库
同时redisClient结构的db属性记录了客户端目前链接的目标数据库，是指向redisDb的指针
- 切换数据库：客户端使用`SELECT`命令切换目标数据库，即**修改redisClient.db指针，指向目标redisDb**
~~~
127.0.0.1:6379> set msg "hello"
OK
127.0.0.1:6379> select 1
OK
127.0.0.1:6379[1]> get msg
(nil)
~~~

**键空间**：Redis是键值对的服务器，每个redisDb结构中都有一个dict字典，用于**保存数据库中所有的键**，这个字典就是键空间(key space)
数据库的添加操作，其实就是添加一个新键值对到键空间。
删除更新取值同理
`FLUSHDB`清空数据库其实就是清空键空间的键值对
![键空间](https://s1.ax1x.com/2020/11/09/Bbuwtg.png)

**读写键空间的维护操作**
- 读取键后，服务器会根据是否命中来更新键空间的命中(hit)次数和未命中次数(miss)，可以通过`INFO status`命令的`keyspace_hits`和`keyspace_misses`属性查看
- 读取键后，服务器还会更新键的LRU时间，用于计算键的闲置时间，使用`OBJECT idletime <key>`命令可以查看闲置时间
- 读取键，发现键已经过期(超过生存时间)，则会删除键，然后才执行剩余操作
- 服务器每次修改一个键之后，都会将 dirty 计数器+1，这个计数器会触发服务器的持久化以及复制操作
- 如果配置了通知，键被修改后，还会发送相应的通知

**键的过期时间**
- `EXPIRE <key> <秒>`或`PEXPIRE <key> <秒>`： 设置多少秒之后过期，到时间后服务器自动删除这个键。
- `EXPIREAT <key> <毫秒>`或`PEXPIREAT <key> <毫秒>`
- 实际上都会转换成PEXPIREAT执行
- `PERSIST <key>` 可以**移除键的过期时间**
- `TTL <key>` 返回键的剩余生存时间，单位秒，毫秒可以使用PTTL
~~~
127.0.0.1:6379> EXPIRE msg 5
(integer) 1
127.0.0.1:6379> get msg
"hello"
127.0.0.1:6379> get msg
(nil)
~~~

**过期字典**：redisDb中的expires字典保存了所有键的过期时间

**redisDb主要就是由dict和expire两个字典构成**，dict保存键值对，expires保存键的过期时间
![数据库](https://s1.ax1x.com/2020/11/10/BqCbZ9.png)

**过期键删除策略**：
- 定时删除：设置键过期时间的同时创建一个定时器，让定时器在键的过期时间到来时立即执行键的删除操作。
  - 可以保证尽快删除，对内存友好，但是对于集中大量过期的情况增加了CPU的负担
- 惰性删除：**获取时删除**，每次从键空间获取键时检查过期时间是否到达，过期时间到了就删除，没到就返回键。
  - 对CPU时间友好，不会浪费CPU时间，但是对内存不友好，过期键依然占用内存
- 定期删除：每隔一段时间就检查一遍过期字典，删除过期键
  - 折衷方案，难点在于确定删除操作的执行时长和频率
Redis实际采用的是**惰性删除和定期删除相结合**的方式，在CPU时间和内存使用之间取得平衡。定期删除只会随机检查部分键的过期时间，保证性能


**过期键对RDB的影响**
- 执行SAVE、BGSAVE命令时，程序只会将未过期的数据保存到RDB文件中，过期数据会被忽略
- 服务器以主服务器模式运行，载入RDB文件时，过期的键会被直接忽略
- 服务器以从服务器模式运行，所有RDB文件的键都会载入到数据库，但是主从服务器同步时，从服务器数据会被清空，所以也不会造成影响

**过期键对AOF的影响**
- AOF模式运行，键过期后如果未被惰性删除或定期删除，则AOF文件不会进行操作。惰性、定期删除后程序会向AOF文件追加一条DEL命令显示记录该键已被删除
- `BGREWRITEAOF`执行AOF文件重写过程时，已过期键不会被保存到重写后的AOF文件中

**过期键对复制模式的影响**
- 复制模式下，从服务器的数据删除动作由主服务器控制，当主服务器删除一个过期键后，会向所有从服务器发送DEL命令，从服务器删除这个过期键。**从服务器只有接收到主服务器的DEL命令才会删除过期键**
- 主服务器未发送DEL命令时，即使从服务器中数据过期也不会删除，而是继续**像未过期数据一样提供服务**
- **过程**：当主从服务器的message键过期后，客户端请求从服务器的message键，正常返回。之后又有客户端请求主服务器的message键，主服务器发现过期，于是返回空，并删除message键，同时向从服务器发送DEL命令，之后主从服务器就都删除了message键

**通知**
- 键空间通知：`SUBSCRIBE keyspace@0:message`，记录message键上的所有操作
- 键事件通知：`SUBCRIBE keyevent@0:del`，记录del命令被哪些键执行过

### 3.6.2 RDB快照持久化
RDB持久化可以将内存中的数据库状态保存到磁盘，可以手动执行也可以根据配置定期执行，生成压缩的二进制文件：RDB文件，并且可以还原
**RDB快照是某个时间点的一次全量数据备份，是压缩的二进制文件，存储紧凑**

- **优点**：
  - RDB文件小，适合定时备份，用于灾难恢复
  - RDB文件加载比AOF快很多，因为直接存储的数据
- **缺点**：
  - 无法做到实时持久化，两次BGSAVE期间的数据不安全，不适用于实时性要求高的场景
  - fork子进程属于重量级操作，fork期间阻塞redis主进程



**RDB文件载入**：文件载入是在服务器**启动时自动执行的**，RDB文件载入过程中服务器会一直阻塞直到载入完成，没有专门用于主动载入RDB文件的命令。另外，由于AOF文件更新频率高，只有**AOF持久化功能关闭**时，才使用RDB文件还原数据库状态，否则使用AOF文件还原数据库。

**SAVE和BGSAVE**
- `SAVE`命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，阻塞期间不能处理任何命令
- `BGSAVE`是创建子进程来创建RDB文件，不会阻塞服务器进程(**fork子进程期间需要阻塞**)。**BGSAVE执行期间会拒绝客户端的SAVE和BGSAVE命令**，如果期间有`BGREWRITEAOF`命令，则会被延迟到BGSAVE完毕之后执行。而BGREWRITEAOF期间的BGSAVE命令则会被直接拒绝。虽然这两个命令都是子进程进行大量磁盘写入操作，可以同时进行，但考虑到性能问题，Redis选择不同时执行。
可以通过配置redis的conf文件，让服务器每隔一段时间执行BGSAVE，用户可以指定多个save条件，任一条件满足即执行`BGSAVE`。服务器每隔`100ms`执行一个周期函数，检查save选项的条件是否满足
~~~c
//Redis默认的配置：以下三个条件，任意一个满足时，即执行BGSAVE
save 900 1          //900秒内对数据库进行了至少1次修改
save 300 10         //300秒内对数据库进行了至少10次修改  
save 60 10000       //60秒内对数据库进行了至少10000次修改
~~~
服务器用saveparams数组记录了save选项设置的条件，此外，服务器还维持了一个`dirty`属性，表示上次SAVE、BGSAVE之后数据库被修改的次数，`lastsave`属性记录上一次成功执行SAVE、BGSAVE的时间戳

**RDB文件结构**

![RDB文件结构](https://s1.ax1x.com/2020/11/10/BqOBl9.png)

### 3.6.3 AOF日志持久化
AOF(append only file)，与RDB保存键值对的方式不同，AOF 是通过**保存Redis服务器所执行的写命令**来记录数据库状态的

**AOF日志是持续增量的备份，是文本文件，是目前的主流方式**

- **优点**：
  - 追加写日志文件，对服务器性能影响较小，速度比RDB快，消耗内存较少
- **缺点**：
  - 日志文件太大，需要不断的AOF重写，进行瘦身
  - 即使经过AOF重写，由于是文本文件，依然较大
  - 命令式恢复数据比RDB慢很多

**配置开启AOF：**
- 配置redis.windows.conf
- appendonly 默认为no，修改为yes
~~~java
appendonly yes   

//appendfsync always    //每一次写入都进行主动持久化
appendfsync everysec    //写入后每隔一秒进行一次主动持久化
//appendfsync no        //不进行主动持久化，由操作系统自己决定何时持久化
~~~
#### 持久化的实现

AOF持久化功能的实现可以分为 **命令追加(append)、文件写入、文件同步（sync）** 三个步骤实现
命令追加：AOF功能打开后，如武器执行完一个写命令就会以redis命令协议的格式**将被执行的写命令追加到服务器的aof_buf缓冲区**
文件写入和同步：通过设置`appendfsync`实现是否将aof_buf缓冲区内容写入到AOF文件
|appendfsync选项值|flushAppendOnlyFile函数行为|效率和安全性|
|---|---|---|
|always|始终将aof_buf缓冲区的所有内容写入并同步到AOF文件|效率最低，安全性最高
|everysec|将aof_buf缓冲区所有内容写入到AOF文件，如果距离上次同步AOF文件时间超过一秒，则还要进行AOF文件同步，有一个线程单独完成线程同步|效率足够，只有1秒不安全，也不错
|no|将aod_buf缓冲区所有内容写入到AOF文件，但是不主动对AOF文件进行同步，何时同步由操作系统决定|效率最高，安全性最低
**为什么写入文件还有同步？** 因为操作系统为了提高文件写入效率，用户调用write写入时，操作系统也将数据存放到内存缓冲区，而不是立即写入，只有当缓冲区空间满了，或者超过指定时限才进行真正的写入。为此，redis同步是调用操作系统的fsync和fdatasync函数强制让操作系统立即将内存缓冲区的数据写入到硬盘

数据还原的时候，根据AOF文件中的命令，重新执行一遍写操作即可（通过**伪客户端**）

#### 文件重写的实现
一个key可能被写入多次，而重复记录之前的过期无效写入就可能导致AOF文件过大，所以Redis提供了文件重写技术，重写后大大降低AOF文件的大小
**原理：** 首先从数据库中读取当前的键的值，然后用一条命令去记录键值对的写入操作，代替之前的多条命令。
~~~
127.0.0.1:6379> sadd animals pig
(integer) 1
127.0.0.1:6379> sadd animals dog
(integer) 1
127.0.0.1:6379> sadd animals cat
(integer) 1

上述三条命令重写时，直接读取animal键值，使用sadd animals pig dog cat  一条命令替代三条命令即可
~~~
同时，为了避免执行命令时客户端缓冲区溢出，对于包含元素数量特别多的键，采用多条命令来记录键的值。目前`REDIS_AOF_REWRITE_ITEMS_PER_CMD=64`，即一个SADD命令最多包含64个元素

**后台重写**
`BGREWRITEAOF`命令，AOF重写是由子进程进行的，父进程继续处理命令请求。**使用子进程而不用子线程是因为子进程有父进程的内存空间拷贝(快照！)，父进程对内存的修改对于子进程是不可见的，两者互不影响，保证安全性**

数据不一致问题：AOF持久化过程中产生的键值对的改变问题。解决办法，创建AOF重写操作的子进程后，Redis使用了一个AOF重写缓冲区，Redis服务器执行完一个写命令后，会**将写命令同时保存到AOF缓冲区(aof_buf)和AOF重写缓冲区**，AOF重写完成后，还要将AOF重写缓冲区的内容再次写入到新的AOF文件中，最后再原子地覆盖原有AOF文件

![后台重写](https://s1.ax1x.com/2020/11/10/BLX4JO.png)

### 3.6.4 事件
Redis服务器是一个事件驱动程序。需要处理两类事件
文件事件：即来自客户端或其他redis服务器的套接字连接、通信产生相应事件的抽象
事件事件：redis服务器一些操作需要在给定的时间点执行，时间事件就是这些定时操作的抽象

#### 文件事件
Redis基于Reactor模式开发了自己的网络事件处理器，即文件事件处理器(file event handler)
文件事件处理器使用**IO多路复用程序**`epoll`同时监听多个套接字，根据套接字目前执行的任务来为套接字关联不同的事件处理器
被监听的套接字准备好执行accept、read、write、close等操作时，相应的文件事件就会产生，文件事件处理器调用套接字之前关联好的事件处理器来处理这些事件
**文件事件处理器以单线程运行，通过IO多路复用技术实现了同时监听多个套接字**

![文件事件处理器](https://s1.ax1x.com/2020/11/10/BLx4YV.png)
尽管多个文件事件(套接字)可能会并发的出现，但是IO多路复用总是将所有产生事件的套接字放在队列里，以有序、同步、每次一个套接字的方式向事件分派器传送套接字，当一个套接字产生的事件处理完毕后，IO多路复用程序才会继续分派下一个套接字

**事件类型**：AE_READABLE 和 AE_WRITABLE，IO多路复用技术可以同时监听一个套接字的读写事件。**如果一个套接字同时产生了这个两种事件，那么文件事件分配器先分配读事件，后分配写事件**

**文件事件处理器：** 
1. 连接应答处理器：对连接服务器监听套接字的客户端进行应答
2. 命令请求处理器：当连接应答成功后，客户端发出的命令请求就会产生AE_READABLE事件，由命令请求处理器执行
3. 命令回复处理器：将命令请求的执行结果返回给客户端。当客户端准备好接收服务端的命令回复时，就会产生AE_WRITABLE事件
服务器启动后就监听AE_READABLE事件，有客户端发起连接请求，就产生AE_READABLE事件，由连接应答处理器处理。然后创建该客户端套接字，将该套接字的AE_READABLE事件和命令请求处理器关联，客户端就可以发送命令请求了。执行命令将产生返回结果，于是服务器将客户端套接字的AE_WRITABLE事件与命令回复处理器进行关联，当客户端尝试读取命令回复时，客户端套接字就会产生AE_WRITABLE事件，触发命令回复处理器执行，当回复全部写入到套接字后，服务器就结束客户端套接字的AE_WRITABLE事件和命令回复处理器的关联

#### 时间事件
Redis时间事件分为：定时事件和周期性事件
时间事件由：事件id，事件到达事件when，事件处理器timeProc 三部分组成。多个事件组成一个**time_events无序链表(不按when排序)**，每次事件事件执行器运行时就遍历链表，查找已到达时间的事件，调用相应事件处理器处理
![时间事件](https://s1.ax1x.com/2020/11/10/BO94HJ.png)

Redis有很多周期性事件(`serverCron函数`)：更新服务器状态，清理过期键值对，关闭和清理连接失效的客户端，AOF和RDB持久化，对从服务器进行同步，对集群进行定期同步和连接测试等等

服务器轮流处理文件事件和时间事件，合作关系，不会进行抢占

时间事件的实际处理时间通常要比设定值晚一些


### 3.6.5 客户端
通过使用**IO多路复用**技术实现的文件事件处理器，**Redis服务器使用单线程单进程的方式处理命令请求**，并于多个客户端进行网络通信

对每个与服务器连接的客户端，Redis都为这些客户端建立了`redisClient`结构，保存客户端当前的状态信息，以及执行相关功能时需要用到的数据结构。`clients`链表中记录了所有的`redisClient`

~~~c
struct redisServer{
    //...
    list *clients; //redisClient结构的链表
}
~~~

**伪客户端**：**由于redis命令只能只能在客户端的上下文中被执行，所以Lua脚本和AOF文件执行，都需要创建伪客户端(没有网络连接的客户端)**

#### 客户端clients的属性
通过`CLIENT list`命令可以查看客户端的属性
通过`CLIENT setname`给客户端设置名字
~~~
127.0.0.1:6379> client list
//age是客户端创建时间，idle是最后一次交互时间
id=7 addr=127.0.0.1:65449 fd=11 name= age=70622 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client
127.0.0.1:6379> client setname "mylocal"
OK
127.0.0.1:6379> client list
id=7 addr=127.0.0.1:65449 fd=11 name=mylocal age=70752 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client
~~~
**套接字描述符**：`fd`，-1表示伪客户端(请求来自于AOF文件还原数据库操作或者Lua脚本，而不是网络，无需套接字)。大于-1的整数表示普通客户端连接
**名字**：客户端的`name`域默认是空的，可以自己使用`CLIENT setname`设置名字，让客户端身份更清晰
**标志**：`flags`，记录客户端的角色以及目前所处状态。如主从服务器角色，版本，专用于Lua脚本的伪客户端；阻塞中，事务中，。。。
**输入缓冲区**：`querybuf` 临时保存客户端发送的命令请求，动态大小，但不能超过1GB，否则服务器将关闭该客户端
**命令和命令参数**：使用一个数组`argv`，表示`querybuf`中一条命令，argv[0]存放命令，后面依次存放命令参数。
**命令表**：一个dict，服务器根据argv[0]的值去`命令表`中查找对应的`实现函数`。
**输出缓冲区**：一个固定缓冲区保存长度小的回复，一个可变缓冲区是链表，可以保存很长的命令(不超过硬性限制)
**身份验证**：一个`authenticated`属性，记录该客户端是否通过验证，通过`AUTH 密码`命令进行验证。仅在服务器启用身份验证功能后使用
**时间**：`ctime`客户端创建时间(CLIENT list age域)，`lastinteraction`最后一次交互时间(CLIENT list idle域)

#### 创建客户端
**创建普通客户端**：(网络连接的普通客户端)，客户端使用connect函数连接服务器时，服务器调用事件连接处理器，为客户端创建相应`redisClient`，并添加到`clients`链表末尾

**创建Lua脚本伪客户端**：服务器初始化时创建一个负责执行Lua脚本中所包含Redis命令的为客户端`redisClient`，放到`lua_client`属性中，**lua_client伪客户端只有在服务器被关闭时才会关闭**

**创建AOF文件的伪客户端**：服务器载入AOF文件时，会创建一个用于执行AOF文件包含的Redis命令的伪客户端，**载入完成后便关闭这个伪客户端**


#### 关闭普通客户端
1. 客户端进程退出或被杀死，网络连接关闭，造成客户端被关闭
2. 客户端发送了带有不符合协议格式的命令请求
3. 客户端成为`CLIENT KILL`命令的目标
4. 服务器设置了`timeout`配置，客户端空转超时，关闭。(客户端是主服务器时不会关闭)
5. 客户端发送的命令请求超过输入缓冲区大小(1GB)
6. 服务器发送给客户端的命令回复超过输出缓冲区限制


### 3.6.6 服务器

#### 命令请求执行过程
客户端键入命令请求时描绘转换成协议格式，通过连接到服务器的套接字，将协议格式的命令发送给服务器。
服务器读取套接字中协议格式的命令请求，保存到客户端状态的输入缓冲区中
对输入缓冲区命令进行分析，提取命令、参数、参数个数，将参数保存到`redisClient.argv`
调用命令执行器执行命令：`redisClient.cmd`命令表中查找到命令，检查参数个数，检查服务器状态(maxmemory,SAVE,等)，调用命令的实现函数执行`setCommand(redisClient *c)`
函数的返回则保存到`redisClient.buf`中
后续工作：写命令写入AOF缓冲(若开启)，更新redisCommand.milliseconds属性，慢查询日志

#### serverCron函数
Redis中的serverCron函数每隔100ms执行一次，负责管理服务器的资源，并保持服务器自身的良好运转

**更新服务器时间缓存**：为避免频繁系统调用获取时间，服务器每隔100ms更新一次`unixtime`和`mstime`属性，用于精确度要求不高的时间，如打印日志、LRU时钟、持久化等。对于**键的过期时间、慢查询日志**这种高精度时间，服务器还是会执行**系统调用**来获取准确时间
**更新LRU时钟**：每10秒更新一次`redisServer.lruclock`，每个redis对象的`redisObject.lru`属性保存了最后一次被访问时间，于是计算键的空转时长`idle=redisServer.lruclock-redisObject.lru`
**更新服务器每秒执行命令次数**：每隔100ms执行一次，估算，期间每毫秒命令次数*1000
**更新服务器内存峰值记录**
~~~
127.0.0.1:6379> INFO stats                        
...  
instantaneous_ops_per_sec:10   
...      

127.0.0.1:6379> INFO memory
...
used_memory_peak:722520
used_memory_peak_human:705.59K
...
~~~
**处理SIGTERM信号**：收到该信号时，打开服务器状态的shoutdown_asp标识，每次serverCron函数运行时检查标识，决定是否关闭服务器(服务器关闭自身之前会进行RDB持久化)
**管理客户端资源**：每次执行serverCron都调用clientsCron函数，会对一定数量的客户端检查，是否连接超时，输入缓冲区是否超过阈值，超时和超阈值要进行关闭
**管理数据库资源**：每次执行都会调用databaseCron函数，检查一部分数据库，删除过期键(即定时删除)，对字典进行收缩
**执行被延迟的BGREWRITEAOF**：BGSAVE期间的BGREWRITEAOF会被延迟到BGSAVE执行完成之后，所以要检查是否有BGREWRITEAOF，有，且此时没有BGSAVE和BGREWRITEAOF在执行，则执行
**检查持久化操作的子进程状态**：如果RDB文件生成完毕或者AOF文件重写完毕，要进行后续操作(替换原有文件)
**将AOF缓冲区内容写入AOF文件**
**关闭异步客户端**：缓冲区超出限制的客户端
**增加Cronloops计数器值**：cronloops记录了serverCron函数执行次数


#### 初始化服务器
创建 struct redisServer 实例
载入配置 
初始化数据结构
还原数据库状态（AOF/RDB）
执行事件循环

## 3.7 多机数据库

### 3.7.1 复制
通过命令`SLAVE ip port`去复制目标ip的数据库的数据，被复制的目标数据库是主服务器(master)，发出slave的服务器是从服务器(slave)
~~~
127.0.0.1:6379> SLAVAOF 127.0.0.2 12345
//那么127.0.0.1:6379将成为127.0.0.2:12345的从服务器
~~~

#### 2.8以前的旧版复制
Redis的复制功能分为`同步(sync)`和`命令传播(command propagate)`两个操作
同步是将从服务器的数据库状态更新至与主服务器一致
命令传播是在主服务器的数据库状态被修改，导致主服务器数据库状态不一致时，让主从服务器状态重新一致

**同步**
1. 客户端向从服务器发送`SLAVEOF 主服务器`命令后，从服务器通过向主服务器发送`SYNC`命令来实现**同步操作**，将从服务器数据库状态更新至与主服务器一致
2. 收到`SYNC`的主服务器执行`BGSAVE`，在后台生成RDB，**并使用缓冲区记录在BGSAVE期间又执行了的写命令**
3. 主服务器BGSAVE完后，将RDB文件发送给从服务器，从服务器收到后**进行载入**
4. 从服务器将**缓冲区**所有的`写命令`发送给从服务器，从服务器**执行写命令**，更新至主服务器当前状态

**命令传播**
同步操作后，客户端向主服务器发起修改键值的写命令，导致主从服务器数据不一致，于是主服务器需要对从服务器执行**命令传播操作**，即将自己执行的写命令发送给从服务器执行

**旧版复制功能的缺陷**
旧版，从服务器在初次连接主服务器或者断线重连后，都需要进行完全的复制操作`SYNC`，复制完全的RDB文件。但是对于断线后没有必要完全复制，效率太低，只需要断线期间的命令进行传播即可。
SYNC效率非常低，因为**SYNC会让主服务器执行BGSAVE**，耗费大量CPU、内存、IO！传送RDB又浪费很多带宽，载入RDB期间从服务器需要阻塞，无法处理命令请求

#### 2.8开始的新版复制
使用`PSYNC`命令替代`SYNC`命令，PSYNC具有完整重同步和部分重同步两种模式
完整重同步用于初次复制
部分重同步用于从服务器断线重连，只发送断线期间的命令

部分重同步功能实现：**主从服务器的复制偏移量、主服务器的复制积压缓冲区、服务器的运行ID**

**复制偏移量**
主从服务器都会维护一个复制偏移量，主服务器每次发送N字节数据就会将偏移量加N，从服务器收到N字节数据也会将偏移量加N。
当从服务器断线后，发送`PSYNC`时报告自己的偏移量，主服务器发现和自己的偏移量不相同，就会进行部分重同步

**复制积压缓冲区**
主服务器维护了一个固定长度的FIFO队列，默认1MB(可修改，从服务器平均重连时间$second*write\_size\_per\_second$)。由于固定长度，队列满时，不得不让队首出队，从而从队尾入队
当主服务器进行命令传播时，**将命令发送给所有从服务器，同时将命令写入复制积压缓冲区**，同时复制积压缓冲区中每个字节都记录了**复制偏移量**
如果从服务器发送的`PSYNC`中的偏移量在复制积压缓冲区的范围内，就从offset+1开始进行部分重同步，否则才进行完整重同步

**服务器运行ID**
每个服务器启动时都会生成40个随机16进制字符序列ID。
从服务器初次复制时，发送`PSYNC ? -1`，请求完整重同步
主服务器将自己ID发送给从服务器`runid`
从服务器断线重连后发送`PSYNC <runid> <从offset>`，带着之前的主服务器ID以确认是复制该主服务器
主服务器如果返回`+FULLRESYNC <runid> <主offset>`，则需要执行完整冲突公布
主服务器如果返回`+CONTINUE` 说明是增量复制
主服务器如果返回`-ERR` 说明主服务器版本低于2.8，识别不了PSYNC，从服务器将发起SYNC命令进行完整重同步

![复制过程](https://s3.ax1x.com/2020/11/11/BvcyZQ.png)

#### 心跳检测
命令传播阶段，从服务器每秒一次向主服务器发送`REPLCONF ACK <replication_offset>`命令，其中offset是从服务器当前的复制偏移量，作用：检测网络连接状态、辅助实现min-slaves、检测命令丢失

**检测网络连接状态**：主服务器超过1秒每收到从服务器的REPCONF ACK，就知道连接出问题了，向主服务器发送`INFO replicaiton`命令，可以查看所有从服务器的最后一次REPLCONF ACK命令距离现在多少秒，`lag`的值

**辅助实现min-slaves**：例如设置主服务器`min-slaves-to-write 3, min-slaves-max-lag 10` 表示从服务器数量少于3，或者延迟都大于等于10时，主服务器拒绝写命令

**检测命令丢失**：主服务器发现从服务器发来的偏移量小于自己的偏移量，就把复制积压缓冲区中从服务器缺少的数据重发给从服务器

Redis2.8以前灭有REPLCONF ACK命令和复制积压缓冲区，不会补发从服务器丢失的数据，不安全


### 3.7.2 Sentinel

![sentinel和服务器](https://s3.ax1x.com/2020/11/12/BzCvHf.png)

Sentinel是Redis高可用的解决方案，一个Sentinel系统由多个Sentinel组成，可以监听任意多个主服务器，以及这些主服务器下的从服务器。当某个主服务器下线时，从服务器的复制操作将被中止，Sentinel系统察觉到主服务器下线，**自动将下线主服务器的某个从服务器升级为新的主服务器**，然后向其他从服务器发送新的复制命令，让其他从服务器复制新的主服务器，同时Sentinel还继续监视着原来的主服务器，当它重新上线时会被降级为从服务器                

**Sentinel本质是运行在特殊模式下的Redis服务器**

#### Sentinel的初始化
`redis-sentinel /path/to/sentinel.conf`
或`redis-server /path/to/sentinel.conf --sentinel`

Sentinel初始化过程
1. 初始化服务器：Sentinel本身就是Redis服务器，所以要初始化一个普通的Redis服务器，但不载入RDB/AOF
2. 将普通Redis服务器使用的代码替换成Sentinel专用代码，将`PING, SENTINEL, INFO, SUBSCRIBE, UNSUBSCRIBE, PUBSUNSCRIBE`七个命令变为Sentinel专有，其他命令不使用
3. 初始化Sentinel状态：初始化一个`SentinelState`结构，保存所有和Sentinel有关的状态
    ~~~c
    struct sentinelState{
        //当前纪元，用于实现故障转移
        uint64_t current_epoch;

        //所有被该sentinel监视的主服务器的字典
        dict *masters;
        
        //是否进入TILT模式
        int tilt;  
        
        //目前正在执行的脚本数量
        int running_scripts;  
        
        //进入TILT模式的时间
        mstime_t tilt_start_time;  
        
        //最后一次执行时间处理器的时间
        mstime_t previous_time;  
        
        //所有要执行的用户脚本队列
        list *scripts_queue;  
    }sentinel;
    ~~~
4. 根据配置文件，初始化Sentinel的监视主服务器列表：sentinel的masters字典中存放了所有的被监视主服务器的相关状态，如名字，id，地址，判断下线的无响应时间等等
5. 创建连向主服务器的网络连接：sentinel将成为主服务器的客户端，可以向主服务器发送命令，从回复中获取相关信息。sentinel会对每个监视的主服务器创建两个连接，一个是命令连接，一个是订阅连接

#### 获取主从服务器信息
**每隔10秒向主从服务器发送一次INFO命令**
- sentinel每隔10秒通过命令连接发送一次`INFO`命令给所有监视的主服务器，获得命令回复并保存/更新到主服务器的`sentinelRedisInstance`结构中，并创建/更新`slaves`字段的子服务器的ip:port的`dict`，命令回复包含两方面信息：
    1. 主服务器本身信息：run_id，role
    2. 主服务器下属从服务器信息：slave字段中记录了所有从服务器的IP:port

- 当sentinel发现有新的从服务器出现时，不仅会创建相应的`sentinelRedisInstance`实体结构，还会**创建连接到从服务器的命令连接和订阅连接**。每隔十秒发送一次INFO命令，获取如下信息：
    1. 从服务器run_id，role，flags，name
    2. 所属主服务器的ip，port
    3. 主从服务器连接状态master_link_status
    4. 从服务器优先级 slave_priority
    5. 从服务器的复制偏移量 slave_repl_offset

![sentinel和服务器](https://s3.ax1x.com/2020/11/12/BzCvHf.png)

#### 发布和订阅
Sentinel通过PUBLISH命令发送和接收订阅

订阅连接建立之后，Sentinel每隔两秒通过**命令连接**向服务器的`__sentinel__:hello频道`发送一次`PUBLISH`命令，内容是sentinel和master的ip,port,runid,epoch。每两秒一次直到Sentinel与服务器连接断开为止
~~~
PUBLISH __sentinel__:hello "<s_ip>,<s_port>,<s_runid>,<s_epoch>,<m_name>,<m_ip>,<m_port>,<m_epoch>"
~~~

之后，Sentinel通过**订阅连接**从服务器的`__sentinel:hello__频道`接收信息，`SUBSCRIBE`命令
对于监视同一个服务器的多个Sentinel来说，**一个Sentinel的信息会被其他Sentinel接收到(包括自己)**，这些信息用于更新其他Sentinel对发送信息的Sentinel的认知

收到`__sentinel__:hello`频道消息的sentinel会提取消息中的sentinel的ip端口runid等参数，如果消息中的sentinel是自己(自己发送的)就丢弃，否则说明是监视同一个服务器的其他sentinel发来的，根据参数更新参数中的主服务器的`sentinels字典`

之后sentinel根据更新的`sentinels字典`，和其他sentinel互相建立命令连接(**sentilen之间只有命令连接**)，最终监视同一个服务器的sentinel之间都会互相建立命令连接


#### 检测主观下线状态
sentinel每秒一次向所有与他建立联系的实例(主从服务器，sentinel)发送`PING`命令，通过返回值判断实例是否在线
sentinel配置文件中的`down-after-milliseconds`指定了PING命令连续多少毫秒内返回无效回复，就认定为主观下线

#### 检测主服务器客观下线状态
当主服务器被检测为主观下线之后，为了确认是否真的下线，会向监视该主服务器的其他sentinel发送`SENTINEL is-master-down-by-addr <ip> <port> <current_epoch> <runid>`命令询问，如果足够多(根据sentinel配置)的sentinel都认为该主服务器是下线状态，则判断为客观下线，然后对主服务器执行**故障转移操作**

#### 领头Sentinel
当一个主服务器客观下线时，监听这个主服务器的各个Sentinel会进行协商，选举出一个领头Sentinel，由领头Sentinel对下线的主服务器执行故障转移操作

由发现主服务器进入客观下线的Sentinels发起，要求其他Sentinel把自己设置为局部领头Sentinel，**在相同的epoch里，每个Sentinel只有一次机会设置另一个Sentinel为局部领头Sentinel**，所以是先到先得，当某个局部领头Sentinel的票数大于一半时，就变成了真正的领头Sentinel。不管选举成功与否，**选举完后所有sentinel的epoch都会+1**，在新的epoch里所有Sentinel又有一次机会投票了

#### 故障转移
领头Sentinel选举完成后，由领头Sentinel对已下线的主服务器执行故障转移操作
1. 在已下线的主服务器的所有在线的从服务器中，选出一个从服务器，转换为主服务器(规则：状态良好，最近与回复过sentinel的`INFO`命令且最近与原主服务器有交互，数据完整，偏移量最大)
2. 修改其他从服务器的复制目标，让其他从服务器复制新的主服务器
3. 将已下线的主服务器设置为新的主服务器的从服务器(在sentinel的实例结构中)，当其再度上线，sentinel就会向它发送`SLAVEOF`指令，让它去复制新的主服务器


### 3.7.3 集群
Redis集群是Redis提供的分布式数据库方案，集群通过分片(sharding)来进行数据共享，提供复制和故障转移功能

#### 节点
一个节点就是运行在集群模式下的一个Redis服务器，Redis启动时根据`cluster-enabled`设置决定是否开启集群模式
`CLUSTER NODES`命令，查看当前集群的节点
`CLUSTER MEET <ip> <port>`命令，与指定节点握手，握手成功后将目标节点添加到当前节点所在的集群中(互相为对方节点创建一个`clusterNode`存放到`clusterState.nodes`字典里)
- A和B进行CLUSTER MEET三次握手：
  - A发送CLUSTER MEET命令给B
  - B返回PONG
  - A返回PING，握手完成
握手完成后A会将B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最后B就会被集群中所有节点认识

`clusterNode`结构保存了一个节点的当前状态，比如节点的创建时间、节点名、节点标志、节点当前纪元epoch、节点的IP、端口、一个连接节点所需信息的指针`clusterLink`(连接的创建时间、套接字描述符、输入输出缓冲区、相关联的节点)、以及该节点视角下集群目前的状态`clusterState`(集群是否在线、包含的节点、集群纪元等)
~~~c
struct clusterNode{
    //节点创建时间
    mstime_t ctime;

    //节点名字，40个十六进制字符组成
    char name[REDIS_CLUSTER_NAMELEN];

    //节点标志：标志节点的角色(主从)以及节点所处状态(在线/下线)
    int flags;

    //节点当前纪元，用于实现故障转移
    uint64_t configEpoch;

    //节点ip
    char ip[REDIS_IP_STR_LEN];

    //节点端口
    int port;

    //连接节点所需信息：节点创建时间、套接字描述符、输入输出缓冲区、相关联的节点
    clusterLink *link;

    //当前节点视角下，集群目前的状态：是否在线、包含的节点、集群纪元等
    clusterState *cluster_state;

    ...
}
~~~

#### slot槽
Redis集群通过**分片**的方式保存数据库中的键值对。
集群的整个数据库被分为16384个槽(slot)，数据库中的每个键都属于其中一个slot，每个节点可以处理0~16384个slot。
当集群的16384个slot全都有节点在处理时，集群处于上线状态(ok)，否则处于下线状态(fail)

`CLUSTER ADDSLOTS <slot> [slot ...]`命令可以将一个或多个**slot指派给当前节点**负责
`CLUSTER KEYSLOT <key>` 查看**对应key属于哪个slot**槽

集群的每个节点 `clusterNode` 结构的`slots`属性(bit数组)和`numslot`属性记录了该节点负责处理哪些slot，节点除了记录自己处理的slot，**还会把自己的slots数组通过消息发送给集群中的其他节点**，告诉其他节点自己目前负责处理哪些slot。所以**集群中每个节点都知道数据库中的16384个槽分别被指派给集群中哪些节点**

同时，`clusterState`结构的`clusterNode *slot[16384]`数组记录了每个slot槽分配给了哪些 clusterNode(一个slot位置可以由多个clusterNode负责)


#### 集群中的命令执行
当16384个slot全都被指派后，集群就进入了上线状态，客户端可以向集群中的节点发送数据了

1. 客户端向一个节点发送命令
2. 节点检查该命令要处理的槽是否指派给了自己
3. 目标槽指派给了自己则执行，否则向客户端返回一个MOVED错误`MOVED <slot> <ip>:<port>`，指引客户端转向(redirect)至正确的节点重新发送命令

**集群模式的redis-cli收到MOVED错误时不会打印，而是自动进行节点转向，并打印出转向信息，所以我们看不见节点返回的MOVED错误**

每个节点有自己的`slots_to_keys`**跳跃表**，保存了每个slot中的keys。方便进行按slot的keys查找 
如`CLUSTER GETKEYSINSLOT <slot> <count>`命令可以返回最多count个属于槽slot的keys

![slot_to_keys跳跃表](https://s3.ax1x.com/2020/11/12/DSiNHx.png)

#### 重新分片
重新分片即**重新将任意数量的槽指派给另一个目标节点**，槽所属的键值对(跳跃表中)也会移动到目标节点中。
重新分片的过程中集群无需下线，源节点和目标节点都可以继续处理命令请求
重新分片的过程由Redis的集群管理软件redis-trib负责执行

1. redis-trib对目标节点发送`CLUSTER SETSLOT <slot> IMPORTING <source_id>`，让目标节点准备从源节点导入slot的键值对
2. redis-trib对源节点发送`CLUSTER SETSLOT <slot> MIGRATING <target_id>`，让源节点准备迁移(migrate)slot的键值到目标节点 
3. redis-trib向源节点发送`CLUSTER GETKEYSINSLOT <slot> <count>`，获得最多count个属于slot的键值对的键名
4. 对3中的每个键名，redis-trib向源节点发送`MIGRATE <target_ip> <target_port> <key_name> 0 <timeout>`，将该键迁移到目标节点
5. 重复34直到源节点在该slot的所有键值对都迁移到了目标节点
6. redis-trib向集群中任意一个节点发送`CLUSTER SETSLOT <slot> NODE <target_id>`，将槽指派给目标节点，该信息会通过消息发送至整个集群，最终集群中所有节点都知道该slot已经指派给了目标节点

![重新分片](https://s3.ax1x.com/2020/11/16/DkQXi6.png)

**ASK错误**：如果slot从源节点迁移到目标节点的过程中，**客户端向源节点请求了一个slot中的key**，如果该key尚未迁移，则可以查找到，直接返回value，否则若查找不到，则去源节点的`clusterState.migrating_slots_to[i]`查看该key所属slot是否正在迁移，以及迁移的目标`clusterNode`，如果slot确实存在于数组中，说明正在迁移，则**源节点将返回ASK错误**，指引客户端转向目标节点再次发送之前的命令。
客户端向目标节点发送`ASKING`命令，打开客户端的`REDIS_ASKING`标识，如果未打开ASKING标识是查找不到的，因为slot尚未分配给目标节点。之后带有ASKING标识的客户端再发起查找请求，目标节点收到ASKING后破例去查找`clusterState.importing_slots_from[i]`，**找到正在导入过程中的slot[i]**，然后去slot[i]中查找目标key
同样ASK错误和MOVED错误类似，**集群的redis-cli收到错误不会打印，而是自动转向**
MOVED错误是永久重定向，之后所有关于该槽的请求都直接发送至新节点。而ASK是临时重定向，每次都要收到ASK错误后重定向一次

#### 复制与故障转移
Redis集群的节点分为主节点(Master)和从节点(slave)，其中**主节点用于处理槽，从节点用于复制某个主节点**，主节点下线后，其从节点将选出一个作为新的主节点，继续接管原主节点负责的槽，继续处理客户端的命令请求。同时，故障转移完成后，主节点从新上线将作为新的主节点的从节点

**复制**：`CLUSTER REPLICATE <node_id>` 让接收命令的节点去复制node_id节点，成为node_id节点的从节点(相当于非集群模式的SLAVE命令)
**故障检测**：集群中节点定期向集群中其他节点发送PING，检测对方是否在线，规定时间未收到回复PONG，则被主观标记为疑似下线`PFAIL`。集群中一半以上负责处理槽的主节点都认为某个主节点x疑似下线，则x被标记为已下线`FAIL`

**故障转移**：从下线的主节点的从节点中挑选出新的主节点，将原主节点的所有槽指派给新主节点，向集群广播一条`PONG消息`，告知其他节点，自己已经成为了新的主节点

**选举办法**：epoic是自增计数器，一次故障转移自增一次。一个epoic中每个处理槽的主节点都有一次投票机会，第一个向主节点要求投票的从节点获得投票(先到先得)，当某个从节点的票大于N/2时成为主节点。否则进入下一个纪元重新选举投票，直到选出新的主节点


#### 消息
集群中各个节点通过发送和接收消息来进行通信
所有消息都有一个消息头，包括了消息长度、类型、消息包含的节点数量、发送者纪元、发送者ID、发送者槽指派信息、发送者主从状态、发送者所处集群状态等

节点发送的消息有五种，其中MEET、PING、PONG是Gossip协议实现
**MEET消息**：当节点接收到客户端的`CLUSTER MEET <ip> <port>`命令后，就会向目标ip:port节点发送MEET消息，请求目标节点加入到自己所在的集群
**PING消息**：集群中每个节点默认每隔一秒就从自己已知节点列表中随机选出5个，再从5个中**选出一个最长时间没发送PING的节点**来发送PING消息，检测是否在线。此外若距离A最后一次收到B的PONG时间点超过A的`cluster-node-timeout`的一半，A也会向B发送PING，防止长时间未选中B导致消息更新落后
**PONG消息**：接收者收到PING或MEET消息后就会发送PONG回应。此外节点可以通过向集群广播自己的PONG消息，让其他节点立即刷新对这个节点的认识(如故障转移成功后的新主节点就会广播一条PONG)
**FAIL消息**：当一个主节点A判断另一个主节点B已经进入`FAIL`下线状态时，A会广播一条关于B下线的FAIL消息，收到消息的节点立即将B标记为下线
**PUBLISH消息**：当节点收到PUBLISH命令时，节点会执行这个命令并向集群广播一条PUBLISH消息，所有收到PUBLISH消息的节点都会执行相同的PUBLISH命令

## 3.8 独立功能的实现

### 3.8.1 发布与订阅
`PUBLISH` 向频道发送消息
`SUBSCRIBE` 订阅一个或多个频道
`UNSUBSCRIBE` 退订频道
`PSUBSCRIBE` 订阅一个或多个模式
`PUNSUBSCRIBE` 退订模式
![订阅模式](https://s3.ax1x.com/2020/11/16/DkDOun.png)

Redis将所有频道的订阅关系都保存在服务器状态的`pubsub_channels`字典里面，字典的键是某个被订阅的频道，值是所有订阅该频道的所有客户端的链表
Redis将所有模式的订阅关系都保存在服务器状态的`pubsub_patterns`链表中，链表包含了一个`pubsub_pattern`结构，结构包含被订阅的模式和订阅该模式的客户端

#### 发送消息
`PUBLISH <channel> <message>` 将消息发送到指定的频道channel。
服务器需要执行两个动作：**将消息发送给channel频道的订阅者**，如果有一个或多个模式与频道相匹配，还要**将消息发送到这些匹配的模式的订阅者**
**发送给channel频道的订阅者**：只需要`pubsub_channels`**字典**的channel键对应的值的**链表**，将消息发送给链表中的客户端即可
**发送给模式订阅者**：**遍历**整个`pubsub_patterns`链表，查找到那些与channel匹配的模式，然后将消息发送给这些模式的订阅者

#### 查看订阅信息
`PUBSUB`命令，Redis2.8才有，可以查看频道或者模式的相关信息，如目前多少订阅者
`PUBSUB CHANNELS [pattern]` 返回服务器当前被订阅的频道。不给定pattern返回服务器当前被订阅的所有频道，给定pattern给返回匹配的所有频道。通过遍历服务器状态的pubsub_channels字典的所有键来实现
`PUBSUB NUMSUB [channel-1 channel-2 ... channel-n]` 返回这些频道的订阅者数量
`PUBSUB NUMPAT` 返回当前服务器被订阅的模式数量，通过遍历pubsub_patterns链表得到长度来实现

### 3.8.3 事务
Redis的事务通过`MULTI`、`EXEC`、`WATCH`等命令来实现
使用`MULTI`开启事务，使用`EXEC`提交事务，使用

#### 事务的实现
事务开启后，客户端发送的命令除了`EXEC、DISCARD、WATCH、MULTI`四个之外会立即执行，其他命令都会放入**事务队列**里，向客户端返回QUEUED
当客户端发送`EXEC`命令之后，EXEC命令被立即执行，之后服务器会遍历这个客户端的事务队列，**依次执行队列中保存的所有命令**，最后将执行结果全部返回给客户端

#### WATCH命令的实现
WATCH是一个乐观锁，在EXEC命令前监视任意数量的数据库键，如检查被监视的键是否至少有一个被改变了，如果改变了，服务器就拒绝执行事务，返回空回复
![watch](https://s3.ax1x.com/2020/11/16/DkXBh8.png)

每个Redis数据库都保存着一个`watched_keys`字典，键是某个被watch命令监视的数据库键，值是监视该键的客户端的链表
当所有对数据库进行修改的命令执行后，都会调用touchWatchKey函数对`watch_keys`字典进行检查，查看刚刚修改的数据库键是否被监视，如果被监视，就把监视该键的客户端的`REDIS_DIRTY_CAS`标志打开，表示该事务的安全性已经被破坏了，客户端发送EXEC命令后，服务器发现客户端的`REDIS_DIRTY_CAS`标志打开，于是就拒绝执行客户端的提交

#### 事务的ACID特性
Redis事务总是有原子性、一致性、隔离性的，持久性在某种特性的持久化模式下也具有

**原子性**：由于Redis事务的提交是事务队列，队列中要么全部执行，要么全部不执行，所以具有原子性。但是Redis**不支持事务的回滚操作**，当开启事务后发送了错误的命令(Redis不识别的命令)，事务提交后不会被执行。若开启事务后发送了简单的错误，如命令对应的类型错误，Redis会跳过错误语句继续执行

**一致性**：
- 命令入队错误：提交了错误的命令(Redis不识别的命令)，在提交时直接报错，不执行
- 命令执行错误：如对string执行rpush，在实际执行时出错，除了出错的命令外，其他命令都正常执行，不会影响事务一致性
- 服务器停机：RDB或AOF恢复到上一个一致状态

**隔离性**：由于Redis单线程的方式执行事务(事务队列)，所以执行事务期间不会对事务进行中断，串行方式运行，总是具有隔离性

**持久性**：
- 无持久化模式显然不具有持久性
- RDB模式下，只有特定条件满足时才执行BGSAVE，异步BGSAVE不能保证事务数据第一时间保存到硬盘，所以也不具有持久性
- AOF模式下，只有appendfsync=always时每次写入都持久化，才具有持久性。否则每秒的持久化也可能丢失数据，而不主动持久化更是丢失数据

### 3.8.5 排序
Redis的`SORT`命令可以对列表键、集合键、有序集合键的值进行排序。输出排序结果，但是不改变存储的数据顺序
~~~c
typedef struct _redisSortObject{
    //被排序的值
    robj *obj;

    //权重
    union{
        double score;   //排序数字值时使用
        robj *compobj;  //排序带有BY选项的字符串值使用
    }
}
~~~
#### 1. SORT <key>命令
~~~
127.0.0.1:6379> rpush numbers 2 3 1
3
127.0.0.1:6379> sort numbers
1
2
3
~~~

SORT nbumbers命令的详细步骤
1. 创建一个和numbers同长度的数组，数组的每一项都是一个`redisSortObject`结构
2. 遍历数组，将obj指针分别指向numbers列表的各个项，一一对应
3. 遍历数组，将obj指针指向的列表项转换成`double`类型浮点数，然后保存到`u.score`属性里
4. 根据`u.score`进行排序
5. 遍历数组，将各个数组项的obj指针指向的列表项作为结果返回给客户端

#### 2. ALPHA选项
通过`ALPHA`选项，可以对包含字符串的键进行排序`SORT <key> ALPHA`
~~~
127.0.0.1:6379> rpush strs "one" "two" "three" "four"
4
127.0.0.1:6379> sort strs
ERR One or more scores can't be converted into double

127.0.0.1:6379> sort strs alpha
four
one
three
two
~~~

#### 3. ASC和DESC
默认是ASC升序
降序排序`SORT <key> DESC`

#### 4. BY、LIMIT
将列表/集合/有序集合 按指定的某个字符串键，或者某个哈希键所包含的某些域来作为元素的权重，对一个键进行排序
~~~
127.0.0.1:6379> SADD fruits "apple" "banana" "cherry"
(integer) 3
127.0.0.1:6379> MSET apple-price 4 banana-price 2 cherry-price 8
OK
127.0.0.1:6379> SORT fruits BY *-price
1) "banana"
2) "apple"
3) "cherry"
~~~

过程：
- 创建redisSortObject数组，长度等于fruits集合大小
- 遍历数组，将数组各项的obj指针指向fruits集合的各个元素
- 遍历数组，根据obj指向的元素，以及BY所指定的模式*-price，查找对应的权重键
- 将权重键的值转换为double，保存到u.score，然后排序
- 按顺序依次输出各项的obj指针对应集合元素

**如果给定的权值是字符串，还可以将BY和ALPHA结合**
~~~
127.0.0.1:6379> MSET apple-id "fruits-2" banana-id "fruits-3" cherry-id "fruits-1"
OK
127.0.0.1:6379> SORT fruits BY *-id ALPHA DESC
1) "banana"
2) "apple"
3) "cherry"
~~~

**还可以使用LIMIT限制结果的数量**：`LIMIT <offset> <count>`，表示跳过offset个元素，然后返回count个元素
~~~
127.0.0.1:6379> SORT fruits BY *-id ALPHA DESC LIMIT 0 2
1) "banana"
2) "apple"
~~~

#### 5. GET命令
SORT对键进行排序之后，根据被排序的元素，以及GET选项所指定的模式，查找并返回某些键的值
~~~
127.0.0.1:6379> SORT fruits ALPHA
1) "apple"
2) "banana"
3) "cherry"
127.0.0.1:6379> SORT fruits ALPHA GET *-id
1) "fruits-2"
2) "fruits-3"
3) "fruits-1"
127.0.0.1:6379> SORT fruits ALPHA GET *-price
1) "4"
2) "2"
3) "8"
~~~

#### 6. STORE保存结果
默认情况下SORT只向客户端返回排序结果，而不保存排序结果，使用STORE选项，可以将结果保存到指定的键中

~~~
127.0.0.1:6379> SORT fruits ALPHA GET *-id STORE stored_fruit_get_id
(integer) 3
127.0.0.1:6379> LRANGE stored_fruit_get_id 0 -1
1) "fruits-2"
2) "fruits-3"
3) "fruits-1"
~~~

#### 7. 组合排序
`SORT <key> ALPHA DESC BY <by-pattern> LIMIT <offset> <count> GET <get-pattern> STORE <store_key>`

### 3.8.6 二进制位数组
`SETBIT`、`GETBIT`、`BITCOUNT`、`BITOP`四个命令
~~~
127.0.0.1:6379> SETBIT bits 0 1     //0000 0001
(integer) 0
127.0.0.1:6379> SETBIT bits 3 1     //0000 1001
(integer) 0
127.0.0.1:6379> SETBIT bits 7 1     //1000 1001
(integer) 0
127.0.0.1:6379> GETBIT bits 3       
(integer) 1
127.0.0.1:6379> GETBIT bits 2
(integer) 0
127.0.0.1:6379> BITCOUNT bits
(integer) 3
~~~
**BITOP**可以进行and，or，xor，not运算
~~~
127.0.0.1:6379> SETBIT x 0 1
(integer) 0
127.0.0.1:6379> SETBIT x 1 1    //0000 0011
(integer) 0
127.0.0.1:6379> SETBIT y 2 1
(integer) 0
127.0.0.1:6379> SETBIT y 3 1    //0000 1100
(integer) 0
127.0.0.1:6379> BITOP AND and-result x y    //0000 0000
(integer) 1
127.0.0.1:6379> BITOP OR or-result x y      //0000 1111
(integer) 1
127.0.0.1:6379> BITOP XOR xor-result x y    //0000 1111
(integer) 1
~~~

#### 二进制位数组的存储
二进制位数组使用`SDS`结构存储，是一字节长的位数组。 最后一个字节是`\0`
**每个字节的位数组的位是倒序存放的，便于SETBIT和GETBIT命令的实现**
如下图对应了 `1101 0111 0100 1101` 的内存结构：
![位数组](https://s3.ax1x.com/2020/11/16/DE9GtA.png)

这样`SETBIT`和`GETBIT`的时候只需要通过除法和mod运算就可以查找到要修改的位了


#### BITCOUNT的实现
**遍历算法**：一次一位，效率低下
**查表法**：需要额外 2^8 B 的空间，一次比较8位，也可以用 2^17 B 空间来一次比较16位
**variable-precision SWAR算法**：
~~~
//计算32位二进制的汉明重量
uint32_t swar(uint32_t i)
{
	i = (i & 0x55555555) + ((i >> 1) & 0x55555555);			//步骤1
	i = (i & 0x33333333) + ((i >> 2) & 0x33333333);			//步骤2
	i = (i & 0x0F0F0F0F) + ((i >> 4) & 0x0F0F0F0F);			//步骤3
	i = (i * (0x01010101) >> 24);							//步骤4

	return i;
}
~~~
**Redis的实现**：如果未处理的二进制位数大于等于128，则使用variable-precision SWAR算法。否则使用查表法(8位的表)

### 3.8.7 慢查询日志
`CONFIG SET slowlog-log-slower-than <ms>`配置服务器超过多少微秒的命令会被记录到日志上。(例如100，则执行时间超过100微秒的命令就会被记录到慢查询日志)
`CONFIG SET slowlog-max-len <len>`指定服务器最多保存多少条慢查询日志。(先进先出的方式保存)
`SLOWLOG GET`获得慢查询日志
`SLOWLOG LEN`查看当前保存的慢查询日志的条数
~~~
127.0.0.1:6379> CONFIG SET slowlog-log-slower-than 0
OK
127.0.0.1:6379> CONFIG SET slowlog-max-len 2
OK
127.0.0.1:6379> SET msg1 "hello"
OK
127.0.0.1:6379> SET msg2 "hello"
OK
127.0.0.1:6379> SET msg3 "hello"
OK
127.0.0.1:6379> SLOWLOG GET
1) 1) (integer) 10              //唯一标识符
   2) (integer) 1605534574      //命令执行时的时间
   3) (integer) 136             //命令执行消耗的时间
   4) 1) "SET"                  //命令与命令参数
      2) "msg3"
      3) "hello"
   5) "127.0.0.1:50313"
   6) ""
2) 1) (integer) 9
   2) (integer) 1605534569
   3) (integer) 8
   4) 1) "SET"
      2) "msg2"
      3) "hello"
   5) "127.0.0.1:50313"
   6) ""
127.0.0.1:6379>
~~~

### 3.8.9 监视器
通过`MONITOR`命令，可以将客户端变为一个监视器，实时的打印出服务器当前处理的命令请求的相关信息。每当其他客户端向服务器发送一条命令请求时，服务器除了会处理这条命令请求之外，还会将关于这条命令请求的信息发送给所有的监视器
![MONITOR1](https://s3.ax1x.com/2020/11/16/DEmlFK.png)
![MONITOR2](https://s3.ax1x.com/2020/11/16/DEm1JO.png)


### 3.8.9 Lua脚本


# 4. Jedis

## 1. QuickStart
- 获取Jedis连接对象 `Jedis jedis = new Jedis("localhost", 6379);`，空参构造默认就是localhost和3306
- 关闭连接 `jedis.close();`

~~~java
    public void test1(){
        //获取连接,空参构造默认就是localhost和3306
        Jedis jedis = new Jedis("localhost", 6379);
        jedis.set("username","zhangsan");
        jedis.setex("name", 20, "lisi");  //20秒后自动删除数据

        jedis.hset("user", "username", "张三");
        jedis.hset("user", "password", "zhangsan123");
        Map<String, String> user = jedis.hgetAll("user");
        for(Map.Entry<String,String> entry:user.entrySet()){
            System.out.println(entry.getKey()+"--->"+entry.getValue());     //password--->zhangsan123  username--->张三
        }

        jedis.lpush("list", "张三", "李四", "王五");
        jedis.rpush("list", "赵六");
        List<String> list = jedis.lrange("list", 0, -1);
        System.out.println(list);       //[王五, 李四, 张三, 赵六]

        jedis.sadd("nameSet", "张三", "李四", "王五");
        Set<String> nameSet = jedis.smembers("nameSet");
        System.out.println(nameSet);    //[王五, 张三, 李四]

        jedis.zadd("nameZ", 40, "李四");
        jedis.zadd("nameZ", 50, "王五");
        jedis.zadd("nameZ", 30, "张三");
        Set<String> nameZ = jedis.zrange("nameZ", 0, -1);
        System.out.println(nameZ);      //[张三, 李四, 王五]

        //关闭连接
        jedis.close();
    }
~~~

## 2. Jedis连接池
- 创建 JedisPool 连接池对象
- 使用 `getResource()` 方法获取Jedis 连接

~~~java
    public void test2(){
        //创建配置对象
        JedisPoolConfig config = new JedisPoolConfig();
        config.setMaxTotal(50); //最大连接
        config.setMaxIdle(10); //最大空闲连接
        
        //创建jedis连接池对象
        JedisPool jedisPool = new JedisPool(config, "localhost", 6379);
        
        //获取连接对象
        Jedis jedis = jedisPool.getResource();
        
        //使用jedis
        jedis.set("name","张三");
        
        //释放资源
        jedis.colse();
    }
~~~

- jedis连接池工具类 JedisPoolUtils

~~~java
public class JedisPoolUtils {
    private static JedisPool jedisPool;

    static{
        //读取配置文件
        Properties properties = new Properties();
        try {
            properties.load(JedisPoolUtils.class.getClassLoader().getResourceAsStream("jedis.properties"));
        } catch (IOException e) {
            e.printStackTrace();
        }

        //配置JedisPoolConfig
        JedisPoolConfig config = new JedisPoolConfig();
        config.setMaxTotal(Integer.parseInt(properties.getProperty("maxTotal")));
        config.setMaxIdle(Integer.parseInt(properties.getProperty("maxIdle")));

        //初始化JedisPool
        jedisPool = new JedisPool(config, properties.getProperty("host"), Integer.parseInt(properties.getProperty("port")));
    }

    public static Jedis getJedis(){
        return jedisPool.getResource();
    }
}
~~~
